{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYHUSCHjPhAq"
   },
   "source": [
    "# SummerTime Midway Showcase\n",
    "\n",
    "#### This notebook shows part of the current functionality of the SummerTime - A summarization library.\n",
    "\n",
    "Note: This is not the production version of the library and more modules are being added, including but not limited to pip installation, more models, more datasets, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbJwtmwJQabJ"
   },
   "source": [
    "## Installation\n",
    "Cloning from GitHub at the moment, but will support `pip install` soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQvjj2buK3Qo",
    "outputId": "7541ebf4-2d48-473e-e61e-685e369dac15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/lily/mmm274/SummerTime/notebook/SummerTime\n",
      "HEAD is now at 6b48c8b Merge branch 'main' into troyfeng116/integration-tests\n"
     ]
    }
   ],
   "source": [
    "## Uncomment to clone git repo if not already done so\n",
    "## Swith to the Summertime directory\n",
    "## Switch to the relevant git branch\n",
    "\n",
    "# !git clone https://github.com/Yale-LILY/SummerTime.git\n",
    "# %cd SummerTime/\n",
    "# !git checkout origin/troyfeng116/integration-tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VttAZIVvQ5Ye"
   },
   "source": [
    "### Install dependencies for the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdrTYwrFLl8A",
    "outputId": "3613dd53-6b81-49bf-eb7f-0adad7508709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 6.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: transformers==4.5.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (4.5.1)\n",
      "Requirement already satisfied: torch==1.8.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.8.1)\n",
      "Requirement already satisfied: torchvision==0.9.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.9.1)\n",
      "Requirement already satisfied: torchaudio==0.8.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
      "Collecting lexrank==0.1.0\n",
      "  Using cached lexrank-0.1.0-py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: nltk==3.6.2 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (3.6.2)\n",
      "Requirement already satisfied: spacy==3.0.6 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (3.0.6)\n",
      "Requirement already satisfied: pytextrank in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (3.2.1)\n",
      "Collecting datasets==1.6.2\n",
      "  Using cached datasets-1.6.2-py3-none-any.whl (221 kB)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.1.95)\n",
      "Requirement already satisfied: summ_eval in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (0.70)\n",
      "Requirement already satisfied: jupyter in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (1.0.0)\n",
      "Collecting gensim==3.8.3\n",
      "  Using cached gensim-3.8.3-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
      "Requirement already satisfied: sklearn in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (0.0)\n",
      "Requirement already satisfied: py7zr==0.16.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.16.1)\n",
      "Requirement already satisfied: mpi4py==3.0.3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (3.0.3)\n",
      "Requirement already satisfied: tqdm==4.49.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (4.49.0)\n",
      "Requirement already satisfied: pandas in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (5.0.0)\n",
      "Requirement already satisfied: dill in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (0.3.4)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (0.0.15)\n",
      "Requirement already satisfied: packaging in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (21.0)\n",
      "Requirement already satisfied: xxhash in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (2.0.2)\n",
      "Requirement already satisfied: fsspec in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (2021.7.0)\n",
      "Requirement already satisfied: multiprocess in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (0.70.12.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (2.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (1.21.2)\n",
      "Requirement already satisfied: six>=1.5.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from gensim==3.8.3->-r requirements.txt (line 14)) (1.16.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from gensim==3.8.3->-r requirements.txt (line 14)) (1.7.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from gensim==3.8.3->-r requirements.txt (line 14)) (5.2.0)\n",
      "Requirement already satisfied: regex>=2017.11.9 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from lexrank==0.1.0->-r requirements.txt (line 5)) (2021.8.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from lexrank==0.1.0->-r requirements.txt (line 5)) (0.17.3)\n",
      "Requirement already satisfied: urlextract>=0.7 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from lexrank==0.1.0->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: path.py>=10.5 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from lexrank==0.1.0->-r requirements.txt (line 5)) (12.5.0)\n",
      "Requirement already satisfied: joblib in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nltk==3.6.2->-r requirements.txt (line 6)) (1.0.1)\n",
      "Requirement already satisfied: click in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nltk==3.6.2->-r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: pyzstd<0.15.0,>=0.14.4 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (0.14.4)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (0.2.3)\n",
      "Requirement already satisfied: bcj-cffi<0.6.0,>=0.5.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (0.5.1)\n",
      "Requirement already satisfied: brotli>=1.0.9 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (1.0.9)\n",
      "Requirement already satisfied: pyppmd>=0.14.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (0.16.1)\n",
      "Requirement already satisfied: texttable in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (1.6.4)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (3.10.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (1.0.5)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (1.7.4)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (8.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (2.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (0.6.0)\n",
      "Requirement already satisfied: jinja2 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (3.0.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (2.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (0.7.4)\n",
      "Requirement already satisfied: setuptools in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (52.0.0.post20210125)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (0.3.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: typing-extensions in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from torch==1.8.1->-r requirements.txt (line 2)) (3.10.0.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from torchvision==0.9.1->-r requirements.txt (line 3)) (8.3.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: filelock in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (0.0.45)\n",
      "Requirement already satisfied: cffi>=1.14.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from bcj-cffi<0.6.0,>=0.5.1->py7zr==0.16.1->-r requirements.txt (line 16)) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from cffi>=1.14.0->bcj-cffi<0.6.0,>=0.5.1->py7zr==0.16.1->-r requirements.txt (line 16)) (2.20)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from packaging->datasets==1.6.2->-r requirements.txt (line 9)) (2.4.7)\n",
      "Requirement already satisfied: path in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from path.py>=10.5->lexrank==0.1.0->-r requirements.txt (line 5)) (16.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.6.2->-r requirements.txt (line 9)) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.6.2->-r requirements.txt (line 9)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.6.2->-r requirements.txt (line 9)) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from requests>=2.19.0->datasets==1.6.2->-r requirements.txt (line 9)) (1.26.6)\n",
      "Requirement already satisfied: appdirs in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from urlextract>=0.7->lexrank==0.1.0->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: uritools in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from urlextract>=0.7->lexrank==0.1.0->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: ipykernel in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (5.3.4)\n",
      "Requirement already satisfied: jupyter-console in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (6.4.0)\n",
      "Requirement already satisfied: notebook in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (6.4.3)\n",
      "Requirement already satisfied: ipywidgets in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (7.6.3)\n",
      "Requirement already satisfied: nbconvert in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (6.1.0)\n",
      "Requirement already satisfied: qtconsole in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (5.1.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from pytextrank->-r requirements.txt (line 8)) (2.6.2)\n",
      "Requirement already satisfied: icecream>=2.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from pytextrank->-r requirements.txt (line 8)) (2.1.1)\n",
      "Requirement already satisfied: graphviz>=0.13 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from pytextrank->-r requirements.txt (line 8)) (0.17)\n",
      "Requirement already satisfied: pygments>=2.7.4 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from pytextrank->-r requirements.txt (line 8)) (2.10.0)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from icecream>=2.1->pytextrank->-r requirements.txt (line 8)) (0.4.4)\n",
      "Requirement already satisfied: executing>=0.3.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from icecream>=2.1->pytextrank->-r requirements.txt (line 8)) (0.8.0)\n",
      "Requirement already satisfied: asttokens>=2.0.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from icecream>=2.1->pytextrank->-r requirements.txt (line 8)) (2.0.5)\n",
      "Requirement already satisfied: scikit-learn in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from sklearn->-r requirements.txt (line 15)) (0.24.2)\n",
      "Requirement already satisfied: psutil in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (5.8.0)\n",
      "Requirement already satisfied: stanza in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (1.2.3)\n",
      "Requirement already satisfied: sacrebleu in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (2.0.0)\n",
      "Requirement already satisfied: moverscore in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (1.0.3)\n",
      "Requirement already satisfied: wmd in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: blanc in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: bert-score in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.3.10)\n",
      "Requirement already satisfied: pytorch-pretrained-bert in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.6.2)\n",
      "Requirement already satisfied: gin-config in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: pyemd==0.5.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.5.1)\n",
      "Requirement already satisfied: matplotlib in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from bert-score->summ_eval->-r requirements.txt (line 11)) (3.4.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from pandas->datasets==1.6.2->-r requirements.txt (line 9)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from pandas->datasets==1.6.2->-r requirements.txt (line 9)) (2021.1)\n",
      "Requirement already satisfied: jupyter-client in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 13)) (6.1.12)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 13)) (5.0.5)\n",
      "Requirement already satisfied: tornado>=4.2 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 13)) (6.1)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 13)) (7.26.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib-inline in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.18.0)\n",
      "Requirement already satisfied: decorator in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (5.0.9)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (3.0.17)\n",
      "Requirement already satisfied: backcall in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from traitlets>=4.1.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 13)) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 13)) (1.0.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 13)) (3.5.1)\n",
      "Requirement already satisfied: jupyter-core in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 13)) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 13)) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter->-r requirements.txt (line 13)) (21.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (0.11.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (0.9.4)\n",
      "Requirement already satisfied: pyzmq>=17 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (22.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from jinja2->spacy==3.0.6->-r requirements.txt (line 7)) (2.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from matplotlib->bert-score->summ_eval->-r requirements.txt (line 11)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from matplotlib->bert-score->summ_eval->-r requirements.txt (line 11)) (0.10.0)\n",
      "Requirement already satisfied: typing in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from moverscore->summ_eval->-r requirements.txt (line 11)) (3.7.4.3)\n",
      "Requirement already satisfied: portalocker in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from moverscore->summ_eval->-r requirements.txt (line 11)) (2.3.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.8.4)\n",
      "Requirement already satisfied: testpath in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.3)\n",
      "Requirement already satisfied: bleach in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (4.0.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (1.4.3)\n",
      "Requirement already satisfied: async-generator in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->-r requirements.txt (line 13)) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->-r requirements.txt (line 13)) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 13)) (0.5.1)\n",
      "Requirement already satisfied: boto3 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from pytorch-pretrained-bert->summ_eval->-r requirements.txt (line 11)) (1.18.26)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->summ_eval->-r requirements.txt (line 11)) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.26 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->summ_eval->-r requirements.txt (line 11)) (1.21.26)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->summ_eval->-r requirements.txt (line 11)) (0.5.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qtpy in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from qtconsole->jupyter->-r requirements.txt (line 13)) (1.9.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from sacrebleu->summ_eval->-r requirements.txt (line 11)) (0.8.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 15)) (2.2.0)\n",
      "Requirement already satisfied: protobuf in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from stanza->summ_eval->-r requirements.txt (line 11)) (3.17.3)\n",
      "Installing collected packages: lexrank, gensim, en-core-web-sm, datasets\n",
      "Successfully installed datasets-1.6.2 en-core-web-sm-3.0.0 gensim-3.8.3 lexrank-0.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1tna-CoXccl",
    "outputId": "84ff21e9-7008-499b-b223-f204363a6354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/bheinzerling/pyrouge.git\r\n",
      "  Cloning https://github.com/bheinzerling/pyrouge.git to /tmp/pip-req-build-ant4nznt\r\n",
      "  Running command git clone -q https://github.com/bheinzerling/pyrouge.git /tmp/pip-req-build-ant4nznt\r\n"
     ]
    }
   ],
   "source": [
    "## Finish setup\n",
    "\n",
    "# Setup ROUGE\n",
    "!export ROUGE_HOME=/usr/local/lib/python3.7/dist-packages/summ_eval/ROUGE-1.5.5/\n",
    "!pip install -U  git+https://github.com/bheinzerling/pyrouge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pFDLAguuRYti"
   },
   "outputs": [],
   "source": [
    "## Uncomment to restart runtime if prompted to do so in either of the two previous cells; else ignore\n",
    "## Restart runtime to install modules\n",
    "# import os\n",
    "# os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to move back into the Summertime directory if restarted runtime\n",
    "## Only use if you cloned the repo\n",
    "# %cd SummerTime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KsF1YSE8Oh2r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules for this notebook\n",
    "\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2_w-G2sYVk7"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8mlHZTueGse"
   },
   "source": [
    "### Supported Models\n",
    "\n",
    "SummerTime supports different models (*e.g.,* TextRank, BART, Longformer) as well as model wrappers for more complex summariztion tasks (*e.g.,* JointModel for multi-doc summarzation, BM25 retrieval for query-based summarization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nks3fuiqeTTX",
    "outputId": "17fc39b9-7cee-4215-d237-e196b8c5656e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'model.single_doc.bart_model.BartModel'>,\n",
      " <class 'model.single_doc.lexrank_model.LexRankModel'>,\n",
      " <class 'model.single_doc.longformer_model.LongformerModel'>,\n",
      " <class 'model.single_doc.pegasus_model.PegasusModel'>,\n",
      " <class 'model.single_doc.textrank_model.TextRankModel'>,\n",
      " <class 'model.multi_doc.multi_doc_joint_model.MultiDocJointModel'>,\n",
      " <class 'model.multi_doc.multi_doc_separate_model.MultiDocSeparateModel'>,\n",
      " <class 'model.dialogue.hmnet_model.HMNetModel'>,\n",
      " <class 'model.query_based.tf_idf_model.TFIDFSummModel'>,\n",
      " <class 'model.query_based.bm25_model.BM25SummModel'>]\n"
     ]
    }
   ],
   "source": [
    "from model import SUPPORTED_SUMM_MODELS\n",
    "\n",
    "pprint(SUPPORTED_SUMM_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MueJBGGRDx_p"
   },
   "source": [
    "### Automatic Pipeline Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91GZr7NVYVlD"
   },
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5xjUxipwYVk-"
   },
   "outputs": [],
   "source": [
    "import model\n",
    "\n",
    "# Users can load a default summarization model\n",
    "sample_model = model.summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qVuMfAWRYVlA"
   },
   "outputs": [],
   "source": [
    "from model import SUPPORTED_SUMM_MODELS, LexRankModel, PegasusModel\n",
    "\n",
    "# Or a specific model\n",
    "pegasus = PegasusModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XWzGHXYUYVlE",
    "outputId": "2cf9aa74-595a-4597-acd5-8a14b84a3b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegasus is the default singe-document summarization model.\n",
      "Pegasus is a abstractive, neural model for summarization. \n",
      " #################### \n",
      " Introduced in 2019, a large neural abstractive summarization model trained on web crawl and news data.\n",
      " Strengths: \n",
      " - High accuracy \n",
      " - Performs well on almost all kinds of non-literary written text \n",
      " Weaknesses: \n",
      " - High memory usage \n",
      " Initialization arguments: \n",
      " - `device = 'cpu'` specifies the device the model is stored on and uses for computation. Use `device='gpu'` to run on an Nvidia GPU.\n"
     ]
    }
   ],
   "source": [
    "# Users can easily access documentation to assist with model selection\n",
    "sample_model.show_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SGQ8FqgYVlK"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNJ8WbcgYVlN",
    "outputId": "240cd6c6-6f96-4c0e-d376-6a70b5aec651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"California's largest electricity provider has turned off power to hundreds of thousands of customers.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. \n",
    "    The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected \n",
    "    by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "sample_model.summarize(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc-6dI_RYVlQ"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMth4yUce8IR"
   },
   "source": [
    "### Datasets supported\n",
    "\n",
    "SummerTime supports different summarization datasets across different domains (*e.g.,* CNNDM dataset - news article corpus, Samsum - dialogue corpus, QM-Sum - query-based dialogue corpus, MultiNews - multi-document corpus, ML-sum - multi-lingual corpus, PubMedQa - Medical domain, Arxiv - Science papers domain, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DULD_cWhe8IS",
    "outputId": "b505223a-14bf-4623-c711-4fe8553807e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'dataset.huggingface_datasets.CnndmDataset'>,\n",
      " <class 'dataset.huggingface_datasets.MultinewsDataset'>,\n",
      " <class 'dataset.huggingface_datasets.SamsumDataset'>,\n",
      " <class 'dataset.huggingface_datasets.XsumDataset'>,\n",
      " <class 'dataset.huggingface_datasets.PubmedqaDataset'>,\n",
      " <class 'dataset.huggingface_datasets.MlsumDataset'>,\n",
      " <class 'dataset.non_huggingface_datasets.ScisummnetDataset'>,\n",
      " <class 'dataset.non_huggingface_datasets.SummscreenDataset'>,\n",
      " <class 'dataset.non_huggingface_datasets.QMsumDataset'>,\n",
      " <class 'dataset.non_huggingface_datasets.ArxivDataset'>]\n"
     ]
    }
   ],
   "source": [
    "from dataset import SUPPORTED_SUMM_DATASETS\n",
    "\n",
    "pprint(SUPPORTED_SUMM_DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go7c_qboLx0t"
   },
   "source": [
    "### Dataset Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzqFrrKJYVlU",
    "outputId": "59517a79-d4f3-4c6b-eb3e-0c7f8bbd5f03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/lily/mmm274/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "\n",
    "cnn_dataset = dataset.CnndmDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhpjrvfhYVlV",
    "outputId": "31bb139b-2471-4c2e-a9c7-6a863b9e3bc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/287113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(\"{'source': 'It\\\\'s official: U.S. President Barack Obama wants lawmakers to \"\n",
      " 'weigh in on whether to use military force in Syria. Obama sent a letter to '\n",
      " 'the heads of the House and Senate on Saturday night, hours after announcing '\n",
      " 'that he believes military action against Syrian targets is the right step to '\n",
      " 'take over the alleged use of chemical weapons. The proposed legislation from '\n",
      " 'Obama asks Congress to approve the use of military force \"to deter, disrupt, '\n",
      " 'prevent and degrade the potential for future uses of chemical weapons or '\n",
      " 'other weapons of mass destruction.\" It\\\\\\'s a step that is set to turn an '\n",
      " 'international crisis into a fierce domestic political battle. There are key '\n",
      " 'questions looming over the debate: What did U.N. weapons inspectors find in '\n",
      " 'Syria? What happens if Congress votes no? And how will the Syrian government '\n",
      " 'react? In a televised address from the White House Rose Garden earlier '\n",
      " 'Saturday, the president said he would take his case to Congress, not because '\n",
      " 'he has to -- but because he wants to. \"While I believe I have the authority '\n",
      " 'to carry out this military action without specific congressional '\n",
      " 'authorization, I know that the country will be stronger if we take this '\n",
      " 'course, and our actions will be even more effective,\" he said. \"We should '\n",
      " 'have this debate, because the issues are too big for business as usual.\" '\n",
      " 'Obama said top congressional leaders had agreed to schedule a debate when '\n",
      " 'the body returns to Washington on September 9. The Senate Foreign Relations '\n",
      " 'Committee will hold a hearing over the matter on Tuesday, Sen. Robert '\n",
      " \"Menendez said. Transcript: Read Obama\\\\'s full remarks . Syrian crisis: \"\n",
      " \"Latest developments . U.N. inspectors leave Syria . Obama\\\\'s remarks came \"\n",
      " 'shortly after U.N. inspectors left Syria, carrying evidence that will '\n",
      " 'determine whether chemical weapons were used in an attack early last week in '\n",
      " 'a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- '\n",
      " 'and that is to ascertain whether chemical weapons were used -- and not by '\n",
      " 'whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who '\n",
      " 'used the weapons in the reported toxic gas attack in a Damascus suburb on '\n",
      " 'August 21 has been a key point of global debate over the Syrian crisis. Top '\n",
      " \"U.S. officials have said there\\\\'s no doubt that the Syrian government was \"\n",
      " 'behind it, while Syrian officials have denied responsibility and blamed '\n",
      " 'jihadists fighting with the rebels. British and U.S. intelligence reports '\n",
      " 'say the attack involved chemical weapons, but U.N. officials have stressed '\n",
      " 'the importance of waiting for an official report from inspectors. The '\n",
      " 'inspectors will share their findings with U.N. Secretary-General Ban Ki-moon '\n",
      " \"Ban, who has said he wants to wait until the U.N. team\\\\'s final report is \"\n",
      " 'completed before presenting it to the U.N. Security Council. The '\n",
      " 'Organization for the Prohibition of Chemical Weapons, which nine of the '\n",
      " 'inspectors belong to, said Saturday that it could take up to three weeks to '\n",
      " 'analyze the evidence they collected. \"It needs time to be able to analyze '\n",
      " 'the information and the samples,\" Nesirky said. He noted that Ban has '\n",
      " 'repeatedly said there is no alternative to a political solution to the '\n",
      " 'crisis in Syria, and that \"a military solution is not an option.\" Bergen:  '\n",
      " \"Syria is a problem from hell for the U.S. Obama: \\\\'This menace must be \"\n",
      " \"confronted\\\\' Obama\\\\'s senior advisers have debated the next steps to take, \"\n",
      " \"and the president\\\\'s comments Saturday came amid mounting political \"\n",
      " 'pressure over the situation in Syria. Some U.S. lawmakers have called for '\n",
      " 'immediate action while others warn of stepping into what could become a '\n",
      " 'quagmire. Some global leaders have expressed support, but the British '\n",
      " \"Parliament\\\\'s vote against military action earlier this week was a blow to \"\n",
      " \"Obama\\\\'s hopes of getting strong backing from key NATO allies. On Saturday, \"\n",
      " 'Obama proposed what he said would be a limited military action against '\n",
      " 'Syrian President Bashar al-Assad. Any military attack would not be '\n",
      " \"open-ended or include U.S. ground forces, he said. Syria\\\\'s alleged use of \"\n",
      " 'chemical weapons earlier this month \"is an assault on human dignity,\" the '\n",
      " 'president said. A failure to respond with force, Obama argued,  \"could lead '\n",
      " 'to escalating use of chemical weapons or their proliferation to terrorist '\n",
      " 'groups who would do our people harm. In a world with many dangers, this '\n",
      " 'menace must be confronted.\" Syria missile strike: What would happen next? '\n",
      " 'Map: U.S. and allied assets around Syria . Obama decision came Friday night '\n",
      " '. On Friday night, the president made a last-minute decision to consult '\n",
      " \"lawmakers. What will happen if they vote no? It\\\\'s unclear. A senior \"\n",
      " 'administration official told CNN that Obama has the authority to act without '\n",
      " 'Congress -- even if Congress rejects his request for authorization to use '\n",
      " 'force. Obama on Saturday continued to shore up support for a strike on the '\n",
      " 'al-Assad government. He spoke by phone with French President Francois '\n",
      " 'Hollande before his Rose Garden speech. \"The two leaders agreed that the '\n",
      " 'international community must deliver a resolute message to the Assad regime '\n",
      " '-- and others who would consider using chemical weapons -- that these crimes '\n",
      " 'are unacceptable and those who violate this international norm will be held '\n",
      " 'accountable by the world,\" the White House said. Meanwhile, as uncertainty '\n",
      " 'loomed over how Congress would weigh in, U.S. military officials said they '\n",
      " 'remained at the ready. 5 key assertions: U.S. intelligence report on Syria . '\n",
      " 'Syria: Who wants what after chemical weapons horror . Reactions mixed to '\n",
      " \"Obama\\\\'s speech . A spokesman for the Syrian National Coalition said that \"\n",
      " 'the opposition group was disappointed by Obama\\\\\\'s announcement. \"Our fear '\n",
      " 'now is that the lack of action could embolden the regime and they repeat his '\n",
      " 'attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite '\n",
      " 'concerned.\" Some members of Congress applauded Obama\\\\\\'s decision. House '\n",
      " 'Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin '\n",
      " 'McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement '\n",
      " 'Saturday praising the president. \"Under the Constitution, the responsibility '\n",
      " 'to declare war lies with Congress,\" the Republican lawmakers said. \"We are '\n",
      " 'glad the president is seeking authorization for any military action in Syria '\n",
      " 'in response to serious, substantive questions being raised.\" More than 160 '\n",
      " \"legislators, including 63 of Obama\\\\'s fellow Democrats, had signed letters \"\n",
      " 'calling for either a vote or at least a \"full debate\" before any U.S. '\n",
      " 'action. British Prime Minister David Cameron, whose own attempt to get '\n",
      " 'lawmakers in his country to support military action in Syria failed earlier '\n",
      " 'this week, responded to Obama\\\\\\'s speech in a Twitter post Saturday. \"I '\n",
      " 'understand and support Barack Obama\\\\\\'s position on Syria,\" Cameron said. '\n",
      " 'An influential lawmaker in Russia -- which has stood by Syria and criticized '\n",
      " 'the United States -- had his own theory. \"The main reason Obama is turning '\n",
      " 'to the Congress:  the military operation did not get enough support either '\n",
      " 'in the world, among allies of the US or in the United States itself,\" Alexei '\n",
      " 'Pushkov, chairman of the international-affairs committee of the Russian '\n",
      " 'State Duma, said in a Twitter post. In the United States, scattered groups '\n",
      " 'of anti-war protesters around the country took to the streets Saturday. '\n",
      " '\"Like many other Americans...we\\\\\\'re just tired of the United States '\n",
      " 'getting involved and invading and bombing other countries,\" said Robin '\n",
      " 'Rosecrans, who was among hundreds at a Los Angeles demonstration. What do '\n",
      " \"Syria\\\\'s neighbors think? Why Russia, China, Iran stand by Assad . \"\n",
      " \"Syria\\\\'s government unfazed . After Obama\\\\'s speech, a military and \"\n",
      " 'political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia '\n",
      " 'opposes military action against Syria, is \"crying for help\" for someone to '\n",
      " 'come to his rescue and is facing two defeats -- on the political and '\n",
      " \"military levels. Syria\\\\'s prime minister appeared unfazed by the \"\n",
      " 'saber-rattling. \"The Syrian Army\\\\\\'s status is on maximum readiness and '\n",
      " 'fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi '\n",
      " 'said during a meeting with a delegation of Syrian expatriates from Italy, '\n",
      " 'according to a banner on Syria State TV that was broadcast prior to '\n",
      " \"Obama\\\\'s address. An anchor on Syrian state television said Obama \"\n",
      " '\"appeared to be preparing for an aggression on Syria based on repeated '\n",
      " 'lies.\" A top Syrian diplomat told the state television network that Obama '\n",
      " 'was facing pressure to take military action from Israel, Turkey, some Arabs '\n",
      " 'and right-wing extremists in the United States. \"I think he has done well by '\n",
      " 'doing what Cameron did in terms of taking the issue to Parliament,\" said '\n",
      " \"Bashar Jaafari, Syria\\\\'s ambassador to the United Nations. Both Obama and \"\n",
      " 'Cameron, he said, \"climbed to the top of the tree and don\\\\\\'t know how to '\n",
      " 'get down.\" The Syrian government has denied that it used chemical weapons in '\n",
      " 'the August 21 attack, saying that jihadists fighting with the rebels used '\n",
      " 'them in an effort to turn global sentiments against it. British intelligence '\n",
      " 'had put the number of people killed in the attack at more than 350. On '\n",
      " 'Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. '\n",
      " 'Secretary of State John Kerry on Friday cited a death toll of 1,429, more '\n",
      " 'than 400 of them children. No explanation was offered for the discrepancy. '\n",
      " \"Iran: U.S. military action in Syria would spark \\\\'disaster\\\\' Opinion: Why \"\n",
      " \"strikes in Syria are a bad idea .', 'summary': 'Syrian official: Obama \"\n",
      " 'climbed to the top of the tree, \"doesn\\\\\\'t know how to get down\"\\\\nObama '\n",
      " 'sends a letter to the heads of the House and Senate .\\\\nObama to seek '\n",
      " 'congressional approval on military action against Syria .\\\\nAim is to '\n",
      " \"determine whether CW were used, not by whom, says U.N. spokesman .'}\")\n"
     ]
    }
   ],
   "source": [
    "# Data is loaded using a generator to save on space and time\n",
    "\n",
    "data_instance = next(cnn_dataset.train_set)\n",
    "print(\"\\n\")\n",
    "pprint(data_instance.__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcO7hkZLYVlX"
   },
   "source": [
    "### A non-neural model\n",
    "Below we train an unsupervised non-neural summarizer with a subset of the cnn_dailymail dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo8ceRCEYVlY",
    "outputId": "631fb685-5763-4056-df36-9b9ff65d0d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming '\n",
      " \"his third gold in Moscow as he anchored Jamaica to victory in the men's \"\n",
      " '4x100m relay. The fastest man in the world charged clear of United States '\n",
      " 'rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar '\n",
      " 'Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished '\n",
      " 'second in 37.56 seconds with Canada taking the bronze after Britain were '\n",
      " 'disqualified for a faulty handover. The 26-year-old Bolt has now collected '\n",
      " 'eight gold medals at world championships, equaling the record held by '\n",
      " 'American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention '\n",
      " 'the small matter of six Olympic titles. The relay triumph followed '\n",
      " 'individual successes in the 100 and 200 meters in the Russian capital. \"I\\'m '\n",
      " \"proud of myself and I'll continue to work to dominate for as long as \"\n",
      " 'possible,\" Bolt said, having previously expressed his intention to carry on '\n",
      " 'until the 2016 Rio Olympics. Victory was never seriously in doubt once he '\n",
      " 'got the baton safely in hand from Ashmeade, while Gatlin and the United '\n",
      " 'States third leg runner Rakieem Salaam had problems. Gatlin strayed out of '\n",
      " 'his lane as he struggled to get full control of their baton and was never '\n",
      " \"able to get on terms with Bolt. Earlier, Jamaica's women underlined their \"\n",
      " 'dominance in the sprint events by winning the 4x100m relay gold, anchored by '\n",
      " 'Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their '\n",
      " 'quartet recorded a championship record of 41.29 seconds, well clear of '\n",
      " 'France, who crossed the line in second place in 42.73 seconds. Defending '\n",
      " 'champions, the United States, were initially back in the bronze medal '\n",
      " 'position after losing time on the second handover between Alexandria '\n",
      " 'Anderson and English Gardner, but promoted to silver when France were '\n",
      " 'subsequently disqualified for an illegal handover. The British quartet, who '\n",
      " \"were initially fourth, were promoted to the bronze which eluded their men's \"\n",
      " 'team. Fraser-Pryce, like Bolt aged 26, became the first woman to achieve '\n",
      " 'three golds in the 100-200 and the relay. In other final action on the last '\n",
      " \"day of the championships, France's Teddy Tamgho became the third man to leap \"\n",
      " 'over 18m in the triple jump, exceeding the mark by four centimeters to take '\n",
      " \"gold. Germany's Christina Obergfoll finally took gold at global level in the \"\n",
      " \"women's javelin after five previous silvers, while Kenya's Asbel Kiprop \"\n",
      " \"easily won a tactical men's 1500m final. Kiprop's compatriot Eunice Jepkoech \"\n",
      " \"Sum was a surprise winner of the women's 800m. Bolt's final dash for golden \"\n",
      " 'glory brought the eight-day championship to a rousing finale, but while the '\n",
      " 'hosts topped the medal table from the United States there was criticism of '\n",
      " 'the poor attendances in the Luzhniki Stadium. There was further concern when '\n",
      " 'their pole vault gold medalist Yelena Isinbayeva made controversial remarks '\n",
      " 'in support of Russia\\'s new laws, which make \"the propagandizing of '\n",
      " 'non-traditional sexual relations among minors\" a criminal offense. She later '\n",
      " 'attempted to clarify her comments, but there were renewed calls by gay '\n",
      " 'rights groups for a boycott of the 2014 Winter Games in Sochi, the next '\n",
      " 'major sports event in Russia.',\n",
      " 'Kansas City, Missouri (CNN) -- The General Services Administration, already '\n",
      " 'under investigation for lavish spending, allowed an employee to telecommute '\n",
      " \"from Hawaii even though he is based at the GSA's Kansas City, Missouri, \"\n",
      " 'office, a CNN investigation has found. It cost more than $24,000 for the '\n",
      " 'business development specialist to travel to and from the mainland United '\n",
      " 'States over the past year. He is among several hundred GSA \"virtual\" workers '\n",
      " 'who also travel to various conferences and their home offices, costing the '\n",
      " 'agency millions of dollars over the past three years. Under the program, '\n",
      " 'employees work from home and may live in another state from the region in '\n",
      " \"which they're actually assigned. The Kansas City employee, who started his \"\n",
      " 'job in January 2011, is paid $84,440 and works from his home in Honolulu, a '\n",
      " 'GSA representative confirmed. In the past year, according to GSA travel '\n",
      " 'records, the employee has flown back to the mainland nine times for '\n",
      " 'conferences and meetings. Four of those trips were to St. Louis; four were '\n",
      " 'to Washington, with a side trip to Cincinnati; and one was to San Diego. The '\n",
      " \"total cost to taxpayers was $24,221. Jason Klumb, the GSA's regional \"\n",
      " 'administrator for Kansas City, defended the hire. \"The cost of that travel '\n",
      " 'was included in the consideration of his candidacy as an employee as '\n",
      " 'compared with the other applicants,\" Klumb said. \"And when factoring all of '\n",
      " 'those in, it was determined that he was the best candidate, even in light of '\n",
      " 'the cost that would be incurred.\" Klumb called the GSA\\'s teleworking '\n",
      " 'program \"a successful program that\\'s going to lead to cost savings for '\n",
      " 'taxpayers.\" But a GSA spokeswoman said, \"We are not going to defend this '\n",
      " 'type of travel.\" And a GSA employee in Kansas City, who requested anonymity, '\n",
      " 'said that hiring someone in Hawaii to work for the Kansas City region was '\n",
      " 'ludicrous. \"It doesn\\'t make sense,\" the employee said. \"When you consider '\n",
      " 'everything you need when you hire someone, it would have been better to look '\n",
      " 'for someone in the Kansas City area. It would have reduced the cost of '\n",
      " 'travel by at least 70 percent when you look at just the airfare of what it '\n",
      " 'takes to from Honolulu to Washington, D.C., where a lot of business is '\n",
      " 'done.\" Dan Tangherlini, who was appointed acting GSA administrator this '\n",
      " 'year, said the agency was examining the cost of the entire teleworking '\n",
      " 'program. \"I think the most important part for the GSA to think about is make '\n",
      " 'sure we open ourselves up, avail ourselves to all the smart people in the '\n",
      " 'country, but then also make sure we have a clear business case,\" he said. '\n",
      " '\"If we have someone who is working in Nebraska but reporting to Boston, '\n",
      " \"there has to be a clear explanation for what value they're providing, and \"\n",
      " \"you've got to give me the business case. You've got to explain to me why \"\n",
      " \"that's a cost-effective move for the American people, and that's a new \"\n",
      " 'standard that we\\'re asking everyone at GSA to adhere to.\" The GSA \"virtual '\n",
      " 'employee\" program is different from telework programs offered by many '\n",
      " \"private companies including CNN's parent company, Turner Broadcasting, in \"\n",
      " 'which some employees are encouraged to work from home some days of the week, '\n",
      " 'partially to reduce traffic congestion. The House Committee on Oversight and '\n",
      " \"Government Reform requested details about the GSA's teleworking program in \"\n",
      " 'June. That followed disclosures that 95 virtual employees, including 12 in '\n",
      " 'supervisory positions, spent nearly $750,000 in travel costs between October '\n",
      " '2010 and June 2011. \"The American people have a right to know that federal '\n",
      " 'bureaucrats who enjoy the benefits of virtual work are eligible and '\n",
      " 'responsible stewards of the taxpayer dollars that support the program,\" '\n",
      " 'according to a letter from committee Chairman Rep. Darrell Issa, '\n",
      " 'R-California, to the GSA. The details requested by Issa about the GSA '\n",
      " 'program have not been provided to the committee. CNN also requested the '\n",
      " 'information more than two months ago through the federal Freedom of '\n",
      " 'Information Act but has been repeatedly told by the GSA that FOIA staff '\n",
      " 'members have not finished compiling the material. The General Services '\n",
      " 'Administration, which has more than 12,600 employees and a $26.3 billion '\n",
      " 'budget, is a relatively obscure federal agency that handles government real '\n",
      " 'estate and other non-military procurement. Congress launched an '\n",
      " \"investigation into the GSA after a scathing inspector general's report \"\n",
      " \"issued this year showed lavish spending -- $823,000 -- at the agency's \"\n",
      " 'Western Regions Conference in Las Vegas in October 2010. The controversy '\n",
      " 'became politically toxic after reports and video clips of the lavish '\n",
      " 'conference were released. The revelation prompted taxpayer indignation, '\n",
      " 'embarrassed the administration and put a spotlight on wasteful spending by '\n",
      " 'the GSA. Jeff Neely, the GSA official who organized the conference, '\n",
      " \"resigned, as did the agency's administrator, Martha Johnson. Two of \"\n",
      " \"Johnson's deputies were fired, and eight other employees left the agency. \"\n",
      " 'Tangherlini, a former Treasury Department official, took over as acting GSA '\n",
      " 'administrator. In addition to the Las Vegas conference, the GSA apparently '\n",
      " 'spent $330,000 to relocate an employee from Denver to Hawaii and probably '\n",
      " 'millions more on other employees over a two-year period, according to a '\n",
      " 'transcript of an interview with a GSA event planner. And 84 GSA employees, '\n",
      " 'most of them supervisors or other senior staff -- all subjects of inspector '\n",
      " 'general investigations -- are still collecting their bonuses, totaling more '\n",
      " 'than $1 million in taxpayer money. In July, a CNN investigation revealed '\n",
      " \"that the GSA's Kansas City office spent more than $20,000 to send employees \"\n",
      " 'to cooking classes to build team spirit. While the classes do not amount to '\n",
      " 'a significant sum of money in the world of trillion-dollar government '\n",
      " 'budgets, insiders said it was part of the free-spending culture that went on '\n",
      " \"for years at the GSA's Kansas City regional headquarters. GSA spokeswoman \"\n",
      " \"Betsaida Alcantara said in a statement this year that all the agency's \"\n",
      " \"practices are under a top-down review. CNN's Sara Anwar, Elizabeth M. Nunez \"\n",
      " 'and Tom Cohen contributed to this report. Watch Erin Burnett weekdays 7pm '\n",
      " 'ET. For the latest from Erin Burnett click here.',\n",
      " 'Los Angeles (CNN) -- A medical doctor in Vancouver, British Columbia, said '\n",
      " 'Thursday that California arson suspect Harry Burkhart suffered from severe '\n",
      " 'mental illness in 2010, when she examined him as part of a team of doctors. '\n",
      " 'Dr. Blaga Stancheva, a family physician and specialist in obstetrics, said '\n",
      " 'both Burkhart and his mother, Dorothee, were her patients in Vancouver while '\n",
      " 'both were applying for refugee status in Canada. \"I was asked to diagnose '\n",
      " 'and treat Harry to support a claim explaining why he was unable to show up '\n",
      " 'in a small-claims court case,\" Stancheva told CNN in a phone interview. She '\n",
      " \"declined to cite the case or Burkhart's role in it. Stancheva said she and \"\n",
      " 'other doctors including a psychiatrist diagnosed Burkhart with \"autism, '\n",
      " 'severe anxiety, post-traumatic stress disorder and depression.\" The '\n",
      " 'diagnosis was spelled out in a letter she wrote for the small-claims court '\n",
      " 'case, Stancheva said. Stancheva, citing doctor-patient confidentiality, '\n",
      " 'would not elaborate further, nor would she identify the psychiatrist '\n",
      " 'involved in the diagnosis. Burkhart, a 24-year-old German national, has been '\n",
      " 'charged with 37 counts of arson following a string of 52 fires in Los '\n",
      " 'Angeles. The charges are in connection with arson fires at 12 locations '\n",
      " 'scattered through Hollywood, West Hollywood and Sherman Oaks, according to '\n",
      " 'authorities. Stancheva said the refugee applications by Burkhart and his '\n",
      " 'mother were denied by the Canadian government, and she has not seen Burkhart '\n",
      " 'since early March of 2010. \"I was shocked and dismayed at what happened in '\n",
      " 'Los Angeles, and it appears he was not being treated for his depression,\" '\n",
      " 'she said. Burkhart was in court on Wednesday for a preliminary hearing. '\n",
      " 'Prosecutors said his \"rage against Americans,\" triggered by his mother\\'s '\n",
      " 'arrest last week, motivated his \"campaign of terror\" with dozens of fires in '\n",
      " 'Hollywood and nearby communities. Burkhart kept his eyes closed and remained '\n",
      " \"limp during most of his hearing, requiring sheriff's deputies to hold him \"\n",
      " 'up. The district attorney called his courtroom behavior \"very bizarre.\" '\n",
      " '\"This defendant has engaged in a protracted campaign in which he has set, '\n",
      " 'the people believe, upwards of 52 arson fires in what essentially amounts to '\n",
      " 'a campaign of terror against this community,\" Los Angeles County Deputy '\n",
      " 'District Attorney Sean Carney said. \"The people believe he has engaged in '\n",
      " 'this conduct because he has a hatred for Americans.\" Carney told the court '\n",
      " 'Burkhart would flee the country if he was allowed out of jail on bond, but '\n",
      " 'Los Angeles Superior Court Judge Upinder Kalra said he had no choice but to '\n",
      " 'set bail. To go free while awaiting trial, Burkhart must post a $2.85 '\n",
      " 'million bond and surrender his German passport. It was revealed that '\n",
      " 'Burkhart is also under investigation for arson and fraud in relation to a '\n",
      " 'fire in Neukirchen, near Frankfurt, Germany. The worst arson sprees in the '\n",
      " \"city's history began last Friday morning with a car fire in Hollywood that \"\n",
      " 'spread to apartments above a garage, but no new fires have happened since '\n",
      " 'Burkhart was arrested Monday, Los Angeles District Attorney Steve Cooley '\n",
      " 'said. No one was hurt in the fires, but property damage costs are likely to '\n",
      " 'reach $3 million, authorities said. Cooley called it \"almost attempted '\n",
      " 'murder,\" because people were sleeping in apartments above where Burkhart '\n",
      " 'allegedly set cars on fire with incendiary devices placed under their '\n",
      " 'engines. The criminal complaint filed Wednesday also alleged that the fires '\n",
      " 'were \"caused by use of a device designed to accelerate the fire,\" Cooley '\n",
      " 'said. \"If found true, the allegation could mean additional custody time for '\n",
      " 'the defendant.\" \"In numerous instances, the cars were parked in carports, '\n",
      " 'resulting in the fires spreading to the adjacent occupied apartment '\n",
      " 'buildings,\" a sworn affidavit from a Los Angeles arson investigator said. '\n",
      " '\"The vast majority of these fires occurred late at night when the occupants '\n",
      " 'of the apartment buildings were asleep.\" Investigator Edward Nordskog\\'s '\n",
      " \"affidavit detailed Burkhart's behavior a day before the fires began, when he \"\n",
      " 'was in a federal courtroom during extradition proceedings for his mother. '\n",
      " '\"While in the audience, the defendant (Burkhart) began yelling in an angry '\n",
      " \"manner, 'F--k all Americans.' The defendant also attempted to communicate \"\n",
      " 'with his mother who was in custody. Shortly thereafter, the defendant was '\n",
      " 'ejected from the courtroom by Deputy U.S. Marshals,\" Nordskog wrote. '\n",
      " 'Dorothee Burkhart was arrested a day before on an international arrest '\n",
      " 'warrant issued by a district court in Frankfurt, Germany, said federal court '\n",
      " 'spokesman Gunther Meilinger. The 53-year-old German woman is wanted on 16 '\n",
      " 'counts of fraud and three counts of embezzlement, he said. The charges '\n",
      " 'include an allegation that she failed to pay for a breast enhancement '\n",
      " 'operation performed on her in 2004, Meilinger said. Most of the German '\n",
      " 'charges, however, stem from phony real estate deals that Dorothee Burkhart '\n",
      " 'allegedly conducted between 2000 and 2006. \"It is my opinion that the '\n",
      " \"defendant's criminal spree was motivated by his rage against Americans and \"\n",
      " 'that by setting these fires the defendant intended to harm and terrorize as '\n",
      " 'many residents of the city and county of Los Angeles as possible,\" Nordskog '\n",
      " \"wrote. A search of Burkhart's Hollywood apartment found newspaper clippings \"\n",
      " 'about the Los Angeles fires and articles from Germany reporting similar car '\n",
      " 'fires in Frankfurt, Germany in September, 2011, the investigator said. \"It '\n",
      " 'is my opinion based on my experience that it is highly likely the defendant '\n",
      " 'has a history of setting arson fires in Germany before he came to the United '\n",
      " 'States,\" Nordskog wrote. Burkhart\\'s mother is scheduled for another '\n",
      " 'extradition hearing Friday, while he is due back in court for arraignment on '\n",
      " 'January 24. Meanwhile, both Burkharts are housed in a Los Angeles jail.',\n",
      " '(CNN) -- Police arrested another teen Thursday, the sixth suspect jailed in '\n",
      " 'connection with the gang rape of a 15-year-old girl on a northern California '\n",
      " 'high school campus. Jose Carlos Montano, 18, was arrested on charges of '\n",
      " 'felony rape, rape in concert with force, and penetration with a foreign '\n",
      " 'object, said Richmond Police Lt. Mark Gagan. Montano was arrested Thursday '\n",
      " 'evening in San Pablo, California, a small town about two miles from the city '\n",
      " 'of Richmond, where the crime took place. Montano, who was held in lieu of '\n",
      " '$1.3 million bail, is accused of taking part in what police said was a '\n",
      " '2½-hour assault on the Richmond High School campus. Police said as many as '\n",
      " '10 people were involved in the rape in a dimly lit back alley at the school, '\n",
      " 'while another 10 people watched without calling 911. The victim was taken to '\n",
      " 'the hospital in critical condition, but was released Wednesday. Four other '\n",
      " 'teenage suspects were arraigned Thursday on charges connected to the rape. '\n",
      " 'Cody Ray Smith, described by the court as older than 14, pleaded not guilty '\n",
      " 'to charges of rape with a foreign object and rape by force. Two other '\n",
      " 'juveniles, Ari Abdallah Morales and Marcelles James Peter, appeared with '\n",
      " 'Smith at the Contra Costa County Superior Court, but did not enter a plea. '\n",
      " 'The court described Morales as younger than 16, and did not give an age for '\n",
      " 'Peter. All three juveniles, who wore bulletproof vests at the hearing, were '\n",
      " 'charged as adults. A fourth person, Manuel Ortega, 19, appeared separately '\n",
      " 'without an attorney and did not enter a plea. He did not wear a protective '\n",
      " 'vest. Another person, Salvador Rodriguez, 21, was arrested Tuesday night, '\n",
      " 'but he was not in court Thursday.',\n",
      " '(CNN) -- Thousands on Saturday fled the area in southwestern Ivory Coast '\n",
      " 'where attacks left seven U.N. peacekeepers and eight civilians dead, '\n",
      " 'according to a U.N. official. One attack occurred late Thursday and into '\n",
      " \"Friday near Para Village, not far from the west-central African nation's \"\n",
      " 'border with Liberia, according to the United Nations. Humanitarian '\n",
      " 'organizations reported Saturday they were expecting about 4,000 people in '\n",
      " 'Tai, said Remi Dourlot, a spokesman for the U.N. Office for the Coordination '\n",
      " 'of Humanitarian Affairs. Several hundred had arrived by midday Saturday in '\n",
      " 'the town, which is on the edge of Tai National Park. Another 35 families '\n",
      " \"crossed the Ivory Coast's southwest border into U.N. refugee camps in \"\n",
      " 'Liberia, and humanitarian groups said hundreds of others had been pushed '\n",
      " 'south by the violence, according to Dourlot. The movement comes after '\n",
      " 'blue-helmeted peacekeepers -- who were in the area because of threats '\n",
      " 'against civilians -- came under attack, the United Nations said in a '\n",
      " 'statement. Besides the U.N. peacekeepers, humanitarian groups reported eight '\n",
      " 'civilians died in violence, said Dourlot. U.N. Secretary-General Ban Ki-moon '\n",
      " 'on Friday called on the government of Ivory Coast \"to do its utmost to '\n",
      " 'identify the perpetrators and hold them accountable.\" He added that he '\n",
      " 'understood other peacekeepers remained in danger. \"Even tonight, after the '\n",
      " 'attack, more than 40 peacekeepers remain with the villagers in this remote '\n",
      " 'region to protect them from this armed group,\" Ban said. U.N. Operation in '\n",
      " \"Cote d'Ivoire and Ivory Coast troops have increased their presence in the \"\n",
      " 'area, Dourlot said Saturday. Members of the U.N. humanitarian affairs office '\n",
      " 'have deployed to Tai to coordinate relief efforts there with local '\n",
      " 'authorities. Clinton urges Ivory Coast dialogue . A spokeswoman for the U.N. '\n",
      " \"mission in Ivory Coast said Friday's incident was the first attack on \"\n",
      " 'peacekeepers since they entered the country in 2004. Sylvie van den '\n",
      " 'Wildenberg, in a telephone interview from her office in Abidjan, said the '\n",
      " 'remaining forces were continuing to protect area residents, \"who are living '\n",
      " 'in a very difficult terrain -- their villages scattered.\" Van den Wildenberg '\n",
      " 'said it was not clear who was responsible for the attack, which occurred '\n",
      " 'mid-afternoon. \"This is an area where you have so many different types of '\n",
      " 'armed people,\" she said. \"People have different aims and different reasons '\n",
      " 'to carry arms and to perpetrate attack. So this is a very complex '\n",
      " 'environment. We can\\'t extrapolate. We just can\\'t fingerpoint any group.\" '\n",
      " 'The peacekeepers were on a reconnaissance patrol because U.N. officials had '\n",
      " 'heard rumors several days earlier of armed men in the area threatening to '\n",
      " 'attack a village, she said. U.N. peacekeepers remained in Ivory Coast after '\n",
      " 'the 2010 presidential election, when the country was thrown into crisis '\n",
      " 'after incumbent President Laurent Gbagbo refused to acknowledge defeat to '\n",
      " 'former Prime Minister Alassane Ouattara. The latter was sworn in on May 21. '\n",
      " 'Gbagbo is in custody at the Hague, accused of crimes against humanity during '\n",
      " 'post-election violence that killed thousands. According to the United '\n",
      " 'Nations, its peacekeeping force in Ivory Coast as of April 30 included '\n",
      " 'nearly 11,000 uniformed personnel, as well as several hundred international '\n",
      " 'civilian personnel, local staff and volunteers. They provide technical, '\n",
      " \"logistical and security support to the government. CNN's Christabelle Fombu \"\n",
      " 'and Tom Watkins contributed to this report.']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Get a slice of the train set - first 5 instances\n",
    "train_set = itertools.islice(cnn_dataset.train_set, 5)\n",
    "\n",
    "corpus = [instance.source for instance in train_set]\n",
    "pprint(corpus)\n",
    "\n",
    "trad_model = LexRankModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GtpYpvhYVla",
    "outputId": "ad7e8698-79a8-4c1f-f6eb-aa8f223b5be2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/11490 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. '\n",
      " 'Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. '\n",
      " 'He was 88. Best died in hospice in Hickory, North Carolina, of complications '\n",
      " 'from pneumonia, said Steve Latshaw, a longtime friend and Hollywood '\n",
      " \"colleague. Although he'd been a busy actor for decades in theater and in \"\n",
      " 'Hollywood, Best didn\\'t become famous until 1979, when \"The Dukes of '\n",
      " 'Hazzard\\'s\" cornpone charms began beaming into millions of American homes '\n",
      " \"almost every Friday night. For seven seasons, Best's Rosco P. Coltrane \"\n",
      " 'chased the moonshine-running Duke boys back and forth across the back roads '\n",
      " 'of fictitious Hazzard County, Georgia, although his \"hot pursuit\" usually '\n",
      " 'ended with him crashing his patrol car. Although Rosco was slow-witted and '\n",
      " 'corrupt, Best gave him a childlike enthusiasm that got laughs and made him '\n",
      " 'endearing. His character became known for his distinctive \"kew-kew-kew\" '\n",
      " 'chuckle and for goofy catchphrases such as \"cuff \\'em and stuff \\'em!\" upon '\n",
      " \"making an arrest. Among the most popular shows on TV in the early '80s, \"\n",
      " '\"The Dukes of Hazzard\" ran until 1985 and spawned TV movies, an animated '\n",
      " 'series and video games. Several of Best\\'s \"Hazzard\" co-stars paid tribute '\n",
      " 'to the late actor on social media. \"I laughed and learned more from Jimmie '\n",
      " 'in one hour than from anyone else in a whole year,\" co-star John Schneider, '\n",
      " 'who played Bo Duke, said on Twitter. \"Give Uncle Jesse my love when you see '\n",
      " 'him dear friend.\" \"Jimmy Best was the most constantly creative person I have '\n",
      " 'ever known,\" said Ben Jones, who played mechanic Cooter on the show, in a '\n",
      " 'Facebook post. \"Every minute of his long life was spent acting, writing, '\n",
      " \"producing, painting, teaching, fishing, or involved in another of his life's \"\n",
      " 'many passions.\" Born Jewel Guy on July 26, 1926, in Powderly, Kentucky, Best '\n",
      " 'was orphaned at 3 and adopted by Armen and Essa Best, who renamed him James '\n",
      " 'and raised him in rural Indiana. Best served in the Army during World War II '\n",
      " 'before launching his acting career. In the 1950s and 1960s, he accumulated '\n",
      " 'scores of credits, playing a range of colorful supporting characters in such '\n",
      " 'TV shows as \"The Twilight Zone,\" \"Bonanza,\" \"The Andy Griffith Show\" and '\n",
      " '\"Gunsmoke.\" He later appeared in a handful of Burt Reynolds\\' movies, '\n",
      " 'including \"Hooper\" and \"The End.\" But Best will always be best known for his '\n",
      " '\"Hazzard\" role, which lives on in reruns. \"Jimmie was my teacher, mentor, '\n",
      " 'close friend and collaborator for 26 years,\" Latshaw said. \"I directed two '\n",
      " \"of his feature films, including the recent 'Return of the Killer Shrews,' a \"\n",
      " 'sequel he co-wrote and was quite proud of as he had made the first one more '\n",
      " 'than 50 years earlier.\" People we\\'ve lost in 2015 . CNN\\'s Stella Chan '\n",
      " 'contributed to this story.']\n",
      "['(CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. '\n",
      " 'Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. '\n",
      " '\"Jimmie was my teacher, mentor, close friend and collaborator for 26 years,\" '\n",
      " 'Latshaw said.']\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "text = [next(cnn_dataset.test_set).source]\n",
    "pprint(text)\n",
    "\n",
    "summary = trad_model.summarize(text)\n",
    "pprint(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pc5yHLO_YVlb",
    "outputId": "e7af379f-1553-48f2-a39e-fba7b6987fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexRank is a extractive, non-neural model for summarization. \n",
      " #################### \n",
      " Works by using a graph-based method to identify the most salient sentences in the document. \n",
      "Strengths: \n",
      " - Fast with low memory usage \n",
      " - Allows for control of summary length \n",
      " Weaknesses: \n",
      " - Not as accurate as neural methods. \n",
      " Initialization arguments: \n",
      " - `corpus`: Unlabelled corpus of documents. ` \n",
      " - `summary_length`: sentence length of summaries \n",
      " - `threshold`: Level of salience required for sentence to be included in summary.\n"
     ]
    }
   ],
   "source": [
    "# More about lexrank\n",
    "\n",
    "trad_model.show_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjN2Mu_EYVlc"
   },
   "source": [
    "A spaCy pipeline for TextRank (another non-neueral extractive summarization model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ooX2BN4lYVld"
   },
   "outputs": [],
   "source": [
    "# TextRank model\n",
    "textrank = model.TextRankModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcGi-4Q1YVld",
    "outputId": "51579d49-c54a-4729-c703-65a9395a353b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"For seven seasons, Best's Rosco P. Coltrane chased the moonshine-running \"\n",
      " 'Duke boys back and forth across the back roads of fictitious Hazzard County, '\n",
      " 'Georgia, although his \"hot pursuit\" usually ended with him crashing his '\n",
      " 'patrol car.']\n"
     ]
    }
   ],
   "source": [
    "textrank_summary = textrank.summarize(text[0:1])\n",
    "pprint(textrank_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUj8ZWSvYVle",
    "outputId": "93337f28-5a52-456d-dfb0-7229cc444036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank is a extractive, non-neural model for summarization. \n",
      " #################### \n",
      " A graphbased ranking model for text processing. Extractive sentence summarization. \n",
      " Strengths: \n",
      " - Fast with low memory usage \n",
      " - Allows for control of summary length \n",
      " Weaknesses: \n",
      " - Not as accurate as neural methods.\n"
     ]
    }
   ],
   "source": [
    "# More about TextRank\n",
    "textrank.show_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2F-NQRyYVle",
    "outputId": "efaf1664-657d-4f07-87d0-63d1395ab33e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Longformer2Roberta\n",
    "longformer = model.LongformerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cic-cqNYVlg",
    "outputId": "61d6975a-9227-4675-de65-4bd222029dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('(CNN)James Holmes made his introduction to the world in a Colorado cinema '\n",
      " 'filled with spectators watching a midnight showing of the new Batman movie, '\n",
      " '\"The Dark Knight Rises,\" in June 2012. The moment became one of the '\n",
      " 'deadliest shootings in U.S. history. Holmes is accused of opening fire on '\n",
      " 'the crowd, killing 12 people and injuring or maiming 70 others in Aurora, a '\n",
      " 'suburb of Denver. Holmes appeared like a comic book character: He resembled '\n",
      " \"the Joker, with red-orange hair, similar to the late actor Heath Ledger's \"\n",
      " 'portrayal of the villain in an earlier Batman movie, authorities said. But '\n",
      " 'Holmes was hardly a cartoon. Authorities said he wore body armor and carried '\n",
      " 'several guns, including an AR-15 rifle, with lots of ammo. He also wore a '\n",
      " 'gas mask. Holmes says he was insane at the time of the shootings, and that '\n",
      " 'is his legal defense and court plea: not guilty by reason of insanity. '\n",
      " \"Prosecutors aren't swayed and will seek the death penalty. Opening \"\n",
      " 'statements in his trial are scheduled to begin Monday. Holmes admits to the '\n",
      " 'shootings but says he was suffering \"a psychotic episode\" at the time,  '\n",
      " 'according to court papers filed in July 2013 by the state public defenders, '\n",
      " 'Daniel King and Tamara A. Brady. Evidence \"revealed thus far in the case '\n",
      " \"supports the defense's position that Mr. Holmes suffers from a severe mental \"\n",
      " 'illness and was in the throes of a psychotic episode when he committed the '\n",
      " 'acts that resulted in the tragic loss of life and injuries sustained by '\n",
      " 'moviegoers on July 20, 2012,\" the public defenders wrote. Holmes no longer '\n",
      " 'looks like a dazed Joker, as he did in his first appearance before a judge '\n",
      " 'in 2012. He appeared dramatically different in January when jury selection '\n",
      " 'began for his trial: 9,000 potential jurors were summoned for duty, '\n",
      " \"described as one of the nation's largest jury calls. Holmes now has a \"\n",
      " 'cleaner look, with a mustache, button-down shirt and khaki pants. In '\n",
      " 'January, he had a beard and eyeglasses. If this new image sounds like one of '\n",
      " 'an academician, it may be because Holmes, now 27, once was one. Just before '\n",
      " 'the shooting, Holmes was a doctoral student in neuroscience, and he was '\n",
      " 'studying how the brain works, with his schooling funded by a U.S. government '\n",
      " 'grant. Yet for all his learning, Holmes apparently lacked the capacity to '\n",
      " 'command his own mind, according to the case against him. A jury will '\n",
      " \"ultimately decide Holmes' fate. That panel is made up of 12 jurors and 12 \"\n",
      " 'alternates. They are 19 women and five men, and almost all are white and '\n",
      " 'middle-aged. The trial could last until autumn. When jury summonses were '\n",
      " 'issued in January, each potential juror stood a 0.2% chance of being '\n",
      " 'selected, District Attorney George Brauchler told the final jury this month. '\n",
      " 'He described the approaching trial as \"four to five months of a horrible '\n",
      " 'roller coaster through the worst haunted house you can imagine.\" The jury '\n",
      " 'will have to render verdicts on each of the 165 counts against Holmes, '\n",
      " 'including murder and attempted murder charges. Meanwhile, victims and their '\n",
      " 'relatives are challenging all media outlets \"to stop the gratuitous use of '\n",
      " 'the name and likeness of mass killers, thereby depriving violent individuals '\n",
      " 'the media celebrity and media spotlight they so crave,\" the No Notoriety '\n",
      " 'group says. They are joined by victims from eight other mass shootings in '\n",
      " 'recent U.S. history. Raised in central coastal California and in San Diego, '\n",
      " 'James Eagan Holmes is the son of a mathematician father noted for his work '\n",
      " 'at the FICO firm that provides credit scores and a registered nurse mother, '\n",
      " 'according to the U-T San Diego newspaper. Holmes also has a sister, Chris, a '\n",
      " \"musician, who's five years younger, the newspaper said. His childhood \"\n",
      " 'classmates remember him as a clean-cut, bespectacled boy with an \"exemplary\" '\n",
      " 'character who \"never gave any trouble, and never got in trouble himself,\" '\n",
      " 'The Salinas Californian reported. His family then moved down the California '\n",
      " 'coast, where Holmes grew up in the San Diego-area neighborhood of Rancho '\n",
      " 'Peñasquitos, which a neighbor described as \"kind of like Mayberry,\" the San '\n",
      " 'Diego newspaper said. Holmes attended Westview High School, which says its '\n",
      " 'school district sits in \"a primarily middle- to upper-middle-income '\n",
      " 'residential community.\" There, Holmes ran cross-country, played soccer and '\n",
      " 'later worked at a biotechnology internship at the Salk Institute and Miramar '\n",
      " 'College, which attracts academically talented students. By then, his peers '\n",
      " 'described him as standoffish and a bit of a wiseacre, the San Diego '\n",
      " 'newspaper said. Holmes attended college fairly close to home, in a '\n",
      " 'neighboring area known as Southern California\\'s \"inland empire\" because '\n",
      " \"it's more than an hour's drive from the coast, in a warm, low-desert \"\n",
      " 'climate. He entered the University of California, Riverside, in 2006 as a '\n",
      " 'scholarship student. In 2008 he was a summer camp counselor for '\n",
      " 'disadvantaged children, age 7 to 14, at Camp Max Straus, run by Jewish Big '\n",
      " 'Brothers Big Sisters of Los Angeles. He graduated from UC Riverside in 2010 '\n",
      " \"with the highest honors and a bachelor's degree in neuroscience. \"\n",
      " '\"Academically, he was at the top of the top,\" Chancellor Timothy P. White '\n",
      " 'said. He seemed destined for even higher achievement. By 2011, he had '\n",
      " 'enrolled as a doctoral student in the neuroscience program at the University '\n",
      " 'of Colorado Anschutz Medical Campus in Aurora, the largest academic health '\n",
      " 'center in the Rocky Mountain region. The doctoral in neuroscience program '\n",
      " 'attended by Holmes focuses on how the brain works, with an emphasis on '\n",
      " 'processing of information, behavior, learning and memory. Holmes was one of '\n",
      " 'six pre-thesis Ph.D. students in the program who were awarded a neuroscience '\n",
      " 'training grant from the National Institutes of Health. The grant rewards '\n",
      " 'outstanding neuroscientists who will make major contributions to '\n",
      " 'neurobiology. A syllabus that listed Holmes as a student at the medical '\n",
      " 'school shows he was to have delivered a presentation about microRNA '\n",
      " 'biomarkers. But Holmes struggled, and his own mental health took an ominous '\n",
      " 'turn. In March 2012, he told a classmate he wanted to kill people, and that '\n",
      " 'he would do so \"when his life was over,\" court documents said. Holmes was '\n",
      " '\"denied access to the school after June 12, 2012, after he made threats to a '\n",
      " 'professor,\" according to court documents. About that time, Holmes was a '\n",
      " 'patient of University of Colorado psychiatrist Lynne Fenton. Fenton was so '\n",
      " \"concerned about Holmes' behavior that she mentioned it to her colleagues, \"\n",
      " 'saying he could be a danger to others, CNN affiliate KMGH-TV reported, '\n",
      " \"citing sources with knowledge of the investigation. Fenton's concerns \"\n",
      " 'surfaced in early June, sources told the Denver station. Holmes began to '\n",
      " 'fantasize about killing \"a lot of people\" in early June, nearly six weeks '\n",
      " 'before the shootings, the station reported, citing unidentified sources '\n",
      " \"familiar with the investigation. Holmes' psychiatrist contacted several \"\n",
      " 'members of a \"behavioral evaluation and threat assessment\" team to say '\n",
      " 'Holmes could be a danger to others, the station reported. At issue was '\n",
      " 'whether to order Holmes held for 72 hours to be evaluated by mental health '\n",
      " 'professionals, the station reported. \"Fenton made initial phone calls about '\n",
      " 'engaging the BETA team\" in \"the first 10 days\" of June, but it \"never came '\n",
      " 'together\" because in the period Fenton was having conversations with team '\n",
      " 'members, Holmes began the process of dropping out of school, a source told '\n",
      " \"KMGH. Defense attorneys have rejected the prosecution's assertions that \"\n",
      " 'Holmes was barred from campus. Citing statements from the university, '\n",
      " \"Holmes' attorneys have argued that his access was revoked because that's \"\n",
      " 'normal procedure when a student drops enrollment. What caused this turn for '\n",
      " 'the worse for Holmes has yet to be clearly detailed. In the months before '\n",
      " 'the shooting, he bought four weapons and more than 6,000 rounds of '\n",
      " 'ammunition, authorities said. Police said he also booby-trapped his '\n",
      " \"third-floor apartment with explosives, but police weren't fooled. After \"\n",
      " 'Holmes was caught in the cinema parking lot immediately after the shooting, '\n",
      " 'bomb technicians went to the apartment and neutralized the explosives. No '\n",
      " 'one was injured at the apartment building. Nine minutes before Holmes went '\n",
      " 'into the movie theater, he called a University of Colorado switchboard, '\n",
      " 'public defender Brady has said in court. The number he called can be used to '\n",
      " 'get in contact with faculty members during off hours, Brady said. Court '\n",
      " 'documents have also revealed that investigators have obtained text messages '\n",
      " 'that Holmes exchanged with someone before the shooting. That person was not '\n",
      " 'named, and the content of the texts has not been made public. According to '\n",
      " 'The New York Times, Holmes sent a text message to a fellow graduate student, '\n",
      " 'a woman, about two weeks before the shooting. She asked if he had left '\n",
      " \"Aurora yet, reported the newspaper, which didn't identify her. No, he had \"\n",
      " 'two months left on his lease, Holmes wrote back, according to the Times. He '\n",
      " 'asked if she had heard of \"dysphoric mania,\" a form of bipolar disorder '\n",
      " 'marked by the highs of mania and the dark and sometimes paranoid delusions '\n",
      " 'of major depression. The woman asked if the disorder could be managed with '\n",
      " 'treatment. \"It was,\" Holmes wrote her, according to the Times. But he warned '\n",
      " 'she should stay away from him \"because I am bad news,\" the newspaper '\n",
      " \"reported. It was her last contact with Holmes. After the shooting, Holmes' \"\n",
      " 'family issued a brief statement: \"Our hearts go out to those who were '\n",
      " 'involved in this tragedy and to the families and friends of those involved,\" '\n",
      " 'they said, without giving any information about their son. Since then, '\n",
      " 'prosecutors have refused to offer a plea deal to Holmes. For Holmes, '\n",
      " '\"justice is death,\" said Brauchler, the district attorney. In December, '\n",
      " \"Holmes' parents, who will be attending the trial, issued another statement: \"\n",
      " \"They asked that their son's life be spared and that he be sent to an \"\n",
      " \"institution for mentally ill people for the rest of his life, if he's found \"\n",
      " 'not guilty by reason of insanity. \"He is not a monster,\" Robert and Arlene '\n",
      " 'Holmes wrote, saying the death penalty is \"morally wrong, especially when '\n",
      " 'the condemned is mentally ill.\" \"He is a human being gripped by a severe '\n",
      " 'mental illness,\" the parents said. The matter will be settled by the jury. '\n",
      " \"CNN's Ana Cabrera and Sara Weisfeldt contributed to this report from Denver.\")\n"
     ]
    }
   ],
   "source": [
    "long_article = \"\"\"(CNN)James Holmes made his introduction to the world in a Colorado cinema filled with spectators watching a midnight showing of the new Batman movie, \"The Dark Knight Rises,\" in June 2012. The moment became one of the deadliest shootings in U.S. history. Holmes is accused of opening fire on the crowd, killing 12 people and injuring or maiming 70 others in Aurora, a suburb of Denver. Holmes appeared like a comic book character: He resembled the Joker, with red-orange hair, similar to the late actor Heath Ledger\\'s portrayal of the villain in an earlier Batman movie, authorities said. But Holmes was hardly a cartoon. Authorities said he wore body armor and carried several guns, including an AR-15 rifle, with lots of ammo. He also wore a gas mask. Holmes says he was insane at the time of the shootings, and that is his legal defense and court plea: not guilty by reason of insanity. Prosecutors aren\\'t swayed and will seek the death penalty. Opening statements in his trial are scheduled to begin Monday. Holmes admits to the shootings but says he was suffering \"a psychotic episode\" at the time,  according to court papers filed in July 2013 by the state public defenders, Daniel King and Tamara A. Brady. Evidence \"revealed thus far in the case supports the defense\\'s position that Mr. Holmes suffers from a severe mental illness and was in the throes of a psychotic episode when he committed the acts that resulted in the tragic loss of life and injuries sustained by moviegoers on July 20, 2012,\" the public defenders wrote. Holmes no longer looks like a dazed Joker, as he did in his first appearance before a judge in 2012. He appeared dramatically different in January when jury selection began for his trial: 9,000 potential jurors were summoned for duty, described as one of the nation\\'s largest jury calls. Holmes now has a cleaner look, with a mustache, button-down shirt and khaki pants. In January, he had a beard and eyeglasses. If this new image sounds like one of an academician, it may be because Holmes, now 27, once was one. Just before the shooting, Holmes was a doctoral student in neuroscience, and he was studying how the brain works, with his schooling funded by a U.S. government grant. Yet for all his learning, Holmes apparently lacked the capacity to command his own mind, according to the case against him. A jury will ultimately decide Holmes\\' fate. That panel is made up of 12 jurors and 12 alternates. They are 19 women and five men, and almost all are white and middle-aged. The trial could last until autumn. When jury summonses were issued in January, each potential juror stood a 0.2% chance of being selected, District Attorney George Brauchler told the final jury this month. He described the approaching trial as \"four to five months of a horrible roller coaster through the worst haunted house you can imagine.\" The jury will have to render verdicts on each of the 165 counts against Holmes, including murder and attempted murder charges. Meanwhile, victims and their relatives are challenging all media outlets \"to stop the gratuitous use of the name and likeness of mass killers, thereby depriving violent individuals the media celebrity and media spotlight they so crave,\" the No Notoriety group says. They are joined by victims from eight other mass shootings in recent U.S. history. Raised in central coastal California and in San Diego, James Eagan Holmes is the son of a mathematician father noted for his work at the FICO firm that provides credit scores and a registered nurse mother, according to the U-T San Diego newspaper. Holmes also has a sister, Chris, a musician, who\\'s five years younger, the newspaper said. His childhood classmates remember him as a clean-cut, bespectacled boy with an \"exemplary\" character who \"never gave any trouble, and never got in trouble himself,\" The Salinas Californian reported. His family then moved down the California coast, where Holmes grew up in the San Diego-area neighborhood of Rancho Peñasquitos, which a neighbor described as \"kind of like Mayberry,\" the San Diego newspaper said. Holmes attended Westview High School, which says its school district sits in \"a primarily middle- to upper-middle-income residential community.\" There, Holmes ran cross-country, played soccer and later worked at a biotechnology internship at the Salk Institute and Miramar College, which attracts academically talented students. By then, his peers described him as standoffish and a bit of a wiseacre, the San Diego newspaper said. Holmes attended college fairly close to home, in a neighboring area known as Southern California\\'s \"inland empire\" because it\\'s more than an hour\\'s drive from the coast, in a warm, low-desert climate. He entered the University of California, Riverside, in 2006 as a scholarship student. In 2008 he was a summer camp counselor for disadvantaged children, age 7 to 14, at Camp Max Straus, run by Jewish Big Brothers Big Sisters of Los Angeles. He graduated from UC Riverside in 2010 with the highest honors and a bachelor\\'s degree in neuroscience. \"Academically, he was at the top of the top,\" Chancellor Timothy P. White said. He seemed destined for even higher achievement. By 2011, he had enrolled as a doctoral student in the neuroscience program at the University of Colorado Anschutz Medical Campus in Aurora, the largest academic health center in the Rocky Mountain region. The doctoral in neuroscience program attended by Holmes focuses on how the brain works, with an emphasis on processing of information, behavior, learning and memory. Holmes was one of six pre-thesis Ph.D. students in the program who were awarded a neuroscience training grant from the National Institutes of Health. The grant rewards outstanding neuroscientists who will make major contributions to neurobiology. A syllabus that listed Holmes as a student at the medical school shows he was to have delivered a presentation about microRNA biomarkers. But Holmes struggled, and his own mental health took an ominous turn. In March 2012, he told a classmate he wanted to kill people, and that he would do so \"when his life was over,\" court documents said. Holmes was \"denied access to the school after June 12, 2012, after he made threats to a professor,\" according to court documents. About that time, Holmes was a patient of University of Colorado psychiatrist Lynne Fenton. Fenton was so concerned about Holmes\\' behavior that she mentioned it to her colleagues, saying he could be a danger to others, CNN affiliate KMGH-TV reported, citing sources with knowledge of the investigation. Fenton\\'s concerns surfaced in early June, sources told the Denver station. Holmes began to fantasize about killing \"a lot of people\" in early June, nearly six weeks before the shootings, the station reported, citing unidentified sources familiar with the investigation. Holmes\\' psychiatrist contacted several members of a \"behavioral evaluation and threat assessment\" team to say Holmes could be a danger to others, the station reported. At issue was whether to order Holmes held for 72 hours to be evaluated by mental health professionals, the station reported. \"Fenton made initial phone calls about engaging the BETA team\" in \"the first 10 days\" of June, but it \"never came together\" because in the period Fenton was having conversations with team members, Holmes began the process of dropping out of school, a source told KMGH. Defense attorneys have rejected the prosecution\\'s assertions that Holmes was barred from campus. Citing statements from the university, Holmes\\' attorneys have argued that his access was revoked because that\\'s normal procedure when a student drops enrollment. What caused this turn for the worse for Holmes has yet to be clearly detailed. In the months before the shooting, he bought four weapons and more than 6,000 rounds of ammunition, authorities said. Police said he also booby-trapped his third-floor apartment with explosives, but police weren\\'t fooled. After Holmes was caught in the cinema parking lot immediately after the shooting, bomb technicians went to the apartment and neutralized the explosives. No one was injured at the apartment building. Nine minutes before Holmes went into the movie theater, he called a University of Colorado switchboard, public defender Brady has said in court. The number he called can be used to get in contact with faculty members during off hours, Brady said. Court documents have also revealed that investigators have obtained text messages that Holmes exchanged with someone before the shooting. That person was not named, and the content of the texts has not been made public. According to The New York Times, Holmes sent a text message to a fellow graduate student, a woman, about two weeks before the shooting. She asked if he had left Aurora yet, reported the newspaper, which didn\\'t identify her. No, he had two months left on his lease, Holmes wrote back, according to the Times. He asked if she had heard of \"dysphoric mania,\" a form of bipolar disorder marked by the highs of mania and the dark and sometimes paranoid delusions of major depression. The woman asked if the disorder could be managed with treatment. \"It was,\" Holmes wrote her, according to the Times. But he warned she should stay away from him \"because I am bad news,\" the newspaper reported. It was her last contact with Holmes. After the shooting, Holmes\\' family issued a brief statement: \"Our hearts go out to those who were involved in this tragedy and to the families and friends of those involved,\" they said, without giving any information about their son. Since then, prosecutors have refused to offer a plea deal to Holmes. For Holmes, \"justice is death,\" said Brauchler, the district attorney. In December, Holmes\\' parents, who will be attending the trial, issued another statement: They asked that their son\\'s life be spared and that he be sent to an institution for mentally ill people for the rest of his life, if he\\'s found not guilty by reason of insanity. \"He is not a monster,\" Robert and Arlene Holmes wrote, saying the death penalty is \"morally wrong, especially when the condemned is mentally ill.\" \"He is a human being gripped by a severe mental illness,\" the parents said. The matter will be settled by the jury. CNN\\'s Ana Cabrera and Sara Weisfeldt contributed to this report from Denver.\"\"\"\n",
    "pprint(long_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAJ8e7-XYVlv",
    "outputId": "83a63c8d-da6c-4d96-b70a-f23ed3ad14e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer model: processing document of tensor([2124]) tokens\n",
      "['James Holmes, 27, is accused of opening fire on a Colorado theater.\\n'\n",
      " 'He was a doctoral student at University of Colorado.\\n'\n",
      " 'Holmes says he was suffering \"a psychotic episode\" at the time of the '\n",
      " 'shooting.\\n'\n",
      " \"Prosecutors won't say whether Holmes was barred from campus.\"]\n"
     ]
    }
   ],
   "source": [
    "longformer_summary = longformer.summarize([long_article])\n",
    "pprint(longformer_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqTNO7N7YVl1",
    "outputId": "f8e07d5d-43f7-4098-e42e-206ae03f0b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer is a abstractive, neural model for summarization. \n",
      " #################### \n",
      " A Longformer2Roberta model finetuned on CNN-DM dataset for summarization.\n",
      "\n",
      "Strengths:\n",
      " - Correctly handles longer (> 2000 tokens) corpus.\n",
      "\n",
      "Weaknesses:\n",
      " - Less accurate on contexts outside training domain.\n",
      "\n",
      "Initialization arguments:\n",
      "  - `corpus`: Unlabelled corpus of documents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "longformer.show_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9g4Qp0rbYVl2"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXy0c_G0Fpvd"
   },
   "source": [
    "### Supported Evalutaionmetrics\n",
    "\n",
    "SummerTime supports different evaluation metrics (*e.g.,* ROUGE, Bleu, BertScore, Meteor, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4aURKURFpvv",
    "outputId": "53a8430b-e7e7-4534-d21c-ada7623788c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'evaluation.bertscore_metric.BertScore'>,\n",
      " <class 'evaluation.bleu_metric.Bleu'>,\n",
      " <class 'evaluation.rouge_metric.Rouge'>,\n",
      " <class 'evaluation.rougewe_metric.RougeWe'>,\n",
      " <class 'evaluation.meteor_metric.Meteor'>]\n"
     ]
    }
   ],
   "source": [
    "from evaluation import SUPPORTED_EVALUATION_METRICS\n",
    "\n",
    "pprint(SUPPORTED_EVALUATION_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPld2tGiYVl2",
    "outputId": "8b8204bc-f588-4475-dc58-bc486514f215"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/287113 [00:55<740:45:34,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<dataset.st_dataset.SummInstance object at 0x7f8f3fc39820>,\n",
      " <dataset.st_dataset.SummInstance object at 0x7f90901aec40>,\n",
      " <dataset.st_dataset.SummInstance object at 0x7f8f3fc398b0>,\n",
      " <dataset.st_dataset.SummInstance object at 0x7f8f3fc39880>,\n",
      " <dataset.st_dataset.SummInstance object at 0x7f8f3fc397c0>]\n"
     ]
    }
   ],
   "source": [
    "from evaluation.base_metric import SummMetric\n",
    "from evaluation import Rouge, RougeWe, BertScore\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Initializes a bertscore metric object\n",
    "metric = BertScore()\n",
    "\n",
    "# Evaluates model on subset of cnn_dailymail\n",
    "# Get a slice of the train set - first 5 instances\n",
    "train_set = itertools.islice(cnn_dataset.train_set, 5)\n",
    "\n",
    "corpus = [instance for instance in train_set]\n",
    "pprint(corpus)\n",
    "\n",
    "articles = [instance.source for instance in corpus]\n",
    "\n",
    "summaries = sample_model.summarize(articles)\n",
    "targets = [instance.summary for instance in corpus]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2_E1kG8zRPHp",
    "outputId": "bbef0b57-15be-4618-9958-323bd7d3379e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge_we_3_f': 0.20183811597317614}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BertScore\n",
    "metric = RougeWe()\n",
    "metric.evaluate(summaries, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5--0--qinJvp"
   },
   "source": [
    "## More Model and dataset tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells below demonstrate the features of the SummerTime library more comprehensively. They are a slightly modified version of our unit tests that applies different models on all the datasets and evaluates the results on each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/nightly/cu111/torch_nightly.html\n",
      "Requirement already satisfied: torch in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (1.10.0.dev20210820+cu111)\n",
      "Requirement already satisfied: torchvision in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (0.9.1)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu111/torchvision-0.11.0.dev20210820%2Bcu111-cp38-cp38-linux_x86_64.whl (21.4 MB)\n",
      "Requirement already satisfied: torchaudio in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (0.8.1)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/nightly/torchaudio-0.10.0.dev20210820-cp38-cp38-linux_x86_64.whl (2.0 MB)\n",
      "Requirement already satisfied: typing-extensions in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from torchvision) (8.3.1)\n",
      "Requirement already satisfied: numpy in /data/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages (from torchvision) (1.21.2)\n",
      "Installing collected packages: torchvision, torchaudio\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.9.1\n",
      "    Uninstalling torchvision-0.9.1:\n",
      "      Successfully uninstalled torchvision-0.9.1\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 0.8.1\n",
      "    Uninstalling torchaudio-0.8.1:\n",
      "      Successfully uninstalled torchaudio-0.8.1\n",
      "Successfully installed torchaudio-0.10.0.dev20210820 torchvision-0.11.0.dev20210820+cu111\n"
     ]
    }
   ],
   "source": [
    "## Uncomment if using Ziva Server\n",
    "## Installs the pytorch version compatible with the CUDA version\n",
    "\n",
    "# !pip install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cu111/torch_nightly.html -U\n",
    "# !pip install tensorboard\n",
    "    \n",
    "    \n",
    "## You might need to restart runtime for the changes to take effect\n",
    "## Uncomment the two lines below to restart runtime \n",
    "\n",
    "# import os\n",
    "# os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Run to check for successful Torch and Cuda compatibility\n",
    "\n",
    "# import torch\n",
    "# import sys\n",
    "\n",
    "# print('A', sys.version)\n",
    "# print('B', torch.__version__)\n",
    "# print('C', torch.cuda.is_available())\n",
    "# print('D', torch.backends.cudnn.enabled)\n",
    "# device = torch.device('cuda')\n",
    "# print('E', torch.cuda.get_device_properties(device))\n",
    "# print('F', torch.tensor([1.0, 2.0]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9djoq_btRfrk",
    "outputId": "2c6362cb-39a0-429f-8293-1a07195923b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "Initializing all evaluation metrics...\u001b[0m\n",
      "<class 'evaluation.bertscore_metric.BertScore'>\n",
      "<class 'evaluation.bleu_metric.Bleu'>\n",
      "<class 'evaluation.rouge_metric.Rouge'>\n",
      "<class 'evaluation.rougewe_metric.RougeWe'>\n",
      "<class 'evaluation.meteor_metric.Meteor'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "\n",
      "Beginning integration tests...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/lily/mmm274/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "100%|██████████| 287113/287113 [00:44<00:00, 6521.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cnn_dailymail has a training set of 287113 examples\n",
      "\u001b[35mInitializing all matching model pipelines for cnn_dailymail dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/lily/mmm274/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "  0%|          | 0/287113 [00:00<?, ?it/s]/home/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages/transformers/configuration_utils.py:403: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\n",
      "You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages/spacy/util.py:1176: ResourceWarning: unclosed file <_io.BufferedReader name='/home/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages/en_core_web_sm/en_core_web_sm-3.0.0/tok2vec/model'>\n",
      "  reader(path / key)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages/spacy/util.py:1176: ResourceWarning: unclosed file <_io.BufferedReader name='/home/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages/en_core_web_sm/en_core_web_sm-3.0.0/tagger/model'>\n",
      "  reader(path / key)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages/spacy/util.py:1176: ResourceWarning: unclosed file <_io.BufferedReader name='/home/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages/en_core_web_sm/en_core_web_sm-3.0.0/senter/model'>\n",
      "  reader(path / key)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "  0%|          | 99/287113 [01:26<69:35:30,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: cnn_dailymail dataset, BART model ####################\u001b[0m\n",
      "Prediction: [\"Denver police showed up last week at Maryjane's Social Club, one of dozens of private pot-smoking clubs in Colorado. The officers handcuffed smokers, seized drug paraphernalia and ticketed the club's owner for violating state law banning indoor cigarette smoking. Three people were cited for smoking in public. Colorado law prohibits recreational pot consumption 'openly and publicly or in a manner that endangers others'\"]\n",
      "Target: [\"Maryjane's Social Club is one of dozens of private pot-smoking clubs in Colorado operating in a legal grey area .\\nThree people were cited by police for smoking in public and club owner was ticketed .\\nColorado law prohibits recreational pot consumption 'openly and publicly or in a manner that endangers others'\\nPlainclothed police officers were posing as new members at the club .\"]\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.7640960812568665}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 47.29107189792839}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.71318, 'rouge_2_f_score': 0.53544, 'rouge_l_f_score': 0.66667}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.624}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.630454478175488}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, BART model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: cnn_dailymail dataset, LexRank model ####################\u001b[0m\n",
      "Prediction: [\"A wide-spread rumor that retired baseball all-star Kevin Mitchell decapitated his girlfriend's cat has been further substantiated after ex-Mets teammate Darryl Strawberry confirmed the incident. Former Mets player Kevin Mitchell decapitated his girlfriend's cat, according to urban legend.\"]\n",
      "Target: ['The rumor started in 1999, when formers Mets pitcher Doc Gooden talked about witnessing the horrifying incident in his autobiography .\\nMitchell went on to refute the claims, saying Gooden made the story up .\\nHowever, former teammate and friend Darryl Strawberry said the incident happened, in an interview he gave while promoting a new book .']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5627058148384094}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.0878383018024818}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.24742, 'rouge_2_f_score': 0.06316, 'rouge_l_f_score': 0.20619}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.17204301075268819}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.1849241158451685}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, LexRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: cnn_dailymail dataset, Longformer model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([263]) tokens\n",
      "Prediction: [\"NEW: The death toll has risen to 110, Pakistan's prime minister's office says.\\nThe flooding has also destroyed 650 homes, officials say.\\nFloods have also hit the Indian-administered Kashmir region.\\nPakistan's prime ministers are meeting Saturday to discuss the situation.\"]\n",
      "Target: ['Flooding caused by monsoon rains has destroyed 650 homes, officials say .\\nThe Pakistani Prime Minister will attend a meeting on the floods Saturday .\\nIndia has also been hit by flooding, which has killed at least 70 people there .']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6850147247314453}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 16.324435637424997}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.41463, 'rouge_2_f_score': 0.175, 'rouge_l_f_score': 0.39024}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.2820512820512821}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.3291511705166151}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, Longformer model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: cnn_dailymail dataset, Pegasus model ####################\u001b[0m\n",
      "Prediction: ['A gunman who killed a security officer and wounded a deputy marshal at a Las Vegas courthouse was killed in a shootout with police, authorities said.']\n",
      "Target: ['NEW: Suspect Johnny Wicks had a lengthy rap sheet .\\nWicks was shot and killed after opening fire in courthouse lobby .\\nSlain guard identified as former Vegas police officer .\\nFBI: Wicks pulled shotgun from underneath his jacket and began shooting .']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5390781760215759}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.2939497943016989}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.27692, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.21539}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.0}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.1624548736462094}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, Pegasus model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: cnn_dailymail dataset, TextRank model ####################\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lily/mmm274/anaconda3/envs/summernotebook/lib/python3.8/site-packages/networkx/algorithms/link_analysis/pagerank_alg.py:107: DeprecationWarning: networkx.pagerank_scipy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
      "  return pagerank_scipy(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: ['Kelley reportedly met Adam Victor at the Republican National Convention in Tampa.']\n",
      "Target: ['Jill Kelley tried to broker deal with energy mogul Adam Victor .\\nDeal collapsed when Kelley demanded $80million commission .\\nKelley and twin Natalie Khawam visited White House three times in three months as guests of aide they met at MacDill Air Force Base .']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.504211962223053}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.6674716951409333}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.22223, 'rouge_2_f_score': 0.03846, 'rouge_l_f_score': 0.18519}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.12}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.2786855482933915}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, TextRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset multi_news (/home/lily/mmm274/.cache/huggingface/datasets/multi_news/default/1.0.0/2e145a8e21361ba4ee46fef70640ab946a3e8d425002f104d2cda99a9efca376)\n",
      "100%|██████████| 44972/44972 [00:09<00:00, 4552.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "multi_news has a training set of 44972 examples\n",
      "\u001b[35mInitializing all matching model pipelines for multi_news dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset multi_news (/home/lily/mmm274/.cache/huggingface/datasets/multi_news/default/1.0.0/2e145a8e21361ba4ee46fef70640ab946a3e8d425002f104d2cda99a9efca376)\n",
      "  0%|          | 0/44972 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 100/44972 [01:05<8:06:17,  1.54it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 200/44972 [02:12<8:11:38,  1.52it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  1%|          | 299/44972 [02:59<7:26:05,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (BART) model ####################\u001b[0m\n",
      "Prediction: ['The big question today is whether Boehner’s bill passes in the House. If it passes the House, then it will simply fail in the Senate. The final bill will not pass through the House on a party-line vote. It will be a compromise proposal, and Boehner will lose far more than 23.']\n",
      "Target: ['– Let the endgame begin: House Republicans say a vote on John Boehner\\'s debt plan will still take place tonight, but the House speaker is apparently having trouble rounding up the necessary votes. Boehner predicted victory earlier today, but he halted debate on the measure about 5pm, reports Politico. Assuming he eventually gets to 217, Harry Reid continues to insist the Boehner plan will die a quick death in the Senate, after which Reid would try to force a vote on his own plan. (Eric Cantor is already threatening Reid with being responsible for a default, notes the Hill.) All of which suggests some last-minute scrambling will be going on through the weekend. \"The smart money in Washington continues to be on some hybrid of the Boehner/Reid/McConnell plans,\" writes Ezra Klein in the Washington Post. \"We’re looking at deal with no new revenue, significant new spending cuts, a spending-cut based enforcement mechanism for further deficit reduction, a series of debt-ceiling votes designed to embarrass Democrats, and a vote on a balanced budget amendment that’s also designed to embarrass Democrats.\"']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.539466917514801}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.43749764704832433}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.21666, 'rouge_2_f_score': 0.06722, 'rouge_l_f_score': 0.14999}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.16101694915254236}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.20092735703245748}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (BART) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (LexRank) model ####################\u001b[0m\n",
      "Prediction: ['PTC research has found a staggering increase in the frequency and explicitness of pixelated nudity on the broadcast networks during primetime hours. PTC found a 407% increase in the amount of full nudity that aired in the 2011–2012 study period compared to the same time period the previous year.']\n",
      "Target: ['– TV has gotten a whole lot racier, according to a report by the Parents Television Council. It found that instances of full-frontal nudity jumped 6,300% last year, from just one instance in the 2010-2011 television season to 64 last year. \"Full nudity\" also ratcheted up 407%, to 76 instances from 15. The council reviewed programming on ABC, NBC, CBS, Fox, and the CW. Among its other findings: Nudity comes earlier in the evening now (as early as 7pm) Most instances of nudity did not get the \"S\" warning for adult content Use of pixilation to cover nudity jumped from two instances to 56, but a rep for the council wasn\\'t impressed. \"The impact is virtually the same,\" she tells the New York Post. \"Just as bleeping an F-word is virtually the same as airing the actual word.\" Click for examples the council uncovered.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5224172472953796}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.3663558555037193}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.26263, 'rouge_2_f_score': 0.05102, 'rouge_l_f_score': 0.16162}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.18556701030927833}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.22222222222222224}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (LexRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (Longformer) model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([3027]) tokens\n",
      "Prediction: ['Joe Donnelly concedes, says he will do everything he can to ensure a smooth transition.\\nGOP retained control of the Senate on Tuesday.\\nRepublicans stood a solid chance of winning the House from Republicans.\\nDemocrats stood a strong chance of gaining control of Texas.\\nRepublican Rep. Marsha Blackburn defeated former Gov. Phil Bredesen.']\n",
      "Target: [\"– Republicans will keep control of the Senate for at least another two years—both CNN and the AP have called it. The GOP went into Tuesday's midterms with a 51-49 advantage, and the party appears to be on track to actually increase that margin. The bad news began early for Democrats when they lost a key race in Indiana: GOP businessman Mike Braun defeated incumbent Joe Donnelly, who had been seen as one of the most vulnerable Senate Democrats, reports ABC News. Democrats also lost another seat in North Dakota and failed to flip a vulnerable one in Tennessee. Meanwhile, the GOP's Ted Cruz won in Texas, while the race in Florida was too close to call. Notable if unsurprising winners elsewhere included Republican Mitt Romney in Utah and Democratic incumbent Tim Kaine in Virginia. More details: Missouri. Republican Josh Hawley defeated Democratic Sen. Claire McCaskill by a 55-42 margin, the St. Louis Post-Dispatch reports. Tennessee: Republican Marsha Blackburn will keep the seat in GOP hands. She defeated Democrat Phil Bredesen to replace the retiring Bob Corker, a Republican, reports the Hill. Florida: Democratic Sen. Bill Nelson vs. Republican Rick Scott. This is shaping up to be a nail-biter based on partial returns. North Dakota: Democratic Sen. Heidi Heitkamp lost her seat to Republican challenger Kevin Cramer. New Jersey: Democratic Sen. Robert Menendez defeated Republican Bob Hugin, per the AP. West Virginia: Democratic Sen. Joe Manchin defeated Republican Patrick Morrisey, reports CNN. Nevada. Incumbent GOP Sen. Dean Heller was defeated by Democrat Jacky Rosen. Closely watched races in Arizona and Montana are still outstanding.\"]\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5596679449081421}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.13273388315821794}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.161, 'rouge_2_f_score': 0.03738, 'rouge_l_f_score': 0.14242}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.09404388714733544}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.20602429149797571}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (Longformer) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (Pegasus) model ####################\u001b[0m\n",
      "Prediction: ['A member of the Bush family may have let a family secret slip. Barbara Bush has only 4 toes on each foot, her claims Chatting with Kathie Lee Gifford, Jenna Bush Hager may have let a family secret slip: She claims her grandmother, former first lady Barbara Bush, has only four toes on each']\n",
      "Target: ['– If someone were to ever put together a biography on former first lady Barbara Bush entitled Everything You Never Knew (and Didn\\'t Necessarily Want to Know) About Barbara Bush, it would now have to include a rather odd factoid supplied by her own granddaughter. The Hill reports that Jenna Bush Hager, one of George W. Bush\\'s twin daughters, appeared on the Today show Monday, and she shared a bit of info about her grandmother\\'s anatomy. \"Do you want to know the truth? My grandma\\'s missing a toe on each foot,\" Bush Hager told Kathie Lee Gifford during, naturally, a conversation about whether to take one\\'s shoes off when visiting other people\\'s homes. \"Has she ever divulged that?\" Gifford asked, to which Bush Hager replied, \"Not that I know of,\" adding the 91-year-old Bush\\'s feet are \"darling\" and \"cute,\" despite only sporting eight balancing digits. Bush Hager also offered up a rather strange scientific explanation that may have every human being running to Google: that \"they\" say, as you age, if you don\\'t get enough sleep, your toes \"go away.\" (Bush Hager\\'s January message to the Obama girls probably didn\\'t mention anyone\\'s toes.)']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5197173357009888}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.9384587654882653}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.26254, 'rouge_2_f_score': 0.10895, 'rouge_l_f_score': 0.13899}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.1803921568627451}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.35062580553209943}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (Pegasus) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (TextRank) model ####################\u001b[0m\n",
      "Prediction: ['More simply, it could have been an iron lacking diet,\" anthropologist Elena Dellù told Discovery News.']\n",
      "Target: ['– A 13-year-old girl apparently died peacefully, but the recent discovery of her undated remains in Italy is raising eyebrows. She was buried face-down—a sign that the person was in some way feared or rejected—and she\\'s being dubbed the \"witch girl\" as a result. \"The prone burial was linked to the belief that the soul left the body through the mouth,\" explains one anthropologist. \"Burying the dead face-down was a way to prevent the impure soul threatening the living.\" Stranger still, the apparently ostracized girl, who appears to have suffered from severe anemia that could have resulted in fainting spells or hemorrhagic conditions, was found in a privileged area in front of a church, reports Discovery News. \"This makes the finding even more unusual,\" excavation director Stefano Roascio tells Discovery. Archaeologists know of one other such case, a teen boy whose belongings and grave placement suggest high social status in spite of his apparent punishment. The oldest downward-facing skeleton dates back 26,000 years to the Czech Republic, adds the International Business Times, and the most recent to the early 20th century. Other unorthodox burials include staking bodies to the ground, stuffing bricks in mouths, and even more horrifyingly, burying living people face-down. (Of course, some are buried alive by accident, as happened just this summer at a sugar plant in Pennsylvania.)']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.43550240993499756}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 7.574213379888901e-05}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.04879, 'rouge_2_f_score': 0.01639, 'rouge_l_f_score': 0.03252}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.024793388429752063}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.12219178082191783}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (TextRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (BART) model ####################\u001b[0m\n",
      "Prediction: ['Few of King\\'s speeches are available to the public because of copyright restrictions from his estate. King began his ministry in 1954 at the Dexter Avenue Baptist Church in Montgomery, Alabama. On Aug. 28, 1963, King gave what many believe to be one of the greatest speeches of the 20th century. Martin Luther King Jr. Day is taken to represent a triumph of acceptable minimums rather than full respect for those who continue to wait for Dr. King’s dream to become reality. While he indeed fought for the security of a full schedule of rights for black Americans, he was in fact fighting for something greater and more difficult to articulate. The mark of true love, for King, was to embrace strangers as familiars, and conversely, to deny that blacks’ humanity was a new and strange thing. Martin Luther King, Jr. led a movement that had won many victories, but the issues of justice and peace he fought for are still with us. What are some concrete ways to talk with kids about King and his legacy, not just on Martin Luther King Day, but in ongoing conversations? Abdul-Jabbar: It\\'s tempting to use MLK Day as a cultural canonization of the man. He says King\\'s legacy may be in more danger from those who admire him. King would have been proud to see so many people across America join together, he says. John Eaton Elementary School in Washington, D.C., is one of the nation\\'s most racially and economically diverse schools. \"I am part of the Dr. Martin Luther King era,\" says prekindergarten teacher Carolyn Barnhardt. Barnhardt: \"When I tell them about some of the things that I\\'m teaching them about Dr. King, I let them know I have experienced it myself\"']\n",
      "Target: ['– At a time when racial tensions are in the spotlight in America, Kareem Abdul-Jabbar is among those reflecting on the legacy of Martin Luther King Jr. Today isn\\'t just a day to remember him, Abdul-Jabbar writes in Time: It\\'s a day to honor him by continuing his work. Of course, there are many who oppose King\\'s efforts, but \"his legacy may be in more danger from those who admire him,\" Abdul-Jabbar notes. It\\'s too easy to allow the existence of MLK Day to suggest that somehow, the fight against racism has been won. But \"just because some of the symptoms of racism are clearing up, you don’t stop taking the medicine or the malady returns even stronger than before.\" King would be glad to see white and black protesters supporting Michael Brown and Eric Garner. One thing he wouldn\\'t want, however, is to see us resorting to violence in the protests. \"Love is the only force capable of transforming an enemy into a friend,\" King said, as Abdul-Jabbar points out. \"His goal was to cleanse the community, not to cleave it.\" In the New York Times, Chris Lebron echoes Abdul-Jabbar: \"Martin Luther King Jr. Day is taken to represent a triumph,\" Lebron writes. \"But here is an uncomfortable truth: It is a triumph of acceptable minimums rather than full respect for those who continue to wait for Dr. King’s dream to become reality.\" Elsewhere, Time offers opinions from a number of thinkers on how to talk to your kids about Martin Luther King; Syracuse.com highlights some of his most enduring speeches; and NPR looks at King from the perspective of today\\'s children.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6257061958312988}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 19.512945386665386}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.5094, 'rouge_2_f_score': 0.19897, 'rouge_l_f_score': 0.20855}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.34423407917383825}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.27976639993196833}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (BART) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (LexRank) model ####################\u001b[0m\n",
      "Prediction: [\"Former Edwards economic policy adviser Leo Hindery testified Thursday he was an intermediary between Edwards and former Sen. Tom Daschle, who was then with Barack Obama's campaign. Hunter was being closely watched over by Edwards' once-close confidant, Andrew Young, who falsely claimed paternity of boss' baby as the tabloid prepared to expose the affair. In the interview, Edwards conceded he’d “made a mistake” by having a brief affair with videographer Rielle Hunter in 2006. Witnesses at the trial have testified about a couple of conversations Edwards was present for in 2007 where donors talked about entertaining or providing assistance to Hunter.\"]\n",
      "Target: ['– The prosecution rested its case today in the John Edwards trial, with testimony providing a glimpse at just how sky-high his political ambitions were just a few years ago, notes Politico: Vice president: As soon as he lost the Iowa caucuses in 2008, he reached out to Barack Obama\\'s camp to trade his endorsement for the VP slot. He didn\\'t contact Hillary Clinton because he thought a presidential victory by her would be a \"disaster,\" said former Edwards adviser Leo Hinderly. Supreme Court: If he didn\\'t get the VP slot, he talked about becoming attorney general, with the larger ambition of landing a seat on the Supreme Court. Prosecutors also said the Edwards campaign spent $319,000 to hide his affair with Rielle Hunter, reports AP, money that went toward \"luxury hotels, private jets, and a $20,000-a-month rental mansion in Santa Barbara.\" Tomorrow, the defense will ask that the case be dismissed. Assuming that formality goes nowhere, Edwards\\' attorneys are expected to present their case starting Monday.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5260353088378906}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.9818575128208996}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.30216, 'rouge_2_f_score': 0.05797, 'rouge_l_f_score': 0.13669}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.11678832116788321}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.22667826874954944}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (LexRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (Longformer) model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([582]) tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer model: processing document of tensor([259]) tokens\n",
      "Prediction: ['Harrison Ford was flying his private plane, a single-engine Husky, at John Wayne Airport in Orange County, California.\\nThe pilot was told to land on a taxiway instead of the runway.\\nFord has been involved in a series of crashes and near-crashes while flying aircraft. Actor Harrison Ford was cleared to land on a runway at John Wayne Airport.\\nThe American Airlines 737 was waiting for his plane to land in Dallas.\\nFord is known for his decades of experience in several different incidents.\\nHe has also used his piloting skills to rescue hikers and rescue hikers.']\n",
      "Target: ['– Perhaps it\\'s time for Harrison Ford to consider a safer hobby? On Monday, the actor was landing his single-engine Husky aircraft at California\\'s John Wayne Airport when he accidentally aimed for a taxiway instead of the runway he\\'d been instructed to land on, sources tell NBC News. As he landed, his plane went over the top of an American Airlines 737 that was in the process of departing the airport; it took off minutes after crossing paths with Ford\\'s aircraft. The 737 was actually waiting for Ford\\'s plane to land at the time; Ford was supposed to land on the runway in front of the 737, ABC 7 reports. \"Was that airliner meant to be underneath me?\" Ford, 74, can be heard asking on air traffic control recordings of the incident. Controllers explained to Ford that, despite the fact that he\\'d read back the correct landing instructions he\\'d been given, he had mistaken the taxiway for the runway he was supposed to land on. The FAA is investigating; Ford\\'s alleged actions violate FAA safety rules, and the organization could issue him a warning or go so far as to suspend his pilot\\'s license. Ford, who collects vintage aircraft, crash-landed a World War II-era plane on a golf course in 2015 after the engine failed and crash-landed a helicopter in 1999 during a lesson. In 2000, another one of his planes was involved in an emergency landing. But NBC notes that the actor \"is revered as an excellent pilot in aviation circles.\"']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6042613387107849}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.795710660323232}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.39118, 'rouge_2_f_score': 0.13851, 'rouge_l_f_score': 0.24793}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.2841225626740947}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.3300187564737829}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (Longformer) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (Pegasus) model ####################\u001b[0m\n",
      "Prediction: ['Scientists at Johns Hopkins say they have discovered a genetic indicator of a person’s vulnerability to the effects of stress and anxiety and, therefore, the risk of suicidal thoughts or attempts. A new genetic discovery could be key to creating a blood test that could, for the first time use DNA to determine a person’s risk of suicide.']\n",
      "Target: [\"– Scientists say they have a new way of determining suicide risk, and it's based on genetics—requiring only a blood test. Researchers running postmortem genome scans of brain samples found that the brains of those who'd committed suicide had less of a gene called SKA2, as well as higher levels of methylation, a chemical process that affects the gene's function, the Daily Beast reports. The gene may play a key role in our response to stress, a researcher says. Researchers applied their findings to blood samples from 325 participants in their study, the Washington Post reports. They sought to predict whether participants had experienced suicidal thoughts, and the results were 80% to 90% accurate. Researchers want to use the findings to help fight military suicide—which occurs at a rate some 50% higher than that of the population as a whole, the Daily Beast notes (though the military reported a decrease in suicides last year). An outside expert points out to the Post, however, that more than just one chemical indicator is needed to assess suicide risk in patients. (The nation's most common suicide spot is taking steps to prevent deaths.)\"]\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5441219210624695}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.6122287362740385}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.30588, 'rouge_2_f_score': 0.06324, 'rouge_l_f_score': 0.17255}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.18326693227091634}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.2247191011235955}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (Pegasus) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (TextRank) model ####################\u001b[0m\n",
      "Prediction: [\"Content includes publicly-accessible government websites hosted on .gov, .mil, and relevant non-.gov domains, as well as government social media materials. Some files posted on the Fed's website were not credit card agreements but rather supplemental materials that often accompany agreements, such as tables listing interest and penalty rates and fees or information about credit card or disability insurance. \\n  \\n The fact is that the chief beneficiary of the success of Daisey’s monologue has been Mike Daisey, much more than any group of factory workers or underground trades unionists in China.\"]\n",
      "Target: ['– Read any good credit card agreements lately? Didn\\'t think so. A follow-up to a July report on the readability of those contracts finds some improvement, but they\\'re still mostly indecipherable and, in fact, beyond the reading comprehension of the average American, reports CreditCards.com. Consumers groups hope the new protection agency being set up by Elizabeth Warren will help, but that\\'s probably at least a year away. At Reuters, Felix Salmon thinks \"somewhere in 2012\" is a good guess on when we might see real progress \"if we\\'re lucky.\" He cites one egregious 15-page contract from Fifth Third. \"I doubt one cardholder in a hundred could even begin to say what it means to \\'honor claims of privilege recognized at law,\\'\" he writes. \"I certainly couldn’t.\" But he also singles out this example from the University of Illinois employee credit union: It\\'s only two pages and free of \"gratuitous legalese.\"']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4501350522041321}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.254430419570316}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.19921, 'rouge_2_f_score': 0.03213, 'rouge_l_f_score': 0.11156}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.09716599190283401}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.1156677181913775}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (TextRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset samsum (/home/lily/mmm274/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6)\n",
      "100%|██████████| 14732/14732 [00:01<00:00, 12336.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "samsum has a training set of 14732 examples\n",
      "\u001b[35mInitializing all matching model pipelines for samsum dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset samsum (/home/lily/mmm274/.cache/huggingface/datasets/samsum/samsum/0.0.0/3f7dba43be72ab10ca66a2e0f8547b3590e96c2bd9f2cbb1f6bb1ec1f1488ba6)\n",
      "  0%|          | 0/14732 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  1%|          | 99/14732 [00:40<1:38:33,  2.47it/s]\n",
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/lily/mmm274/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      "100%|██████████| 204045/204045 [00:12<00:00, 16085.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xsum has a training set of 204045 examples\n",
      "\u001b[35mInitializing all matching model pipelines for xsum dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/lily/mmm274/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      "  0%|          | 0/204045 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 99/204045 [00:38<22:16:25,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: xsum dataset, BART model ####################\u001b[0m\n",
      "Prediction: [\"White, 54, lost 10-7 to fellow Englishman Jack Lisowski at Ponds Forge. White may need to enter May's Q School to regain a full tour card. Former world champions Steve Davis and Stephen Hendry were offered wildcards after losing their places in 2014.\"]\n",
      "Target: [\"Jimmy White has lost his tour card after 37 years as a professional after defeat in the first round of qualifying for this month's World Championship.\"]\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5201109051704407}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.062403823169552}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.25, 'rouge_2_f_score': 0.02857, 'rouge_l_f_score': 0.16666}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.08823529411764704}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.08474576271186442}\n",
      "\u001b[32m#################### Test for xsum dataset, BART model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: xsum dataset, LexRank model ####################\u001b[0m\n",
      "Prediction: ['Rolls-Royce shares fell nearly 9% to 780p on the profit downgrade. Rolls last issued a profit warning in February, claiming the sharp fall in oil prices had \"increased uncertainty for many of our markets and customers\".']\n",
      "Target: ['Rolls-Royce has issued its third profit warning in just over a year, blaming lower oil prices and weaker demand for some of its aircraft engines.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6223244071006775}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 5.190619769166795}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.38095, 'rouge_2_f_score': 0.13115, 'rouge_l_f_score': 0.31746}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.2711864406779661}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.2288711548935565}\n",
      "\u001b[32m#################### Test for xsum dataset, LexRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: xsum dataset, Longformer model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([420]) tokens\n",
      "Prediction: ['Police say Stephen Arthuro Solis-Reyes stole 900 social insurance numbers.\\nThe Canadian police say he stole 900 Social Insurance numbers last week.\\nUK parenting site Mumsnet has provided fresh details about how it fell victim to the bug.\\nHackers have been linked to the heart attack of Canadian mother Justine Roberts.']\n",
      "Target: ['A 19-year-old Canadian became the first person to be arrested in relation to the Heartbleed security breach.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4598506987094879}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.7398283377474275}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.14084, 'rouge_2_f_score': 0.02899, 'rouge_l_f_score': 0.0845}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.08955223880597014}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.07815126050420167}\n",
      "\u001b[32m#################### Test for xsum dataset, Longformer model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: xsum dataset, Pegasus model ####################\u001b[0m\n",
      "Prediction: ['US President Donald Trump reportedly cut short a phone call with Australian Prime Minister Malcolm Turnbull over a refugee deal.']\n",
      "Target: ['A phone call between US President Donald Trump and Australian PM Malcolm Turnbull has called into question a refugee resettlement deal.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.7788962721824646}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 17.989467505514355}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.63415, 'rouge_2_f_score': 0.35897, 'rouge_l_f_score': 0.4878}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.4864864864864865}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.6149724749035886}\n",
      "\u001b[32m#################### Test for xsum dataset, Pegasus model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: xsum dataset, TextRank model ####################\u001b[0m\n",
      "Prediction: ['Police Scotland said the 64-year-old man from Hawick died at the scene of the accident on the A7.']\n",
      "Target: ['A man has died after his car was involved in a collision with a lorry in the Scottish Borders.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5234493613243103}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.568331954752977}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.15384, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.15384}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.11428571428571428}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.08287292817679558}\n",
      "\u001b[32m#################### Test for xsum dataset, TextRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset pubmed_qa (/home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d)\n",
      "Loading cached split indices for dataset at /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-4a7fed3fa9d9c53a.arrow and /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-8917325612f1a482.arrow\n",
      "Loading cached split indices for dataset at /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-8e297aa49ae0c600.arrow and /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-b3ad2bcb7941385f.arrow\n",
      "100%|██████████| 169226/169226 [00:52<00:00, 3208.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pubmed_qa has a training set of 169226 examples\n",
      "\u001b[35mInitializing all matching model pipelines for pubmed_qa dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset pubmed_qa (/home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d)\n",
      "Loading cached split indices for dataset at /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-4a7fed3fa9d9c53a.arrow and /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-8917325612f1a482.arrow\n",
      "Loading cached split indices for dataset at /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-8e297aa49ae0c600.arrow and /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-b3ad2bcb7941385f.arrow\n",
      "  0%|          | 0/169226 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 100/169226 [01:26<40:27:36,  1.16it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 200/169226 [02:26<36:51:37,  1.27it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 299/169226 [03:05<29:11:10,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (BART) model ####################\u001b[0m\n",
      "Prediction: ['therefore, studied possible link perioperative aprotinin treatment renal dysfunction patients undergoing first-time coronary surgery high risk bleeding. performed matched cohort study, comparing 200 patients receiving high-dose aProtinin with tranexamic acid primary isolated coronary surgery. Secondary outcomes evaluations postoperative renal function, mortality, stroke, reoperation bleeding, transfusion requirements.']\n",
      "Target: ['Aprotinin treatment during primary coronary surgery was not associated with impaired postoperative renal function in comparison with patients treated with tranexamic acid.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6612899899482727}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 5.203300368769515}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.34286, 'rouge_2_f_score': 0.17647, 'rouge_l_f_score': 0.22858}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.21212121212121213}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.1955912334352701}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (BART) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (LexRank) model ####################\u001b[0m\n",
      "Prediction: [\"current diet quality , food groups , nutrient intakes differed depending world region individuals resided child . residence outside us point interviewee 's life associated higher diet quality ( healthy eating index-2005 : 50.0 vs. 46.8 ) lower added sugar intake ( 25.8 vs. 34.9 g/d ) .\"]\n",
      "Target: ['Lower added sugar intake and higher overall diet quality were most consistently associated with residence outside of the US, and recent residence outside of the US may be more strongly associated than childhood residence. Some of these differences may be explained by demographic or socioeconomic factors. Future studies could evaluate explanatory factors for these observations, including detailed socioeconomic factors, exposure to diverse foods, and accessibility of processed foods.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.48386621475219727}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.927607268561011}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.24779, 'rouge_2_f_score': 0.09009, 'rouge_l_f_score': 0.12389}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.12844036697247704}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.22970414201183426}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (LexRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (Longformer) model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([77]) tokens\n",
      "Prediction: ['The average household income completed food reinforcement was a bmi.\\nThe study was carried out by the University of New South Wales.\\nLow socioeconomic status and high education levels were the main factors.\\nHigh socioeconomic status was the highest.\\nlevel.\\nof bmi mediated part increased food reinforcement.']\n",
      "Target: ['These findings support the hypothesis that deprivation and restricted food choice associated with low SES enhance food reinforcement, increasing the risk for obesity.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4851062297821045}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.8784392958042233}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.22857, 'rouge_2_f_score': 0.02941, 'rouge_l_f_score': 0.14285}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.09090909090909091}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.1008968609865471}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (Longformer) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (Pegasus) model ####################\u001b[0m\n",
      "Prediction: ['colon cancer hct-8/v cells are resistant to anti-cancer drugs.']\n",
      "Target: ['These data suggest that specific silencing of Livin gene expression could be a promising target for further research in clinical chemotherapy of colon cancer.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5287785530090332}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.536985692769704}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.11111, 'rouge_2_f_score': 0.05883, 'rouge_l_f_score': 0.11111}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.06250000000000001}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.04761904761904762}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (Pegasus) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (TextRank) model ####################\u001b[0m\n",
      "Prediction: ['women less likely men undergo bowel resection ( incidence rate ratio [ irr ] = 0.80 ; 95 % ci : 0.76-0.85 ) .']\n",
      "Target: ['Bowel resection among hospitalized CD patients varies by race, health insurance, and sex. Further mechanistic studies are needed to elucidate the social and biological underpinnings of these variations.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4124193787574768}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.3638844983778693}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.08511, 'rouge_2_f_score': 0.04445, 'rouge_l_f_score': 0.08511}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.04651162790697675}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.07684426229508197}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (TextRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (BART) model ####################\u001b[0m\n",
      "Prediction: ['renal cell carcinoma ( rcc) characterized inherent resistance chemotherapy. microrna let-7, putative tumor suppressor, dysregulated many cancers. Study aims investigate exact role let- 7 chemotherapy sensitivity 5-fluorouracil ( 5-fu ) rcc.']\n",
      "Target: ['Expression of let-7b and let-7c was frequently decreased in clear cell renal cell carcinoma tissues. The dysregulation of let-7b and let-7c may be involved in chemoresistance of RCC cells to 5-FU by down-regulating Akt2.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6117666959762573}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 4.559049544650469}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.25352, 'rouge_2_f_score': 0.08695, 'rouge_l_f_score': 0.19718}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.1492537313432836}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.14249201277955273}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (BART) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (LexRank) model ####################\u001b[0m\n",
      "Prediction: ['significant time-by-treatment interactions seen systolic arterial pressure ( p = 0.015 ) , mean arterial pressure ( p = 0.009 ) diastolic arterial pressure ( p = 0.006 ) . pirinitramide provided good postoperative analgesia without prolonging extubation times : median extubation time minutes stopping opioid-sedative drugs 300 higher-dose remifentanil group 270 lower-dose remifentanil group alfentanil group ( p = 0.606 ) .']\n",
      "Target: ['The higher-dose remifentanil infusion provided superior suppression of haemodynamic responses to noxious stimuli with better haemodynamic stability.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5036441087722778}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.367537266354334}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.10811, 'rouge_2_f_score': 0.05555, 'rouge_l_f_score': 0.08108}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.05714285714285714}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.03424657534246575}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (LexRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (Longformer) model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([139]) tokens\n",
      "Prediction: ['Genome-wide association studies colorectal cancer (crc)\\nGenome studies coloresctal cancers found to be genetic variants.\\nGenomics studies colourctal tumours found genetic variants in one-center group.\\nStudy carried out by genome-based co-authors.']\n",
      "Target: ['Our investigation confirms that variants across multiple risk regions of 8q24 are associated with CRC, and that associations at 18q21 differ by tumor site.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.46549928188323975}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.3494116947566301}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.1356, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.1356}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.0}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.08250825082508251}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (Longformer) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (Pegasus) model ####################\u001b[0m\n",
      "Prediction: [\"preterm infants born 26 29 weeks'gestational age.\"]\n",
      "Target: ['An early oral stimulation program accelerates the transition to full oral feedings in preterm infants. This was associated with greater overall intake and rate of milk transfer observed in the experimental group when compared with the control group.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.47035011649131775}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.22387343808265306}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.08695, 'rouge_2_f_score': 0.04546, 'rouge_l_f_score': 0.08695}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.04761904761904762}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.04950495049504951}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (Pegasus) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (TextRank) model ####################\u001b[0m\n",
      "Prediction: [', mitogen activated protein kinase kinase ( mek ) .']\n",
      "Target: ['In hippocampal neurons, schisandrin exhibits neurotrophic properties that are mediated by the CaMKII-PKCε-MEK pathway.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.45713886618614197}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.7385973411104616}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.09091, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.09091}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset summertime_scisummnet (/home/lily/mmm274/.cache/huggingface/datasets/summertime_scisummnet/default/0.0.0/2de3b585a09db9aaf7f42cebe7c334a94ebae2d8104a752ce286c8a0d3fadaec)\n",
      "  0%|          | 0/808 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.0}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.0}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (TextRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808/808 [00:00<00:00, 8074.69it/s]\n",
      "Reusing dataset summertime_scisummnet (/home/lily/mmm274/.cache/huggingface/datasets/summertime_scisummnet/default/0.0.0/2de3b585a09db9aaf7f42cebe7c334a94ebae2d8104a752ce286c8a0d3fadaec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ScisummNet has a training set of 808 examples\n",
      "\u001b[35mInitializing all matching model pipelines for ScisummNet dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/808 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 12%|█▏        | 99/808 [01:05<07:49,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: ScisummNet dataset, BART model ####################\u001b[0m\n",
      "Prediction: ['Parsing algorithms that process the input from left to right and construct a single derivation have often been considered inadequate for natural language parsing. This article presents a general framework for describing and analyzing algorithms for deterministic incremental dependency parsing. We show that all four algorithms give competitive accuracy, although the non-projective list-based algorithm generally outperforms the projective algorithms.']\n",
      "Target: ['Algorithms for Deterministic Incremental Dependency Parsing\\nParsing algorithms that process the input from left to right and construct a single derivation have often been considered inadequate for natural language parsing because of the massive ambiguity typically found in natural language grammars.\\nNevertheless, it has been shown that such algorithms, combined with treebank-induced classifiers, can be used to build highly accurate disambiguating parsers, in particular for dependency-based syntactic representations.\\nIn this article, we first present a general framework for describing and analyzing algorithms for deterministic incremental dependency parsing, formalized as transition systems.\\nWe then describe and analyze two families of such algorithms: stack-based and list-based algorithms.\\nIn the former family, which is restricted to projective dependency structures, we describe an arc-eager and an arc-standard variant; in the latter family, we present a projective and a nonprojective variant.\\nFor each of the four algorithms, we give proofs of correctness and complexity.\\nIn addition, we perform an experimental evaluation of all algorithms in combination with SVM classifiers for predicting the next parsing action, using data from thirteen languages.\\nWe show that all four algorithms give competitive accuracy, although the non-projective list-based algorithm generally outperforms the projective algorithms for languages with a non-negligible proportion of non-projective constructions.\\nHowever, the projective algorithms often produce comparable results when combined with the technique known as pseudo-projective parsing.\\nThe linear time complexity of the stack-based algorithms gives them an advantage with respect to efficiency both in learning and in parsing, but the projective list-based algorithm turns out to be equally efficient in practice.\\nMoreover, when the projective algorithms are used to implement pseudo-projective parsing, they sometimes become less efficient in parsing (but not in learning) than the non-projective list-based algorithm.\\nAlthough most of the algorithms have been partially described in the literature before, this is the first comprehensive analysis and evaluation of the algorithms within a unified framework.\\nWe give a systematic description of the arc-standard and arc-eager algorithms, currently two popular transition-based parsing methods for word-level dependency parsing.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6977407336235046}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.7183910270410583}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.29612, 'rouge_2_f_score': 0.27805, 'rouge_l_f_score': 0.29612}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.28431372549019607}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.5050197119217815}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, BART model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: ScisummNet dataset, LexRank model ####################\u001b[0m\n",
      "Prediction: ['(2003)).</S>\\n    <S sid=\"120\" ssid=\"4\">The rewritings involved some deletions of irrelevant features, some systematic manipulations of the analyses, and some trivial respellings.</S>\\n    <S sid=\"121\" ssid=\"5\">The deletions involved features produced by the grammar but not included in the PARC 700 such as negative values of PASS, PERF, and PROG and the feature MEASURE used to mark measure phrases.</S>\\n    <S sid=\"122\" ssid=\"6\">The manipulations are more interesting and are necessary to map systematic differences between the analyses in the grammar and those in the dependency bank.</S>\\n    <S sid=\"123\" ssid=\"7\">For example, coordination is treated as a set by the LFG grammar but as a single COORD dependency with several CONJ relations in the dependency bank.</S>\\n    <S sid=\"124\" ssid=\"8\">Finally, the trivial rewritings were used to, for example, change STMT-TYPE decl in the grammar to STMT-TYPE declarative in the dependency bank.</S>\\n    <S sid=\"125\" ssid=\"9\">For the Reduced version of the PARC 700 substantially more features were deleted.</S>\\n    <S sid=\"126\" ssid=\"10\">Collins Model 3 Conversion An abbreviated representation of the Collins tree for the example above is shown in Fig.</S>\\n    <S sid=\"127\" ssid=\"11\">4.</S>\\n    <S sid=\"128\" ssid=\"12\">In this display we have eliminated the head lexical items that appear redundantly at all the nonterminals in a head chain, instead indicating by a single number which daughter is the head.</S>\\n    <S sid=\"129\" ssid=\"13\">Thus, S&#732;2 indicates that the head of the main clause is its second daughter, the VP, and its head is its first VP daughter.</S>\\n    <S sid=\"130\" ssid=\"14\">Indirectly, then, the lexical head of the S is the first verb reiterated.</S>\\n    <S sid=\"131\" ssid=\"15\">The Model 3 output in this example includes standard phrase structure categories, indications of the heads, and the additional -A marker to distinguish arguments from adjuncts.</S>\\n    <S sid=\"132\" ssid=\"16\">The terminal nodes of this tree are inflected forms, and the first phase of our conversion replaces them with their citation forms (the verbs reiterate and express, and the decapitalized and standardized he for He and his).</S>\\n    <S sid=\"133\" ssid=\"17\">We also adjust for systematic differences in the choice of heads.</S>\\n    <S sid=\"134\" ssid=\"18\">The first conjunct tends to be marked as the head of a coordination in Model 3 output, whereas the dependency bank has a more symmetric representation: it introduces a new COORD head and connects that up to the conjunction, and it uses a separate CONJ relation for each of the coordinated items.</S>\\n    <S sid=\"135\" ssid=\"19\">Similarly, Model 3 identifies the syntactic markers to and that as the heads of complements, whereas the dependency bank treats these as selectional features and marks the main predicate of the complements as the head.</S>\\n    <S sid=\"136\" ssid=\"20\">These adjustments are carried out without penalty.</S>\\n    <S sid=\"137\" ssid=\"21\">We also compensate for the differences in the representation of auxiliaries: Model 3 treats these as main verbs with embedded complements instead of the PERF, PROG, and PASSIVE features of the DEPBANK, and our conversion flattens the trees so that the features can be read off.</S>\\n    <S sid=\"138\" ssid=\"22\">The dependencies are read off after these and a few other adjustments are made.</S>\\n    <S sid=\"139\" ssid=\"23\">NPs under VPs are read off either as objects or adjuncts, depending on whether or not the NP is annotated with the argument indicator (-A) as in this example; the -A presumably would be missing in a sentence like John arrived Friday, and Friday would be treated as an ADJUNCT.</S>\\n    <S sid=\"140\" ssid=\"24\">Similarly, NP-As under S are read off as subject.</S>\\n    <S sid=\"141\" ssid=\"25\">In this example, however, this principle of conversion does not lead to a match with the dependency bank: in the DEPBANK grammatical relations that are factored out of conjoined structures are distributed back into those structures, to establish the correct semantic dependencies (in this case, that he is the subject of both reiterate and express and not of the introduced coord).</S>\\n    <S sid=\"142\" ssid=\"26\">We avoided the temptation of building coordinate distribution into the conversion routine because, first, it is not always obvious from the Model 3 output when distribution should take place, and second, that would be a first step towards building into the conversion routine the deep lexical and syntactic knowledge (essentially the functional component of our LFG grammar) that the shallow approach explicitly discounts4.</S>\\n    <S sid=\"143\" ssid=\"27\">For the same reasons our conversion routine does not identify the subjects of infinitival complements with particular arguments of matrix verbs.</S>\\n    <S sid=\"144\" ssid=\"28\">The Model 3 trees provide no indication of how this is to be done, and in many cases the proper assignment depends on lexical information about specific predicates (to capture, for example, the well-known contrast between promise and persuade).</S>\\n    <S sid=\"145\" ssid=\"29\">Model 3 trees also provide information about certain 4However, we did explore a few of these additional transformations and found only marginal F-score increases. maximum-entropy) probability model (Riezler et al., 2002).</S>\\n    <S sid=\"20\" ssid=\"15\">The stochastic component is also &#8220;ambiguity-enabled&#8221; in the sense that the computations for statistical estimation and selection of the most probable analyses are done efficiently by dynamic programming, avoiding the need to unpack the parse forests and enumerate individual analyses.</S>\\n    <S sid=\"21\" ssid=\"16\">The underlying parsing system also has built-in robustness mechanisms that allow it to parse strings that are outside the scope of the grammar as a shortest sequence of wellformed &#8220;fragments&#8221;.</S>\\n    <S sid=\"22\" ssid=\"17\">Furthermore, performance parameters that bound parsing and disambiguation work can be tuned for efficient but accurate operation.</S>\\n    <S sid=\"23\" ssid=\"18\">As part of our assessment, we also measured the parsing speed of the two systems, taking into account all stages of processing that each system requires to produce its output.</S>\\n    <S sid=\"24\" ssid=\"19\">For example, since the Collins parser depends on a prior part-of-speech tagger (Ratnaparkhi, 1996), we included the time for POS tagging in our Collins measurements.</S>\\n    <S sid=\"25\" ssid=\"20\">XLE incorporates a sophisticated finite-state morphology and dictionary lookup component, and its time is part of the measure of XLE performance.</S>\\n    <S sid=\"26\" ssid=\"21\">Performance parameters of both the Collins parser and the XLE system were adjusted on a heldout set consisting of a random selection of 1/5 of the PARC 700 dependency bank; experimental results were then based on the other 560 sentences.</S>\\n    <S sid=\"27\" ssid=\"22\">For Model 3 of the Collins parser, a beam size of 1000, and not the recommended beam size of 10000, was found to optimize parsing speed at little loss in accuracy.</S>\\n    <S sid=\"28\" ssid=\"23\">On the same heldout set, parameters of the stochastic disambiguation system and parameters for parsing performance were adjusted for a Core and a Complete version of the XLE system, differing in the size of the constraint-set of the underlying grammar.</S>\\n    <S sid=\"29\" ssid=\"24\">For both XLE and the Collins parser we wrote conversion programs to transform the normal (tree or fstructure) output into the corresponding relations of the dependency bank.</S>\\n    <S sid=\"30\" ssid=\"25\">This conversion was relatively straightforward for LFG structures (King et al., 2003).</S>\\n    <S sid=\"31\" ssid=\"26\">However, a certain amount of skill and intuition was required to provide a fair conversion of the Collins trees: we did not want to penalize configurations in the Collins trees that encoded alternative but equally legitimate representations of the same linguistic properties (e.g.']\n",
      "Target: ['Speed And Accuracy In Shallow And Deep Stochastic Parsing\\nThis paper reports some experiments that compare the accuracy and performance of two stochastic parsing systems.\\nThe currently popular Collins parser is a shallow parser whose output contains more detailed semantically relevant information than other such parsers.\\nThe XLE parser is a deep-parsing system that couples a Lexical Functional Grammar to a log-linear disambiguation component and provides much richer representations theory.\\nWe measured the accuracy of both systems against a gold standard of the PARC 700 dependency bank, and also measured their processing times.\\nWe report high parsing speeds for a deep parsing system which uses an LFG grammar: 1.9 sentences per second for 560 sentences from section 23 of the Penn Treebank.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4792468249797821}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.5974775194553664}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.0, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.0}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.09497591190640056}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.04862517593199704}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, LexRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: ScisummNet dataset, Longformer model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([4096]) tokens\n",
      "Prediction: ['The task was designed to promote research on semantic inference over texts written in different languages.\\nThe results suggest that the most successful systems (including the most accurate) were in the first round of the task.\\nResults suggest that systems performed better on the SP-EN dataset than the lowest score on DE-EN (0.25)\\nThe final result is a monolingual English translation of the two classes of language pairs.']\n",
      "Target: ['Semeval-2012 Task 8: Cross-lingual Textual Entailment for Content Synchronization\\nThis paper presents the first round of the task on Cross-lingual Textual Entailment for Content Synchronization, organized within SemEval-2012.\\nThe task was designed to promote research on semantic inference over texts written in different languages, targeting at the same time a real application scenario.\\nParticipants were presented with datasets for different language pairs, where multi-directional entailment relations (forward, backward, bidirectional, no entailment) had to be identified.\\nWe report on the training and test data used for evaluation, the process of their creation, the participating systems (10 teams, 92 runs), the approaches adopted and the results achieved.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5771187543869019}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 16.530724949624943}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.41989, 'rouge_2_f_score': 0.25698, 'rouge_l_f_score': 0.38674}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.3276836158192091}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.376096547405573}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, Longformer model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: ScisummNet dataset, Pegasus model ####################\u001b[0m\n",
      "Prediction: ['The aim of this paper is to investigate the feasibility of constructing a dependency tree for natural language analysis.']\n",
      "Target: ['Experiments With A Multilanguage Non-Projective Dependency Parser\\nWe present a deterministic classifier-based Shift/Reduce parser.\\nWe develop DeSR, an incremental deterministic classifier-based parser.\\nWe propose a transition system whose individual transitions can deal with non-projective dependencies only to a limited extent, depending on the distance in the stack of the nodes involved in the newly constructed dependency.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4783267378807068}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.3490466122602539}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.175, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.15}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.10526315789473684}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.1762114537444934}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, Pegasus model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: ScisummNet dataset, TextRank model ####################\u001b[0m\n",
      "Prediction: ['<PAPER>\\n  <S sid=\"0\">Generalizing Word Lattice Translation</S>\\n  <ABSTRACT>\\n    <S sid=\"1\" ssid=\"1\">Word lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.</S>\\n    <S sid=\"2\" ssid=\"2\">We show that prior work in translating lattices using finite state techniques can be naturally extended to more expressive synchronous context-free grammarbased models.</S>\\n    <S sid=\"3\" ssid=\"3\">Additionally, we resolve a significant complication that non-linear word lattice inputs introduce in reordering models.</S>\\n    <S sid=\"4\" ssid=\"4\">Our experiments evaluating the approach demonstrate substantial gains for Chinese- English and Arabic-English translation.</S>\\n  </ABSTRACT>\\n  <SECTION title=\"1 Introduction\" number=\"1\">\\n    <S sid=\"5\" ssid=\"1\">When Brown and colleagues introduced statistical machine translation in the early 1990s, their key insight &#8211; harkening back to Weaver in the late 1940s &#8211; was that translation could be viewed as an instance of noisy channel modeling (Brown et al., 1990).</S>\\n    <S sid=\"6\" ssid=\"2\">They introduced a now standard decomposition that distinguishes modeling sentences in the target language (language models) from modeling the relationship between source and target language (translation models).</S>\\n    <S sid=\"7\" ssid=\"3\">Today, virtually all statistical translation systems seek the best hypothesis e for a given input f in the source language, according to consider all possibilities for f by encoding the alternatives compactly as a confusion network or lattice (Bertoldi et al., 2007; Bertoldi and Federico, 2005; Koehn et al., 2007).</S>\\n    <S sid=\"8\" ssid=\"4\">Why, however, should this advantage be limited to translation from spoken input?</S>\\n    <S sid=\"9\" ssid=\"5\">Even for text, there are often multiple ways to derive a sequence of words from the input string.</S>\\n    <S sid=\"10\" ssid=\"6\">Segmentation of Chinese, decompounding in German, morphological analysis for Arabic &#8212; across a wide range of source languages, ambiguity in the input gives rise to multiple possibilities for the source word sequence.</S>\\n    <S sid=\"11\" ssid=\"7\">Nonetheless, state-of-the-art systems commonly identify a single analysis f during a preprocessing step, and decode according to the decision rule in (1).</S>\\n    <S sid=\"12\" ssid=\"8\">In this paper, we go beyond speech translation by showing that lattice decoding can also yield improvements for text by preserving alternative analyses of the input.</S>\\n    <S sid=\"13\" ssid=\"9\">In addition, we generalize lattice decoding algorithmically, extending it for the first time to hierarchical phrase-based translation (Chiang, 2005; Chiang, 2007).</S>\\n    <S sid=\"14\" ssid=\"10\">Formally, the approach we take can be thought of as a &#8220;noisier channel&#8221;, where an observed signal o gives rise to a set of source-language strings f\\' E F(o) and we seek An exception is the translation of speech recognition output, where the acoustic signal generally underdetermines the choice of source word sequence f. There, Bertoldi and others have recently found that, rather than translating a single-best transcription f, it is advantageous to allow the MT decoder to = arg max max Pr(e)Pr(f\\'|e)Pr(o|f\\')&#65533;(4) e f&#65533;EF(o)']\n",
      "Target: ['Generalizing Word Lattice Translation\\nWord lattice decoding has proven useful in spoken language translation; we argue that it provides a compelling model for translation of text genres, as well.\\nWe show that prior work in translating lattices using finite state techniques can be naturally extended to more expressive synchronous context-free grammar-based models.\\nAdditionally, we resolve a significant complication that non-linear word lattice inputs introduce in reordering models.\\nOur experiments evaluating the approach demonstrate substantial gains for Chinese-English and Arabic-English translation.\\nIn our model, several different segmenters for Chinese are combined to create the lattice.\\nAll of the systems we present use the lattice input format to Moses (Dyer et al, 2008), including the baselines which do not need them.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n",
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.10(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6083104610443115}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 10.035149326492864}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.0, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.0}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset summertime_summscreen (/home/lily/mmm274/.cache/huggingface/datasets/summertime_summscreen/default/0.0.0/3b7dab2d730657a8545307f56c2e997a817186018ef6141b5699deebdc103573)\n",
      "  2%|▏         | 402/22588 [00:00<00:10, 2060.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.2717557251908397}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.1678766200821647}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, TextRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22588/22588 [00:10<00:00, 2241.55it/s]\n",
      "Reusing dataset summertime_summscreen (/home/lily/mmm274/.cache/huggingface/datasets/summertime_summscreen/default/0.0.0/3b7dab2d730657a8545307f56c2e997a817186018ef6141b5699deebdc103573)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SummScreen_fd+tms_tokenized has a training set of 22588 examples\n",
      "\u001b[35mInitializing all matching model pipelines for SummScreen_fd+tms_tokenized dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22588 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 99/22588 [01:06<4:12:17,  1.49it/s]\n",
      "Reusing dataset summertime_qmsum (/home/lily/mmm274/.cache/huggingface/datasets/summertime_qmsum/default/0.0.0/a38c28c0dafe617fb4368a6ebbad1285632e2e82ae89de707d10e7881383ec35)\n",
      "100%|██████████| 162/162 [00:00<00:00, 228.80it/s]\n",
      "Reusing dataset summertime_qmsum (/home/lily/mmm274/.cache/huggingface/datasets/summertime_qmsum/default/0.0.0/a38c28c0dafe617fb4368a6ebbad1285632e2e82ae89de707d10e7881383ec35)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QMsum has a training set of 162 examples\n",
      "\u001b[35mInitializing all matching model pipelines for QMsum dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 89/162 [00:12<00:00, 212.35it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 61%|██████    | 99/162 [01:21<00:51,  1.22it/s] \n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 2826.926s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f605dea9580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "from model.base_model import SummModel\n",
    "from model import SUPPORTED_SUMM_MODELS, LexRankModel, PegasusModel, HMNetModel\n",
    "\n",
    "from pipeline import assemble_model_pipeline\n",
    "\n",
    "from evaluation.base_metric import SummMetric\n",
    "from evaluation import SUPPORTED_EVALUATION_METRICS, Rouge, RougeWe\n",
    "\n",
    "from dataset.st_dataset import SummInstance, SummDataset\n",
    "from dataset import SUPPORTED_SUMM_DATASETS\n",
    "from dataset.non_huggingface_datasets import ScisummnetDataset, SummscreenDataset, ArxivDataset\n",
    "from dataset.huggingface_datasets import CnndmDataset, MlsumDataset, SamsumDataset\n",
    "\n",
    "from tests.helpers import print_with_color, retrieve_random_test_instances\n",
    "\n",
    "import random\n",
    "import time\n",
    "from typing import Dict, List, Union, Tuple\n",
    "import sys\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "class IntegrationTests(unittest.TestCase):\n",
    "    \n",
    "    def get_prediction(self, model: SummModel, dataset: SummDataset, test_instances: List[SummInstance]) -> Tuple[Union[List[str], List[List[str]]], Union[List[str], List[List[str]]]]:\n",
    "        \"\"\"\n",
    "        Get summary prediction given model and dataset instances.\n",
    "\n",
    "        :param SummModel `model`: Model for summarization task.\n",
    "        :param SummDataset `dataset`: Dataset for summarization task.\n",
    "        :param List[SummInstance] `test_instances`: Instances from `dataset` to summarize.\n",
    "        :returns Tuple containing summary list of summary predictions and targets corresponding to each instance in `test_instances`.\n",
    "        \"\"\"\n",
    "\n",
    "        src = [ins.source[0] for ins in test_instances] if isinstance(dataset, ScisummnetDataset) else [ins.source for ins in test_instances]\n",
    "        tgt = [ins.summary for ins in test_instances]\n",
    "        query = [ins.query for ins in test_instances] if dataset.is_query_based else None\n",
    "        prediction = model.summarize(src, query)\n",
    "        return prediction, tgt\n",
    "    \n",
    "    def get_eval_dict(self, metric: SummMetric, prediction: List[str], tgt: List[str]):\n",
    "        \"\"\"\n",
    "        Run evaluation metric on summary prediction.\n",
    "\n",
    "        :param SummMetric `metric`: Evaluation metric.\n",
    "        :param List[str] `prediction`: Summary prediction instances.\n",
    "        :param List[str] `tgt`: Target prediction instances from dataset.\n",
    "        \"\"\"\n",
    "        score_dict = metric.evaluate(prediction, tgt)\n",
    "        return score_dict\n",
    "\n",
    "    def test_all(self):\n",
    "        \"\"\"\n",
    "        Runs integration test on all compatible dataset + model + evaluation metric pipelines supported by SummerTime.\n",
    "        \"\"\"\n",
    "\n",
    "        print_with_color(\"\\nInitializing all evaluation metrics...\", \"35\")\n",
    "        evaluation_metrics = []\n",
    "        for eval_cls in SUPPORTED_EVALUATION_METRICS:\n",
    "            # # TODO: Temporarily skipping Rouge/RougeWE metrics to avoid local bug.\n",
    "            # if eval_cls in [Rouge, RougeWe]:\n",
    "            #     continue\n",
    "            print(eval_cls)\n",
    "            evaluation_metrics.append(eval_cls())\n",
    "\n",
    "        print_with_color(\"\\n\\nBeginning integration tests...\", \"35\")\n",
    "        for dataset_cls in SUPPORTED_SUMM_DATASETS:\n",
    "            # TODO: Temporarily skipping MLSumm (Gitlab: server-side login gating) and Arxiv (size/time)\n",
    "            if dataset_cls in [MlsumDataset, ArxivDataset]:\n",
    "                continue\n",
    "            dataset = dataset_cls()\n",
    "            if dataset.train_set is not None:\n",
    "                dataset_instances = list(dataset.train_set)\n",
    "                print(f\"\\n{dataset.dataset_name} has a training set of {len(dataset_instances)} examples\")\n",
    "                print_with_color(f\"Initializing all matching model pipelines for {dataset.dataset_name} dataset...\", \"35\")\n",
    "                # # TODO Temporarily skipping HMNetModel to a avoid a bug on this branch\n",
    "                matching_model_instances = assemble_model_pipeline(dataset_cls, list(filter(lambda m: m != HMNetModel, SUPPORTED_SUMM_MODELS)))\n",
    "                for model, model_name in matching_model_instances:\n",
    "                    test_instances = retrieve_random_test_instances(dataset_instances=dataset_instances, num_instances=1)\n",
    "                    print_with_color(f\"{'#' * 20} Testing: {dataset.dataset_name} dataset, {model_name} model {'#' * 20}\", \"35\")\n",
    "                    prediction, tgt = self.get_prediction(model, dataset, test_instances)\n",
    "                    print(f\"Prediction: {prediction}\\nTarget: {tgt}\\n\")\n",
    "                    for metric in evaluation_metrics:\n",
    "                        print_with_color(f\"{metric.metric_name} metric\", \"35\")\n",
    "                        score_dict = self.get_eval_dict(metric, prediction, tgt)\n",
    "                        print(score_dict)\n",
    "\n",
    "                    print_with_color(f\"{'#' * 20} Test for {dataset.dataset_name} dataset, {model_name} model COMPLETE {'#' * 20}\\n\\n\", \"32\")\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SummerTime midway showcase",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
