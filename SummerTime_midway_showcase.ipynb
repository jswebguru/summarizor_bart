{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYHUSCHjPhAq"
   },
   "source": [
    "# SummerTime Midway Showcase\n",
    "\n",
    "#### This notebook shows part of the current functionality of the SummerTime - A summarization library.\n",
    "\n",
    "Note: This is not the production version of the library and more modules are being added, including but not limited to pip installation, more models, more datasets, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbJwtmwJQabJ"
   },
   "source": [
    "## Installation\n",
    "Cloning from GitHub at the moment, but will support `pip install` soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NQvjj2buK3Qo",
    "outputId": "7541ebf4-2d48-473e-e61e-685e369dac15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/lily/mmm274/SummerTime/notebook/SummerTime\n",
      "HEAD is now at 6b48c8b Merge branch 'main' into troyfeng116/integration-tests\n"
     ]
    }
   ],
   "source": [
    "## Uncomment to clone git repo if not already done so\n",
    "## Swith to the Summertime directory\n",
    "## Switch to the relevant git branch\n",
    "\n",
    "# !git clone https://github.com/Yale-LILY/SummerTime.git\n",
    "# %cd SummerTime/\n",
    "# !git checkout origin/troyfeng116/integration-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build\t\t  __init__.py\t\tSummerTime.egg-info\r\n",
      "dataset\t\t  model\t\t\tSummerTime_midway_showcase.ipynb\r\n",
      "dataset_test.py   pipeline\t\tsummertime_pkg\r\n",
      "demo.ipynb\t  pip_instructions.txt\tsummertime.py\r\n",
      "dependencies.txt  README.md\t\ttests\r\n",
      "dist\t\t  requirements.txt\r\n",
      "evaluation\t  setup.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VttAZIVvQ5Ye"
   },
   "source": [
    "### Install dependencies for the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mdrTYwrFLl8A",
    "outputId": "3613dd53-6b81-49bf-eb7f-0adad7508709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.5.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (4.5.1)\n",
      "Requirement already satisfied: torch==1.8.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.8.1)\n",
      "Requirement already satisfied: torchvision==0.9.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (0.9.1)\n",
      "Requirement already satisfied: torchaudio==0.8.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
      "Requirement already satisfied: lexrank==0.1.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.1.0)\n",
      "Requirement already satisfied: nltk==3.6.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (3.6.2)\n",
      "Requirement already satisfied: spacy==3.0.6 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (3.0.6)\n",
      "Requirement already satisfied: pytextrank in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 8)) (3.1.1)\n",
      "Requirement already satisfied: datasets==1.6.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 9)) (1.6.2)\n",
      "Requirement already satisfied: sentencepiece==0.1.95 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 10)) (0.1.95)\n",
      "Requirement already satisfied: summ_eval in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 11)) (0.30)\n",
      "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 12)) (3.0.0)\n",
      "Requirement already satisfied: jupyter in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 13)) (1.0.0)\n",
      "Requirement already satisfied: gensim==3.8.3 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 14)) (3.8.3)\n",
      "Requirement already satisfied: sklearn in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 15)) (0.0)\n",
      "Requirement already satisfied: py7zr==0.16.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 16)) (0.16.1)\n",
      "Requirement already satisfied: mpi4py==3.0.3 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 17)) (3.0.3)\n",
      "Requirement already satisfied: tqdm==4.49.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from -r requirements.txt (line 18)) (4.49.0)\n",
      "Requirement already satisfied: sacremoses in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (0.0.45)\n",
      "Requirement already satisfied: packaging in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (20.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (1.19.2)\n",
      "Requirement already satisfied: filelock in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (0.10.3)\n",
      "Requirement already satisfied: requests in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (2.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from transformers==4.5.1->-r requirements.txt (line 1)) (2020.10.15)\n",
      "Requirement already satisfied: typing-extensions in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from torch==1.8.1->-r requirements.txt (line 2)) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from torchvision==0.9.1->-r requirements.txt (line 3)) (8.0.1)\n",
      "Requirement already satisfied: urlextract>=0.7 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from lexrank==0.1.0->-r requirements.txt (line 5)) (1.3.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from lexrank==0.1.0->-r requirements.txt (line 5)) (1.5.2)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from lexrank==0.1.0->-r requirements.txt (line 5)) (0.17.3)\n",
      "Requirement already satisfied: path.py>=10.5 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from lexrank==0.1.0->-r requirements.txt (line 5)) (12.5.0)\n",
      "Requirement already satisfied: click in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nltk==3.6.2->-r requirements.txt (line 6)) (7.1.2)\n",
      "Requirement already satisfied: joblib in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nltk==3.6.2->-r requirements.txt (line 6)) (0.17.0)\n",
      "Requirement already satisfied: jinja2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (2.11.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (1.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (2.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (2.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (50.3.1.post20201107)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (0.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (8.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (2.0.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from spacy==3.0.6->-r requirements.txt (line 7)) (0.5.2)\n",
      "Requirement already satisfied: graphviz>=0.13 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from pytextrank->-r requirements.txt (line 8)) (0.16)\n",
      "Requirement already satisfied: icecream>=2.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from pytextrank->-r requirements.txt (line 8)) (2.1.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from pytextrank->-r requirements.txt (line 8)) (2.5)\n",
      "Requirement already satisfied: fsspec in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (0.8.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (0.0.12)\n",
      "Requirement already satisfied: pandas in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (1.1.3)\n",
      "Requirement already satisfied: xxhash in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (2.0.2)\n",
      "Requirement already satisfied: dill in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (0.3.4)\n",
      "Requirement already satisfied: multiprocess in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from datasets==1.6.2->-r requirements.txt (line 9)) (0.70.12.2)\n",
      "Requirement already satisfied: sacrebleu in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (1.5.1)\n",
      "Requirement already satisfied: wmd in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (1.3.2)\n",
      "Requirement already satisfied: pyrouge in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.1.3)\n",
      "Requirement already satisfied: six in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (1.15.0)\n",
      "Requirement already satisfied: pytorch-pretrained-bert in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.6.2)\n",
      "Requirement already satisfied: psutil in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (5.7.2)\n",
      "Requirement already satisfied: pyemd==0.5.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.5.1)\n",
      "Requirement already satisfied: stanza in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (1.2.1)\n",
      "Requirement already satisfied: blanc in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.2.1)\n",
      "Requirement already satisfied: moverscore in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (1.0.3)\n",
      "Requirement already satisfied: bert-score in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.3.9)\n",
      "Requirement already satisfied: gin-config in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from summ_eval->-r requirements.txt (line 11)) (0.4.0)\n",
      "Requirement already satisfied: nbconvert in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (6.0.7)\n",
      "Requirement already satisfied: ipykernel in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (5.3.4)\n",
      "Requirement already satisfied: jupyter-console in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (6.2.0)\n",
      "Requirement already satisfied: qtconsole in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (4.7.7)\n",
      "Requirement already satisfied: notebook in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (6.1.4)\n",
      "Requirement already satisfied: ipywidgets in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 13)) (7.5.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from gensim==3.8.3->-r requirements.txt (line 14)) (3.0.0)\n",
      "Requirement already satisfied: scikit-learn in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from sklearn->-r requirements.txt (line 15)) (0.23.2)\n",
      "Requirement already satisfied: pyppmd>=0.14.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (0.15.0)\n",
      "Requirement already satisfied: bcj-cffi<0.6.0,>=0.5.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (0.5.1)\n",
      "Requirement already satisfied: texttable in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (1.6.3)\n",
      "Requirement already satisfied: brotli>=1.0.9; platform_python_implementation == \"CPython\" in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (1.0.9)\n",
      "Requirement already satisfied: pyzstd<0.15.0,>=0.14.4 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (0.14.4)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (0.2.3)\n",
      "Requirement already satisfied: pycryptodomex>=3.6.6 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from py7zr==0.16.1->-r requirements.txt (line 16)) (3.10.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from packaging->transformers==4.5.1->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.1->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.1->-r requirements.txt (line 1)) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.1->-r requirements.txt (line 1)) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from requests->transformers==4.5.1->-r requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: appdirs in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from urlextract>=0.7->lexrank==0.1.0->-r requirements.txt (line 5)) (1.4.4)\n",
      "Requirement already satisfied: uritools in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from urlextract>=0.7->lexrank==0.1.0->-r requirements.txt (line 5)) (3.0.2)\n",
      "Requirement already satisfied: path in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from path.py>=10.5->lexrank==0.1.0->-r requirements.txt (line 5)) (15.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jinja2->spacy==3.0.6->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: asttokens>=2.0.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from icecream>=2.1->pytextrank->-r requirements.txt (line 8)) (2.0.5)\n",
      "Requirement already satisfied: pygments>=2.2.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from icecream>=2.1->pytextrank->-r requirements.txt (line 8)) (2.7.2)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from icecream>=2.1->pytextrank->-r requirements.txt (line 8)) (0.4.4)\n",
      "Requirement already satisfied: executing>=0.3.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from icecream>=2.1->pytextrank->-r requirements.txt (line 8)) (0.6.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from networkx>=2.0->pytextrank->-r requirements.txt (line 8)) (4.4.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from pandas->datasets==1.6.2->-r requirements.txt (line 9)) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from pandas->datasets==1.6.2->-r requirements.txt (line 9)) (2.8.1)\n",
      "Requirement already satisfied: portalocker==2.0.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from sacrebleu->summ_eval->-r requirements.txt (line 11)) (2.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from pytorch-pretrained-bert->summ_eval->-r requirements.txt (line 11)) (1.17.99)\n",
      "Requirement already satisfied: protobuf in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from stanza->summ_eval->-r requirements.txt (line 11)) (3.17.3)\n",
      "Requirement already satisfied: typing in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from moverscore->summ_eval->-r requirements.txt (line 11)) (3.7.4.3)\n",
      "Requirement already satisfied: matplotlib in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from bert-score->summ_eval->-r requirements.txt (line 11)) (3.3.2)\n",
      "Requirement already satisfied: defusedxml in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (1.4.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.8.4)\n",
      "Requirement already satisfied: testpath in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.4.4)\n",
      "Requirement already satisfied: traitlets>=4.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (5.0.5)\n",
      "Requirement already satisfied: jupyter-core in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (4.6.3)\n",
      "Requirement already satisfied: bleach in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (3.2.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.5.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (0.1.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 13)) (5.0.8)\n",
      "Requirement already satisfied: jupyter-client in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 13)) (6.1.7)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 13)) (7.19.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 13)) (6.0.4)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 13)) (3.0.8)\n",
      "Requirement already satisfied: ipython-genutils in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from qtconsole->jupyter->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: qtpy in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from qtconsole->jupyter->-r requirements.txt (line 13)) (1.9.0)\n",
      "Requirement already satisfied: pyzmq>=17.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from qtconsole->jupyter->-r requirements.txt (line 13)) (19.0.2)\n",
      "Requirement already satisfied: prometheus-client in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (0.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 13)) (0.9.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 13)) (3.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from scikit-learn->sklearn->-r requirements.txt (line 15)) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.14.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from bcj-cffi<0.6.0,>=0.5.1->py7zr==0.16.1->-r requirements.txt (line 16)) (1.14.3)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.99 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->summ_eval->-r requirements.txt (line 11)) (1.20.99)\n",
      "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->summ_eval->-r requirements.txt (line 11)) (0.4.2)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from boto3->pytorch-pretrained-bert->summ_eval->-r requirements.txt (line 11)) (0.10.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from matplotlib->bert-score->summ_eval->-r requirements.txt (line 11)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from matplotlib->bert-score->summ_eval->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: webencodings in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 13)) (0.5.1)\n",
      "Requirement already satisfied: async-generator in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->-r requirements.txt (line 13)) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter->-r requirements.txt (line 13)) (1.4.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 13)) (3.2.0)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.7.5)\n",
      "Requirement already satisfied: backcall in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.17.1)\n",
      "Requirement already satisfied: wcwidth in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->-r requirements.txt (line 13)) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: pycparser in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from cffi>=1.14.0->bcj-cffi<0.6.0,>=0.5.1->py7zr==0.16.1->-r requirements.txt (line 16)) (2.20)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter->-r requirements.txt (line 13)) (20.3.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /data/lily/mmm274/anaconda3/lib/python3.8/site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->-r requirements.txt (line 13)) (0.7.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pFDLAguuRYti"
   },
   "outputs": [],
   "source": [
    "## Uncomment to restart runtime if prompted to do so in the previous cell; else ignore\n",
    "## Restart runtime to install modules\n",
    "# import os\n",
    "# os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment to move back into the Summertime directory if restarted runtime\n",
    "# %cd SummerTime/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q1tna-CoXccl",
    "outputId": "84ff21e9-7008-499b-b223-f204363a6354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/bheinzerling/pyrouge.git\n",
      "  Cloning https://github.com/bheinzerling/pyrouge.git to /tmp/pip-req-build-u3ae59bd\n",
      "Building wheels for collected packages: pyrouge\n",
      "  Building wheel for pyrouge (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191915 sha256=d1d8f935101ed24af7392cb647bb65198ea94f6265cc007b0e9a483cbd585e80\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2ul06_jw/wheels/33/46/ed/a3751151da9865df57f1333c182c8cb2ac2a7a419bbb5f1258\n",
      "Successfully built pyrouge\n",
      "Installing collected packages: pyrouge\n",
      "  Attempting uninstall: pyrouge\n",
      "    Found existing installation: pyrouge 0.1.3\n",
      "    Uninstalling pyrouge-0.1.3:\n",
      "      Successfully uninstalled pyrouge-0.1.3\n",
      "Successfully installed pyrouge-0.1.3\n"
     ]
    }
   ],
   "source": [
    "## Finish setup\n",
    "\n",
    "# Setup ROUGE\n",
    "!export ROUGE_HOME=/usr/local/lib/python3.7/dist-packages/summ_eval/ROUGE-1.5.5/\n",
    "!pip install -U  git+https://github.com/bheinzerling/pyrouge.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KsF1YSE8Oh2r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules for this notebook\n",
    "\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2_w-G2sYVk7"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8mlHZTueGse"
   },
   "source": [
    "### Supported Models\n",
    "\n",
    "SummerTime supports different models (*e.g.,* TextRank, BART, Longformer) as well as model wrappers for more complex summariztion tasks (*e.g.,* JointModel for multi-doc summarzation, BM25 retrieval for query-based summarization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nks3fuiqeTTX",
    "outputId": "17fc39b9-7cee-4215-d237-e196b8c5656e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'model.single_doc.bart_model.BartModel'>,\n",
      " <class 'model.single_doc.lexrank_model.LexRankModel'>,\n",
      " <class 'model.single_doc.longformer_model.LongformerModel'>,\n",
      " <class 'model.single_doc.pegasus_model.PegasusModel'>,\n",
      " <class 'model.single_doc.textrank_model.TextRankModel'>,\n",
      " <class 'model.multi_doc.multi_doc_joint_model.MultiDocJointModel'>,\n",
      " <class 'model.multi_doc.multi_doc_separate_model.MultiDocSeparateModel'>,\n",
      " <class 'model.dialogue.hmnet_model.HMNetModel'>,\n",
      " <class 'model.query_based.tf_idf_model.TFIDFSummModel'>,\n",
      " <class 'model.query_based.bm25_model.BM25SummModel'>]\n"
     ]
    }
   ],
   "source": [
    "from model import SUPPORTED_SUMM_MODELS\n",
    "\n",
    "pprint(SUPPORTED_SUMM_MODELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MueJBGGRDx_p"
   },
   "source": [
    "### Automatic Pipeline Assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91GZr7NVYVlD"
   },
   "source": [
    "### Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5xjUxipwYVk-"
   },
   "outputs": [],
   "source": [
    "import model\n",
    "\n",
    "# Users can load a default summarization model\n",
    "sample_model = model.summarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qVuMfAWRYVlA"
   },
   "outputs": [],
   "source": [
    "from model import SUPPORTED_SUMM_MODELS, LexRankModel, PegasusModel\n",
    "\n",
    "# Or a specific model\n",
    "pegasus = PegasusModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XWzGHXYUYVlE",
    "outputId": "2cf9aa74-595a-4597-acd5-8a14b84a3b38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegasus is the default singe-document summarization model.\n",
      "Pegasus is a abstractive, neural model for summarization. \n",
      " #################### \n",
      " Introduced in 2019, a large neural abstractive summarization model trained on web crawl and news data.\n",
      " Strengths: \n",
      " - High accuracy \n",
      " - Performs well on almost all kinds of non-literary written text \n",
      " Weaknesses: \n",
      " - High memory usage \n",
      " Initialization arguments: \n",
      " - `device = 'cpu'` specifies the device the model is stored on and uses for computation. Use `device='gpu'` to run on an Nvidia GPU.\n"
     ]
    }
   ],
   "source": [
    "# Users can easily access documentation to assist with model selection\n",
    "sample_model.show_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SGQ8FqgYVlK"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNJ8WbcgYVlN",
    "outputId": "240cd6c6-6f96-4c0e-d376-6a70b5aec651"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"California's largest electricity provider has turned off power to hundreds of thousands of customers.\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\n",
    "    \"\"\" PG&E stated it scheduled the blackouts in response to forecasts for high winds amid dry conditions. \n",
    "    The aim is to reduce the risk of wildfires. Nearly 800 thousand customers were scheduled to be affected \n",
    "    by the shutoffs which were expected to last through at least midday tomorrow.\"\"\"\n",
    "]\n",
    "\n",
    "sample_model.summarize(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mc-6dI_RYVlQ"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMth4yUce8IR"
   },
   "source": [
    "### Datasets supported\n",
    "\n",
    "SummerTime supports different summarization datasets across different domains (*e.g.,* CNNDM dataset - news article corpus, Samsum - dialogue corpus, QM-Sum - query-based dialogue corpus, MultiNews - multi-document corpus, ML-sum - multi-lingual corpus, PubMedQa - Medical domain, Arxiv - Science papers domain, among others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DULD_cWhe8IS",
    "outputId": "b505223a-14bf-4623-c711-4fe8553807e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'dataset.huggingface_datasets.CnndmDataset'>,\n",
      " <class 'dataset.huggingface_datasets.MultinewsDataset'>,\n",
      " <class 'dataset.huggingface_datasets.SamsumDataset'>,\n",
      " <class 'dataset.huggingface_datasets.XsumDataset'>,\n",
      " <class 'dataset.huggingface_datasets.PubmedqaDataset'>,\n",
      " <class 'dataset.huggingface_datasets.MlsumDataset'>,\n",
      " <class 'dataset.non_huggingface_datasets.ScisummnetDataset'>,\n",
      " <class 'dataset.non_huggingface_datasets.SummscreenDataset'>,\n",
      " <class 'dataset.non_huggingface_datasets.QMsumDataset'>,\n",
      " <class 'dataset.non_huggingface_datasets.ArxivDataset'>]\n"
     ]
    }
   ],
   "source": [
    "from dataset import SUPPORTED_SUMM_DATASETS\n",
    "\n",
    "pprint(SUPPORTED_SUMM_DATASETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go7c_qboLx0t"
   },
   "source": [
    "### Dataset Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vzqFrrKJYVlU",
    "outputId": "59517a79-d4f3-4c6b-eb3e-0c7f8bbd5f03"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/lily/mmm274/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n"
     ]
    }
   ],
   "source": [
    "import dataset\n",
    "\n",
    "cnn_dataset = dataset.CnndmDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mhpjrvfhYVlV",
    "outputId": "31bb139b-2471-4c2e-a9c7-6a863b9e3bc1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/287113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(\"{'source': 'It\\\\'s official: U.S. President Barack Obama wants lawmakers to \"\n",
      " 'weigh in on whether to use military force in Syria. Obama sent a letter to '\n",
      " 'the heads of the House and Senate on Saturday night, hours after announcing '\n",
      " 'that he believes military action against Syrian targets is the right step to '\n",
      " 'take over the alleged use of chemical weapons. The proposed legislation from '\n",
      " 'Obama asks Congress to approve the use of military force \"to deter, disrupt, '\n",
      " 'prevent and degrade the potential for future uses of chemical weapons or '\n",
      " 'other weapons of mass destruction.\" It\\\\\\'s a step that is set to turn an '\n",
      " 'international crisis into a fierce domestic political battle. There are key '\n",
      " 'questions looming over the debate: What did U.N. weapons inspectors find in '\n",
      " 'Syria? What happens if Congress votes no? And how will the Syrian government '\n",
      " 'react? In a televised address from the White House Rose Garden earlier '\n",
      " 'Saturday, the president said he would take his case to Congress, not because '\n",
      " 'he has to -- but because he wants to. \"While I believe I have the authority '\n",
      " 'to carry out this military action without specific congressional '\n",
      " 'authorization, I know that the country will be stronger if we take this '\n",
      " 'course, and our actions will be even more effective,\" he said. \"We should '\n",
      " 'have this debate, because the issues are too big for business as usual.\" '\n",
      " 'Obama said top congressional leaders had agreed to schedule a debate when '\n",
      " 'the body returns to Washington on September 9. The Senate Foreign Relations '\n",
      " 'Committee will hold a hearing over the matter on Tuesday, Sen. Robert '\n",
      " \"Menendez said. Transcript: Read Obama\\\\'s full remarks . Syrian crisis: \"\n",
      " \"Latest developments . U.N. inspectors leave Syria . Obama\\\\'s remarks came \"\n",
      " 'shortly after U.N. inspectors left Syria, carrying evidence that will '\n",
      " 'determine whether chemical weapons were used in an attack early last week in '\n",
      " 'a Damascus suburb. \"The aim of the game here, the mandate, is very clear -- '\n",
      " 'and that is to ascertain whether chemical weapons were used -- and not by '\n",
      " 'whom,\" U.N. spokesman Martin Nesirky told reporters on Saturday. But who '\n",
      " 'used the weapons in the reported toxic gas attack in a Damascus suburb on '\n",
      " 'August 21 has been a key point of global debate over the Syrian crisis. Top '\n",
      " \"U.S. officials have said there\\\\'s no doubt that the Syrian government was \"\n",
      " 'behind it, while Syrian officials have denied responsibility and blamed '\n",
      " 'jihadists fighting with the rebels. British and U.S. intelligence reports '\n",
      " 'say the attack involved chemical weapons, but U.N. officials have stressed '\n",
      " 'the importance of waiting for an official report from inspectors. The '\n",
      " 'inspectors will share their findings with U.N. Secretary-General Ban Ki-moon '\n",
      " \"Ban, who has said he wants to wait until the U.N. team\\\\'s final report is \"\n",
      " 'completed before presenting it to the U.N. Security Council. The '\n",
      " 'Organization for the Prohibition of Chemical Weapons, which nine of the '\n",
      " 'inspectors belong to, said Saturday that it could take up to three weeks to '\n",
      " 'analyze the evidence they collected. \"It needs time to be able to analyze '\n",
      " 'the information and the samples,\" Nesirky said. He noted that Ban has '\n",
      " 'repeatedly said there is no alternative to a political solution to the '\n",
      " 'crisis in Syria, and that \"a military solution is not an option.\" Bergen:  '\n",
      " \"Syria is a problem from hell for the U.S. Obama: \\\\'This menace must be \"\n",
      " \"confronted\\\\' Obama\\\\'s senior advisers have debated the next steps to take, \"\n",
      " \"and the president\\\\'s comments Saturday came amid mounting political \"\n",
      " 'pressure over the situation in Syria. Some U.S. lawmakers have called for '\n",
      " 'immediate action while others warn of stepping into what could become a '\n",
      " 'quagmire. Some global leaders have expressed support, but the British '\n",
      " \"Parliament\\\\'s vote against military action earlier this week was a blow to \"\n",
      " \"Obama\\\\'s hopes of getting strong backing from key NATO allies. On Saturday, \"\n",
      " 'Obama proposed what he said would be a limited military action against '\n",
      " 'Syrian President Bashar al-Assad. Any military attack would not be '\n",
      " \"open-ended or include U.S. ground forces, he said. Syria\\\\'s alleged use of \"\n",
      " 'chemical weapons earlier this month \"is an assault on human dignity,\" the '\n",
      " 'president said. A failure to respond with force, Obama argued,  \"could lead '\n",
      " 'to escalating use of chemical weapons or their proliferation to terrorist '\n",
      " 'groups who would do our people harm. In a world with many dangers, this '\n",
      " 'menace must be confronted.\" Syria missile strike: What would happen next? '\n",
      " 'Map: U.S. and allied assets around Syria . Obama decision came Friday night '\n",
      " '. On Friday night, the president made a last-minute decision to consult '\n",
      " \"lawmakers. What will happen if they vote no? It\\\\'s unclear. A senior \"\n",
      " 'administration official told CNN that Obama has the authority to act without '\n",
      " 'Congress -- even if Congress rejects his request for authorization to use '\n",
      " 'force. Obama on Saturday continued to shore up support for a strike on the '\n",
      " 'al-Assad government. He spoke by phone with French President Francois '\n",
      " 'Hollande before his Rose Garden speech. \"The two leaders agreed that the '\n",
      " 'international community must deliver a resolute message to the Assad regime '\n",
      " '-- and others who would consider using chemical weapons -- that these crimes '\n",
      " 'are unacceptable and those who violate this international norm will be held '\n",
      " 'accountable by the world,\" the White House said. Meanwhile, as uncertainty '\n",
      " 'loomed over how Congress would weigh in, U.S. military officials said they '\n",
      " 'remained at the ready. 5 key assertions: U.S. intelligence report on Syria . '\n",
      " 'Syria: Who wants what after chemical weapons horror . Reactions mixed to '\n",
      " \"Obama\\\\'s speech . A spokesman for the Syrian National Coalition said that \"\n",
      " 'the opposition group was disappointed by Obama\\\\\\'s announcement. \"Our fear '\n",
      " 'now is that the lack of action could embolden the regime and they repeat his '\n",
      " 'attacks in a more serious way,\" said spokesman Louay Safi. \"So we are quite '\n",
      " 'concerned.\" Some members of Congress applauded Obama\\\\\\'s decision. House '\n",
      " 'Speaker John Boehner, Majority Leader Eric Cantor, Majority Whip Kevin '\n",
      " 'McCarthy and Conference Chair Cathy McMorris Rodgers issued a statement '\n",
      " 'Saturday praising the president. \"Under the Constitution, the responsibility '\n",
      " 'to declare war lies with Congress,\" the Republican lawmakers said. \"We are '\n",
      " 'glad the president is seeking authorization for any military action in Syria '\n",
      " 'in response to serious, substantive questions being raised.\" More than 160 '\n",
      " \"legislators, including 63 of Obama\\\\'s fellow Democrats, had signed letters \"\n",
      " 'calling for either a vote or at least a \"full debate\" before any U.S. '\n",
      " 'action. British Prime Minister David Cameron, whose own attempt to get '\n",
      " 'lawmakers in his country to support military action in Syria failed earlier '\n",
      " 'this week, responded to Obama\\\\\\'s speech in a Twitter post Saturday. \"I '\n",
      " 'understand and support Barack Obama\\\\\\'s position on Syria,\" Cameron said. '\n",
      " 'An influential lawmaker in Russia -- which has stood by Syria and criticized '\n",
      " 'the United States -- had his own theory. \"The main reason Obama is turning '\n",
      " 'to the Congress:  the military operation did not get enough support either '\n",
      " 'in the world, among allies of the US or in the United States itself,\" Alexei '\n",
      " 'Pushkov, chairman of the international-affairs committee of the Russian '\n",
      " 'State Duma, said in a Twitter post. In the United States, scattered groups '\n",
      " 'of anti-war protesters around the country took to the streets Saturday. '\n",
      " '\"Like many other Americans...we\\\\\\'re just tired of the United States '\n",
      " 'getting involved and invading and bombing other countries,\" said Robin '\n",
      " 'Rosecrans, who was among hundreds at a Los Angeles demonstration. What do '\n",
      " \"Syria\\\\'s neighbors think? Why Russia, China, Iran stand by Assad . \"\n",
      " \"Syria\\\\'s government unfazed . After Obama\\\\'s speech, a military and \"\n",
      " 'political analyst on Syrian state TV said Obama is \"embarrassed\" that Russia '\n",
      " 'opposes military action against Syria, is \"crying for help\" for someone to '\n",
      " 'come to his rescue and is facing two defeats -- on the political and '\n",
      " \"military levels. Syria\\\\'s prime minister appeared unfazed by the \"\n",
      " 'saber-rattling. \"The Syrian Army\\\\\\'s status is on maximum readiness and '\n",
      " 'fingers are on the trigger to confront all challenges,\" Wael Nader al-Halqi '\n",
      " 'said during a meeting with a delegation of Syrian expatriates from Italy, '\n",
      " 'according to a banner on Syria State TV that was broadcast prior to '\n",
      " \"Obama\\\\'s address. An anchor on Syrian state television said Obama \"\n",
      " '\"appeared to be preparing for an aggression on Syria based on repeated '\n",
      " 'lies.\" A top Syrian diplomat told the state television network that Obama '\n",
      " 'was facing pressure to take military action from Israel, Turkey, some Arabs '\n",
      " 'and right-wing extremists in the United States. \"I think he has done well by '\n",
      " 'doing what Cameron did in terms of taking the issue to Parliament,\" said '\n",
      " \"Bashar Jaafari, Syria\\\\'s ambassador to the United Nations. Both Obama and \"\n",
      " 'Cameron, he said, \"climbed to the top of the tree and don\\\\\\'t know how to '\n",
      " 'get down.\" The Syrian government has denied that it used chemical weapons in '\n",
      " 'the August 21 attack, saying that jihadists fighting with the rebels used '\n",
      " 'them in an effort to turn global sentiments against it. British intelligence '\n",
      " 'had put the number of people killed in the attack at more than 350. On '\n",
      " 'Saturday, Obama said \"all told, well over 1,000 people were murdered.\" U.S. '\n",
      " 'Secretary of State John Kerry on Friday cited a death toll of 1,429, more '\n",
      " 'than 400 of them children. No explanation was offered for the discrepancy. '\n",
      " \"Iran: U.S. military action in Syria would spark \\\\'disaster\\\\' Opinion: Why \"\n",
      " \"strikes in Syria are a bad idea .', 'summary': 'Syrian official: Obama \"\n",
      " 'climbed to the top of the tree, \"doesn\\\\\\'t know how to get down\"\\\\nObama '\n",
      " 'sends a letter to the heads of the House and Senate .\\\\nObama to seek '\n",
      " 'congressional approval on military action against Syria .\\\\nAim is to '\n",
      " \"determine whether CW were used, not by whom, says U.N. spokesman .'}\")\n"
     ]
    }
   ],
   "source": [
    "# Data is loaded using a generator to save on space and time\n",
    "\n",
    "data_instance = next(cnn_dataset.train_set)\n",
    "print(\"\\n\")\n",
    "pprint(data_instance.__str__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcO7hkZLYVlX"
   },
   "source": [
    "### A non-neural model\n",
    "Below we train an unsupervised non-neural summarizer with a subset of the cnn_dailymail dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo8ceRCEYVlY",
    "outputId": "631fb685-5763-4056-df36-9b9ff65d0d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming '\n",
      " \"his third gold in Moscow as he anchored Jamaica to victory in the men's \"\n",
      " '4x100m relay. The fastest man in the world charged clear of United States '\n",
      " 'rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar '\n",
      " 'Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished '\n",
      " 'second in 37.56 seconds with Canada taking the bronze after Britain were '\n",
      " 'disqualified for a faulty handover. The 26-year-old Bolt has now collected '\n",
      " 'eight gold medals at world championships, equaling the record held by '\n",
      " 'American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention '\n",
      " 'the small matter of six Olympic titles. The relay triumph followed '\n",
      " 'individual successes in the 100 and 200 meters in the Russian capital. \"I\\'m '\n",
      " \"proud of myself and I'll continue to work to dominate for as long as \"\n",
      " 'possible,\" Bolt said, having previously expressed his intention to carry on '\n",
      " 'until the 2016 Rio Olympics. Victory was never seriously in doubt once he '\n",
      " 'got the baton safely in hand from Ashmeade, while Gatlin and the United '\n",
      " 'States third leg runner Rakieem Salaam had problems. Gatlin strayed out of '\n",
      " 'his lane as he struggled to get full control of their baton and was never '\n",
      " \"able to get on terms with Bolt. Earlier, Jamaica's women underlined their \"\n",
      " 'dominance in the sprint events by winning the 4x100m relay gold, anchored by '\n",
      " 'Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their '\n",
      " 'quartet recorded a championship record of 41.29 seconds, well clear of '\n",
      " 'France, who crossed the line in second place in 42.73 seconds. Defending '\n",
      " 'champions, the United States, were initially back in the bronze medal '\n",
      " 'position after losing time on the second handover between Alexandria '\n",
      " 'Anderson and English Gardner, but promoted to silver when France were '\n",
      " 'subsequently disqualified for an illegal handover. The British quartet, who '\n",
      " \"were initially fourth, were promoted to the bronze which eluded their men's \"\n",
      " 'team. Fraser-Pryce, like Bolt aged 26, became the first woman to achieve '\n",
      " 'three golds in the 100-200 and the relay. In other final action on the last '\n",
      " \"day of the championships, France's Teddy Tamgho became the third man to leap \"\n",
      " 'over 18m in the triple jump, exceeding the mark by four centimeters to take '\n",
      " \"gold. Germany's Christina Obergfoll finally took gold at global level in the \"\n",
      " \"women's javelin after five previous silvers, while Kenya's Asbel Kiprop \"\n",
      " \"easily won a tactical men's 1500m final. Kiprop's compatriot Eunice Jepkoech \"\n",
      " \"Sum was a surprise winner of the women's 800m. Bolt's final dash for golden \"\n",
      " 'glory brought the eight-day championship to a rousing finale, but while the '\n",
      " 'hosts topped the medal table from the United States there was criticism of '\n",
      " 'the poor attendances in the Luzhniki Stadium. There was further concern when '\n",
      " 'their pole vault gold medalist Yelena Isinbayeva made controversial remarks '\n",
      " 'in support of Russia\\'s new laws, which make \"the propagandizing of '\n",
      " 'non-traditional sexual relations among minors\" a criminal offense. She later '\n",
      " 'attempted to clarify her comments, but there were renewed calls by gay '\n",
      " 'rights groups for a boycott of the 2014 Winter Games in Sochi, the next '\n",
      " 'major sports event in Russia.',\n",
      " 'Kansas City, Missouri (CNN) -- The General Services Administration, already '\n",
      " 'under investigation for lavish spending, allowed an employee to telecommute '\n",
      " \"from Hawaii even though he is based at the GSA's Kansas City, Missouri, \"\n",
      " 'office, a CNN investigation has found. It cost more than $24,000 for the '\n",
      " 'business development specialist to travel to and from the mainland United '\n",
      " 'States over the past year. He is among several hundred GSA \"virtual\" workers '\n",
      " 'who also travel to various conferences and their home offices, costing the '\n",
      " 'agency millions of dollars over the past three years. Under the program, '\n",
      " 'employees work from home and may live in another state from the region in '\n",
      " \"which they're actually assigned. The Kansas City employee, who started his \"\n",
      " 'job in January 2011, is paid $84,440 and works from his home in Honolulu, a '\n",
      " 'GSA representative confirmed. In the past year, according to GSA travel '\n",
      " 'records, the employee has flown back to the mainland nine times for '\n",
      " 'conferences and meetings. Four of those trips were to St. Louis; four were '\n",
      " 'to Washington, with a side trip to Cincinnati; and one was to San Diego. The '\n",
      " \"total cost to taxpayers was $24,221. Jason Klumb, the GSA's regional \"\n",
      " 'administrator for Kansas City, defended the hire. \"The cost of that travel '\n",
      " 'was included in the consideration of his candidacy as an employee as '\n",
      " 'compared with the other applicants,\" Klumb said. \"And when factoring all of '\n",
      " 'those in, it was determined that he was the best candidate, even in light of '\n",
      " 'the cost that would be incurred.\" Klumb called the GSA\\'s teleworking '\n",
      " 'program \"a successful program that\\'s going to lead to cost savings for '\n",
      " 'taxpayers.\" But a GSA spokeswoman said, \"We are not going to defend this '\n",
      " 'type of travel.\" And a GSA employee in Kansas City, who requested anonymity, '\n",
      " 'said that hiring someone in Hawaii to work for the Kansas City region was '\n",
      " 'ludicrous. \"It doesn\\'t make sense,\" the employee said. \"When you consider '\n",
      " 'everything you need when you hire someone, it would have been better to look '\n",
      " 'for someone in the Kansas City area. It would have reduced the cost of '\n",
      " 'travel by at least 70 percent when you look at just the airfare of what it '\n",
      " 'takes to from Honolulu to Washington, D.C., where a lot of business is '\n",
      " 'done.\" Dan Tangherlini, who was appointed acting GSA administrator this '\n",
      " 'year, said the agency was examining the cost of the entire teleworking '\n",
      " 'program. \"I think the most important part for the GSA to think about is make '\n",
      " 'sure we open ourselves up, avail ourselves to all the smart people in the '\n",
      " 'country, but then also make sure we have a clear business case,\" he said. '\n",
      " '\"If we have someone who is working in Nebraska but reporting to Boston, '\n",
      " \"there has to be a clear explanation for what value they're providing, and \"\n",
      " \"you've got to give me the business case. You've got to explain to me why \"\n",
      " \"that's a cost-effective move for the American people, and that's a new \"\n",
      " 'standard that we\\'re asking everyone at GSA to adhere to.\" The GSA \"virtual '\n",
      " 'employee\" program is different from telework programs offered by many '\n",
      " \"private companies including CNN's parent company, Turner Broadcasting, in \"\n",
      " 'which some employees are encouraged to work from home some days of the week, '\n",
      " 'partially to reduce traffic congestion. The House Committee on Oversight and '\n",
      " \"Government Reform requested details about the GSA's teleworking program in \"\n",
      " 'June. That followed disclosures that 95 virtual employees, including 12 in '\n",
      " 'supervisory positions, spent nearly $750,000 in travel costs between October '\n",
      " '2010 and June 2011. \"The American people have a right to know that federal '\n",
      " 'bureaucrats who enjoy the benefits of virtual work are eligible and '\n",
      " 'responsible stewards of the taxpayer dollars that support the program,\" '\n",
      " 'according to a letter from committee Chairman Rep. Darrell Issa, '\n",
      " 'R-California, to the GSA. The details requested by Issa about the GSA '\n",
      " 'program have not been provided to the committee. CNN also requested the '\n",
      " 'information more than two months ago through the federal Freedom of '\n",
      " 'Information Act but has been repeatedly told by the GSA that FOIA staff '\n",
      " 'members have not finished compiling the material. The General Services '\n",
      " 'Administration, which has more than 12,600 employees and a $26.3 billion '\n",
      " 'budget, is a relatively obscure federal agency that handles government real '\n",
      " 'estate and other non-military procurement. Congress launched an '\n",
      " \"investigation into the GSA after a scathing inspector general's report \"\n",
      " \"issued this year showed lavish spending -- $823,000 -- at the agency's \"\n",
      " 'Western Regions Conference in Las Vegas in October 2010. The controversy '\n",
      " 'became politically toxic after reports and video clips of the lavish '\n",
      " 'conference were released. The revelation prompted taxpayer indignation, '\n",
      " 'embarrassed the administration and put a spotlight on wasteful spending by '\n",
      " 'the GSA. Jeff Neely, the GSA official who organized the conference, '\n",
      " \"resigned, as did the agency's administrator, Martha Johnson. Two of \"\n",
      " \"Johnson's deputies were fired, and eight other employees left the agency. \"\n",
      " 'Tangherlini, a former Treasury Department official, took over as acting GSA '\n",
      " 'administrator. In addition to the Las Vegas conference, the GSA apparently '\n",
      " 'spent $330,000 to relocate an employee from Denver to Hawaii and probably '\n",
      " 'millions more on other employees over a two-year period, according to a '\n",
      " 'transcript of an interview with a GSA event planner. And 84 GSA employees, '\n",
      " 'most of them supervisors or other senior staff -- all subjects of inspector '\n",
      " 'general investigations -- are still collecting their bonuses, totaling more '\n",
      " 'than $1 million in taxpayer money. In July, a CNN investigation revealed '\n",
      " \"that the GSA's Kansas City office spent more than $20,000 to send employees \"\n",
      " 'to cooking classes to build team spirit. While the classes do not amount to '\n",
      " 'a significant sum of money in the world of trillion-dollar government '\n",
      " 'budgets, insiders said it was part of the free-spending culture that went on '\n",
      " \"for years at the GSA's Kansas City regional headquarters. GSA spokeswoman \"\n",
      " \"Betsaida Alcantara said in a statement this year that all the agency's \"\n",
      " \"practices are under a top-down review. CNN's Sara Anwar, Elizabeth M. Nunez \"\n",
      " 'and Tom Cohen contributed to this report. Watch Erin Burnett weekdays 7pm '\n",
      " 'ET. For the latest from Erin Burnett click here.',\n",
      " 'Los Angeles (CNN) -- A medical doctor in Vancouver, British Columbia, said '\n",
      " 'Thursday that California arson suspect Harry Burkhart suffered from severe '\n",
      " 'mental illness in 2010, when she examined him as part of a team of doctors. '\n",
      " 'Dr. Blaga Stancheva, a family physician and specialist in obstetrics, said '\n",
      " 'both Burkhart and his mother, Dorothee, were her patients in Vancouver while '\n",
      " 'both were applying for refugee status in Canada. \"I was asked to diagnose '\n",
      " 'and treat Harry to support a claim explaining why he was unable to show up '\n",
      " 'in a small-claims court case,\" Stancheva told CNN in a phone interview. She '\n",
      " \"declined to cite the case or Burkhart's role in it. Stancheva said she and \"\n",
      " 'other doctors including a psychiatrist diagnosed Burkhart with \"autism, '\n",
      " 'severe anxiety, post-traumatic stress disorder and depression.\" The '\n",
      " 'diagnosis was spelled out in a letter she wrote for the small-claims court '\n",
      " 'case, Stancheva said. Stancheva, citing doctor-patient confidentiality, '\n",
      " 'would not elaborate further, nor would she identify the psychiatrist '\n",
      " 'involved in the diagnosis. Burkhart, a 24-year-old German national, has been '\n",
      " 'charged with 37 counts of arson following a string of 52 fires in Los '\n",
      " 'Angeles. The charges are in connection with arson fires at 12 locations '\n",
      " 'scattered through Hollywood, West Hollywood and Sherman Oaks, according to '\n",
      " 'authorities. Stancheva said the refugee applications by Burkhart and his '\n",
      " 'mother were denied by the Canadian government, and she has not seen Burkhart '\n",
      " 'since early March of 2010. \"I was shocked and dismayed at what happened in '\n",
      " 'Los Angeles, and it appears he was not being treated for his depression,\" '\n",
      " 'she said. Burkhart was in court on Wednesday for a preliminary hearing. '\n",
      " 'Prosecutors said his \"rage against Americans,\" triggered by his mother\\'s '\n",
      " 'arrest last week, motivated his \"campaign of terror\" with dozens of fires in '\n",
      " 'Hollywood and nearby communities. Burkhart kept his eyes closed and remained '\n",
      " \"limp during most of his hearing, requiring sheriff's deputies to hold him \"\n",
      " 'up. The district attorney called his courtroom behavior \"very bizarre.\" '\n",
      " '\"This defendant has engaged in a protracted campaign in which he has set, '\n",
      " 'the people believe, upwards of 52 arson fires in what essentially amounts to '\n",
      " 'a campaign of terror against this community,\" Los Angeles County Deputy '\n",
      " 'District Attorney Sean Carney said. \"The people believe he has engaged in '\n",
      " 'this conduct because he has a hatred for Americans.\" Carney told the court '\n",
      " 'Burkhart would flee the country if he was allowed out of jail on bond, but '\n",
      " 'Los Angeles Superior Court Judge Upinder Kalra said he had no choice but to '\n",
      " 'set bail. To go free while awaiting trial, Burkhart must post a $2.85 '\n",
      " 'million bond and surrender his German passport. It was revealed that '\n",
      " 'Burkhart is also under investigation for arson and fraud in relation to a '\n",
      " 'fire in Neukirchen, near Frankfurt, Germany. The worst arson sprees in the '\n",
      " \"city's history began last Friday morning with a car fire in Hollywood that \"\n",
      " 'spread to apartments above a garage, but no new fires have happened since '\n",
      " 'Burkhart was arrested Monday, Los Angeles District Attorney Steve Cooley '\n",
      " 'said. No one was hurt in the fires, but property damage costs are likely to '\n",
      " 'reach $3 million, authorities said. Cooley called it \"almost attempted '\n",
      " 'murder,\" because people were sleeping in apartments above where Burkhart '\n",
      " 'allegedly set cars on fire with incendiary devices placed under their '\n",
      " 'engines. The criminal complaint filed Wednesday also alleged that the fires '\n",
      " 'were \"caused by use of a device designed to accelerate the fire,\" Cooley '\n",
      " 'said. \"If found true, the allegation could mean additional custody time for '\n",
      " 'the defendant.\" \"In numerous instances, the cars were parked in carports, '\n",
      " 'resulting in the fires spreading to the adjacent occupied apartment '\n",
      " 'buildings,\" a sworn affidavit from a Los Angeles arson investigator said. '\n",
      " '\"The vast majority of these fires occurred late at night when the occupants '\n",
      " 'of the apartment buildings were asleep.\" Investigator Edward Nordskog\\'s '\n",
      " \"affidavit detailed Burkhart's behavior a day before the fires began, when he \"\n",
      " 'was in a federal courtroom during extradition proceedings for his mother. '\n",
      " '\"While in the audience, the defendant (Burkhart) began yelling in an angry '\n",
      " \"manner, 'F--k all Americans.' The defendant also attempted to communicate \"\n",
      " 'with his mother who was in custody. Shortly thereafter, the defendant was '\n",
      " 'ejected from the courtroom by Deputy U.S. Marshals,\" Nordskog wrote. '\n",
      " 'Dorothee Burkhart was arrested a day before on an international arrest '\n",
      " 'warrant issued by a district court in Frankfurt, Germany, said federal court '\n",
      " 'spokesman Gunther Meilinger. The 53-year-old German woman is wanted on 16 '\n",
      " 'counts of fraud and three counts of embezzlement, he said. The charges '\n",
      " 'include an allegation that she failed to pay for a breast enhancement '\n",
      " 'operation performed on her in 2004, Meilinger said. Most of the German '\n",
      " 'charges, however, stem from phony real estate deals that Dorothee Burkhart '\n",
      " 'allegedly conducted between 2000 and 2006. \"It is my opinion that the '\n",
      " \"defendant's criminal spree was motivated by his rage against Americans and \"\n",
      " 'that by setting these fires the defendant intended to harm and terrorize as '\n",
      " 'many residents of the city and county of Los Angeles as possible,\" Nordskog '\n",
      " \"wrote. A search of Burkhart's Hollywood apartment found newspaper clippings \"\n",
      " 'about the Los Angeles fires and articles from Germany reporting similar car '\n",
      " 'fires in Frankfurt, Germany in September, 2011, the investigator said. \"It '\n",
      " 'is my opinion based on my experience that it is highly likely the defendant '\n",
      " 'has a history of setting arson fires in Germany before he came to the United '\n",
      " 'States,\" Nordskog wrote. Burkhart\\'s mother is scheduled for another '\n",
      " 'extradition hearing Friday, while he is due back in court for arraignment on '\n",
      " 'January 24. Meanwhile, both Burkharts are housed in a Los Angeles jail.',\n",
      " '(CNN) -- Police arrested another teen Thursday, the sixth suspect jailed in '\n",
      " 'connection with the gang rape of a 15-year-old girl on a northern California '\n",
      " 'high school campus. Jose Carlos Montano, 18, was arrested on charges of '\n",
      " 'felony rape, rape in concert with force, and penetration with a foreign '\n",
      " 'object, said Richmond Police Lt. Mark Gagan. Montano was arrested Thursday '\n",
      " 'evening in San Pablo, California, a small town about two miles from the city '\n",
      " 'of Richmond, where the crime took place. Montano, who was held in lieu of '\n",
      " '$1.3 million bail, is accused of taking part in what police said was a '\n",
      " '2½-hour assault on the Richmond High School campus. Police said as many as '\n",
      " '10 people were involved in the rape in a dimly lit back alley at the school, '\n",
      " 'while another 10 people watched without calling 911. The victim was taken to '\n",
      " 'the hospital in critical condition, but was released Wednesday. Four other '\n",
      " 'teenage suspects were arraigned Thursday on charges connected to the rape. '\n",
      " 'Cody Ray Smith, described by the court as older than 14, pleaded not guilty '\n",
      " 'to charges of rape with a foreign object and rape by force. Two other '\n",
      " 'juveniles, Ari Abdallah Morales and Marcelles James Peter, appeared with '\n",
      " 'Smith at the Contra Costa County Superior Court, but did not enter a plea. '\n",
      " 'The court described Morales as younger than 16, and did not give an age for '\n",
      " 'Peter. All three juveniles, who wore bulletproof vests at the hearing, were '\n",
      " 'charged as adults. A fourth person, Manuel Ortega, 19, appeared separately '\n",
      " 'without an attorney and did not enter a plea. He did not wear a protective '\n",
      " 'vest. Another person, Salvador Rodriguez, 21, was arrested Tuesday night, '\n",
      " 'but he was not in court Thursday.',\n",
      " '(CNN) -- Thousands on Saturday fled the area in southwestern Ivory Coast '\n",
      " 'where attacks left seven U.N. peacekeepers and eight civilians dead, '\n",
      " 'according to a U.N. official. One attack occurred late Thursday and into '\n",
      " \"Friday near Para Village, not far from the west-central African nation's \"\n",
      " 'border with Liberia, according to the United Nations. Humanitarian '\n",
      " 'organizations reported Saturday they were expecting about 4,000 people in '\n",
      " 'Tai, said Remi Dourlot, a spokesman for the U.N. Office for the Coordination '\n",
      " 'of Humanitarian Affairs. Several hundred had arrived by midday Saturday in '\n",
      " 'the town, which is on the edge of Tai National Park. Another 35 families '\n",
      " \"crossed the Ivory Coast's southwest border into U.N. refugee camps in \"\n",
      " 'Liberia, and humanitarian groups said hundreds of others had been pushed '\n",
      " 'south by the violence, according to Dourlot. The movement comes after '\n",
      " 'blue-helmeted peacekeepers -- who were in the area because of threats '\n",
      " 'against civilians -- came under attack, the United Nations said in a '\n",
      " 'statement. Besides the U.N. peacekeepers, humanitarian groups reported eight '\n",
      " 'civilians died in violence, said Dourlot. U.N. Secretary-General Ban Ki-moon '\n",
      " 'on Friday called on the government of Ivory Coast \"to do its utmost to '\n",
      " 'identify the perpetrators and hold them accountable.\" He added that he '\n",
      " 'understood other peacekeepers remained in danger. \"Even tonight, after the '\n",
      " 'attack, more than 40 peacekeepers remain with the villagers in this remote '\n",
      " 'region to protect them from this armed group,\" Ban said. U.N. Operation in '\n",
      " \"Cote d'Ivoire and Ivory Coast troops have increased their presence in the \"\n",
      " 'area, Dourlot said Saturday. Members of the U.N. humanitarian affairs office '\n",
      " 'have deployed to Tai to coordinate relief efforts there with local '\n",
      " 'authorities. Clinton urges Ivory Coast dialogue . A spokeswoman for the U.N. '\n",
      " \"mission in Ivory Coast said Friday's incident was the first attack on \"\n",
      " 'peacekeepers since they entered the country in 2004. Sylvie van den '\n",
      " 'Wildenberg, in a telephone interview from her office in Abidjan, said the '\n",
      " 'remaining forces were continuing to protect area residents, \"who are living '\n",
      " 'in a very difficult terrain -- their villages scattered.\" Van den Wildenberg '\n",
      " 'said it was not clear who was responsible for the attack, which occurred '\n",
      " 'mid-afternoon. \"This is an area where you have so many different types of '\n",
      " 'armed people,\" she said. \"People have different aims and different reasons '\n",
      " 'to carry arms and to perpetrate attack. So this is a very complex '\n",
      " 'environment. We can\\'t extrapolate. We just can\\'t fingerpoint any group.\" '\n",
      " 'The peacekeepers were on a reconnaissance patrol because U.N. officials had '\n",
      " 'heard rumors several days earlier of armed men in the area threatening to '\n",
      " 'attack a village, she said. U.N. peacekeepers remained in Ivory Coast after '\n",
      " 'the 2010 presidential election, when the country was thrown into crisis '\n",
      " 'after incumbent President Laurent Gbagbo refused to acknowledge defeat to '\n",
      " 'former Prime Minister Alassane Ouattara. The latter was sworn in on May 21. '\n",
      " 'Gbagbo is in custody at the Hague, accused of crimes against humanity during '\n",
      " 'post-election violence that killed thousands. According to the United '\n",
      " 'Nations, its peacekeeping force in Ivory Coast as of April 30 included '\n",
      " 'nearly 11,000 uniformed personnel, as well as several hundred international '\n",
      " 'civilian personnel, local staff and volunteers. They provide technical, '\n",
      " \"logistical and security support to the government. CNN's Christabelle Fombu \"\n",
      " 'and Tom Watkins contributed to this report.']\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Get a slice of the train set - first 5 instances\n",
    "train_set = itertools.islice(cnn_dataset.train_set, 5)\n",
    "\n",
    "corpus = [instance.source for instance in train_set]\n",
    "pprint(corpus)\n",
    "\n",
    "trad_model = LexRankModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9GtpYpvhYVla",
    "outputId": "ad7e8698-79a8-4c1f-f6eb-aa8f223b5be2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/11490 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. '\n",
      " 'Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. '\n",
      " 'He was 88. Best died in hospice in Hickory, North Carolina, of complications '\n",
      " 'from pneumonia, said Steve Latshaw, a longtime friend and Hollywood '\n",
      " \"colleague. Although he'd been a busy actor for decades in theater and in \"\n",
      " 'Hollywood, Best didn\\'t become famous until 1979, when \"The Dukes of '\n",
      " 'Hazzard\\'s\" cornpone charms began beaming into millions of American homes '\n",
      " \"almost every Friday night. For seven seasons, Best's Rosco P. Coltrane \"\n",
      " 'chased the moonshine-running Duke boys back and forth across the back roads '\n",
      " 'of fictitious Hazzard County, Georgia, although his \"hot pursuit\" usually '\n",
      " 'ended with him crashing his patrol car. Although Rosco was slow-witted and '\n",
      " 'corrupt, Best gave him a childlike enthusiasm that got laughs and made him '\n",
      " 'endearing. His character became known for his distinctive \"kew-kew-kew\" '\n",
      " 'chuckle and for goofy catchphrases such as \"cuff \\'em and stuff \\'em!\" upon '\n",
      " \"making an arrest. Among the most popular shows on TV in the early '80s, \"\n",
      " '\"The Dukes of Hazzard\" ran until 1985 and spawned TV movies, an animated '\n",
      " 'series and video games. Several of Best\\'s \"Hazzard\" co-stars paid tribute '\n",
      " 'to the late actor on social media. \"I laughed and learned more from Jimmie '\n",
      " 'in one hour than from anyone else in a whole year,\" co-star John Schneider, '\n",
      " 'who played Bo Duke, said on Twitter. \"Give Uncle Jesse my love when you see '\n",
      " 'him dear friend.\" \"Jimmy Best was the most constantly creative person I have '\n",
      " 'ever known,\" said Ben Jones, who played mechanic Cooter on the show, in a '\n",
      " 'Facebook post. \"Every minute of his long life was spent acting, writing, '\n",
      " \"producing, painting, teaching, fishing, or involved in another of his life's \"\n",
      " 'many passions.\" Born Jewel Guy on July 26, 1926, in Powderly, Kentucky, Best '\n",
      " 'was orphaned at 3 and adopted by Armen and Essa Best, who renamed him James '\n",
      " 'and raised him in rural Indiana. Best served in the Army during World War II '\n",
      " 'before launching his acting career. In the 1950s and 1960s, he accumulated '\n",
      " 'scores of credits, playing a range of colorful supporting characters in such '\n",
      " 'TV shows as \"The Twilight Zone,\" \"Bonanza,\" \"The Andy Griffith Show\" and '\n",
      " '\"Gunsmoke.\" He later appeared in a handful of Burt Reynolds\\' movies, '\n",
      " 'including \"Hooper\" and \"The End.\" But Best will always be best known for his '\n",
      " '\"Hazzard\" role, which lives on in reruns. \"Jimmie was my teacher, mentor, '\n",
      " 'close friend and collaborator for 26 years,\" Latshaw said. \"I directed two '\n",
      " \"of his feature films, including the recent 'Return of the Killer Shrews,' a \"\n",
      " 'sequel he co-wrote and was quite proud of as he had made the first one more '\n",
      " 'than 50 years earlier.\" People we\\'ve lost in 2015 . CNN\\'s Stella Chan '\n",
      " 'contributed to this story.']\n",
      "['(CNN)James Best, best known for his portrayal of bumbling sheriff Rosco P. '\n",
      " 'Coltrane on TV\\'s \"The Dukes of Hazzard,\" died Monday after a brief illness. '\n",
      " '\"Jimmie was my teacher, mentor, close friend and collaborator for 26 years,\" '\n",
      " 'Latshaw said.']\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "text = [next(cnn_dataset.test_set).source]\n",
    "pprint(text)\n",
    "\n",
    "summary = trad_model.summarize(text)\n",
    "pprint(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pc5yHLO_YVlb",
    "outputId": "e7af379f-1553-48f2-a39e-fba7b6987fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LexRank is a extractive, non-neural model for summarization. \n",
      " #################### \n",
      " Works by using a graph-based method to identify the most salient sentences in the document. \n",
      "Strengths: \n",
      " - Fast with low memory usage \n",
      " - Allows for control of summary length \n",
      " Weaknesses: \n",
      " - Not as accurate as neural methods. \n",
      " Initialization arguments: \n",
      " - `corpus`: Unlabelled corpus of documents. ` \n",
      " - `summary_length`: sentence length of summaries \n",
      " - `threshold`: Level of salience required for sentence to be included in summary.\n"
     ]
    }
   ],
   "source": [
    "# More about lexrank\n",
    "\n",
    "trad_model.show_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjN2Mu_EYVlc"
   },
   "source": [
    "A spaCy pipeline for TextRank (another non-neueral extractive summarization model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ooX2BN4lYVld"
   },
   "outputs": [],
   "source": [
    "# TextRank model\n",
    "textrank = model.TextRankModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DcGi-4Q1YVld",
    "outputId": "51579d49-c54a-4729-c703-65a9395a353b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"For seven seasons, Best's Rosco P. Coltrane chased the moonshine-running \"\n",
      " 'Duke boys back and forth across the back roads of fictitious Hazzard County, '\n",
      " 'Georgia, although his \"hot pursuit\" usually ended with him crashing his '\n",
      " 'patrol car.']\n"
     ]
    }
   ],
   "source": [
    "textrank_summary = textrank.summarize(text[0:1])\n",
    "pprint(textrank_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUj8ZWSvYVle",
    "outputId": "93337f28-5a52-456d-dfb0-7229cc444036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextRank is a extractive, non-neural model for summarization. \n",
      " #################### \n",
      " A graphbased ranking model for text processing. Extractive sentence summarization. \n",
      " Strengths: \n",
      " - Fast with low memory usage \n",
      " - Allows for control of summary length \n",
      " Weaknesses: \n",
      " - Not as accurate as neural methods.\n"
     ]
    }
   ],
   "source": [
    "# More about TextRank\n",
    "textrank.show_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L2F-NQRyYVle",
    "outputId": "efaf1664-657d-4f07-87d0-63d1395ab33e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Longformer2Roberta\n",
    "longformer = model.LongformerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5cic-cqNYVlg",
    "outputId": "61d6975a-9227-4675-de65-4bd222029dfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('(CNN)James Holmes made his introduction to the world in a Colorado cinema '\n",
      " 'filled with spectators watching a midnight showing of the new Batman movie, '\n",
      " '\"The Dark Knight Rises,\" in June 2012. The moment became one of the '\n",
      " 'deadliest shootings in U.S. history. Holmes is accused of opening fire on '\n",
      " 'the crowd, killing 12 people and injuring or maiming 70 others in Aurora, a '\n",
      " 'suburb of Denver. Holmes appeared like a comic book character: He resembled '\n",
      " \"the Joker, with red-orange hair, similar to the late actor Heath Ledger's \"\n",
      " 'portrayal of the villain in an earlier Batman movie, authorities said. But '\n",
      " 'Holmes was hardly a cartoon. Authorities said he wore body armor and carried '\n",
      " 'several guns, including an AR-15 rifle, with lots of ammo. He also wore a '\n",
      " 'gas mask. Holmes says he was insane at the time of the shootings, and that '\n",
      " 'is his legal defense and court plea: not guilty by reason of insanity. '\n",
      " \"Prosecutors aren't swayed and will seek the death penalty. Opening \"\n",
      " 'statements in his trial are scheduled to begin Monday. Holmes admits to the '\n",
      " 'shootings but says he was suffering \"a psychotic episode\" at the time,  '\n",
      " 'according to court papers filed in July 2013 by the state public defenders, '\n",
      " 'Daniel King and Tamara A. Brady. Evidence \"revealed thus far in the case '\n",
      " \"supports the defense's position that Mr. Holmes suffers from a severe mental \"\n",
      " 'illness and was in the throes of a psychotic episode when he committed the '\n",
      " 'acts that resulted in the tragic loss of life and injuries sustained by '\n",
      " 'moviegoers on July 20, 2012,\" the public defenders wrote. Holmes no longer '\n",
      " 'looks like a dazed Joker, as he did in his first appearance before a judge '\n",
      " 'in 2012. He appeared dramatically different in January when jury selection '\n",
      " 'began for his trial: 9,000 potential jurors were summoned for duty, '\n",
      " \"described as one of the nation's largest jury calls. Holmes now has a \"\n",
      " 'cleaner look, with a mustache, button-down shirt and khaki pants. In '\n",
      " 'January, he had a beard and eyeglasses. If this new image sounds like one of '\n",
      " 'an academician, it may be because Holmes, now 27, once was one. Just before '\n",
      " 'the shooting, Holmes was a doctoral student in neuroscience, and he was '\n",
      " 'studying how the brain works, with his schooling funded by a U.S. government '\n",
      " 'grant. Yet for all his learning, Holmes apparently lacked the capacity to '\n",
      " 'command his own mind, according to the case against him. A jury will '\n",
      " \"ultimately decide Holmes' fate. That panel is made up of 12 jurors and 12 \"\n",
      " 'alternates. They are 19 women and five men, and almost all are white and '\n",
      " 'middle-aged. The trial could last until autumn. When jury summonses were '\n",
      " 'issued in January, each potential juror stood a 0.2% chance of being '\n",
      " 'selected, District Attorney George Brauchler told the final jury this month. '\n",
      " 'He described the approaching trial as \"four to five months of a horrible '\n",
      " 'roller coaster through the worst haunted house you can imagine.\" The jury '\n",
      " 'will have to render verdicts on each of the 165 counts against Holmes, '\n",
      " 'including murder and attempted murder charges. Meanwhile, victims and their '\n",
      " 'relatives are challenging all media outlets \"to stop the gratuitous use of '\n",
      " 'the name and likeness of mass killers, thereby depriving violent individuals '\n",
      " 'the media celebrity and media spotlight they so crave,\" the No Notoriety '\n",
      " 'group says. They are joined by victims from eight other mass shootings in '\n",
      " 'recent U.S. history. Raised in central coastal California and in San Diego, '\n",
      " 'James Eagan Holmes is the son of a mathematician father noted for his work '\n",
      " 'at the FICO firm that provides credit scores and a registered nurse mother, '\n",
      " 'according to the U-T San Diego newspaper. Holmes also has a sister, Chris, a '\n",
      " \"musician, who's five years younger, the newspaper said. His childhood \"\n",
      " 'classmates remember him as a clean-cut, bespectacled boy with an \"exemplary\" '\n",
      " 'character who \"never gave any trouble, and never got in trouble himself,\" '\n",
      " 'The Salinas Californian reported. His family then moved down the California '\n",
      " 'coast, where Holmes grew up in the San Diego-area neighborhood of Rancho '\n",
      " 'Peñasquitos, which a neighbor described as \"kind of like Mayberry,\" the San '\n",
      " 'Diego newspaper said. Holmes attended Westview High School, which says its '\n",
      " 'school district sits in \"a primarily middle- to upper-middle-income '\n",
      " 'residential community.\" There, Holmes ran cross-country, played soccer and '\n",
      " 'later worked at a biotechnology internship at the Salk Institute and Miramar '\n",
      " 'College, which attracts academically talented students. By then, his peers '\n",
      " 'described him as standoffish and a bit of a wiseacre, the San Diego '\n",
      " 'newspaper said. Holmes attended college fairly close to home, in a '\n",
      " 'neighboring area known as Southern California\\'s \"inland empire\" because '\n",
      " \"it's more than an hour's drive from the coast, in a warm, low-desert \"\n",
      " 'climate. He entered the University of California, Riverside, in 2006 as a '\n",
      " 'scholarship student. In 2008 he was a summer camp counselor for '\n",
      " 'disadvantaged children, age 7 to 14, at Camp Max Straus, run by Jewish Big '\n",
      " 'Brothers Big Sisters of Los Angeles. He graduated from UC Riverside in 2010 '\n",
      " \"with the highest honors and a bachelor's degree in neuroscience. \"\n",
      " '\"Academically, he was at the top of the top,\" Chancellor Timothy P. White '\n",
      " 'said. He seemed destined for even higher achievement. By 2011, he had '\n",
      " 'enrolled as a doctoral student in the neuroscience program at the University '\n",
      " 'of Colorado Anschutz Medical Campus in Aurora, the largest academic health '\n",
      " 'center in the Rocky Mountain region. The doctoral in neuroscience program '\n",
      " 'attended by Holmes focuses on how the brain works, with an emphasis on '\n",
      " 'processing of information, behavior, learning and memory. Holmes was one of '\n",
      " 'six pre-thesis Ph.D. students in the program who were awarded a neuroscience '\n",
      " 'training grant from the National Institutes of Health. The grant rewards '\n",
      " 'outstanding neuroscientists who will make major contributions to '\n",
      " 'neurobiology. A syllabus that listed Holmes as a student at the medical '\n",
      " 'school shows he was to have delivered a presentation about microRNA '\n",
      " 'biomarkers. But Holmes struggled, and his own mental health took an ominous '\n",
      " 'turn. In March 2012, he told a classmate he wanted to kill people, and that '\n",
      " 'he would do so \"when his life was over,\" court documents said. Holmes was '\n",
      " '\"denied access to the school after June 12, 2012, after he made threats to a '\n",
      " 'professor,\" according to court documents. About that time, Holmes was a '\n",
      " 'patient of University of Colorado psychiatrist Lynne Fenton. Fenton was so '\n",
      " \"concerned about Holmes' behavior that she mentioned it to her colleagues, \"\n",
      " 'saying he could be a danger to others, CNN affiliate KMGH-TV reported, '\n",
      " \"citing sources with knowledge of the investigation. Fenton's concerns \"\n",
      " 'surfaced in early June, sources told the Denver station. Holmes began to '\n",
      " 'fantasize about killing \"a lot of people\" in early June, nearly six weeks '\n",
      " 'before the shootings, the station reported, citing unidentified sources '\n",
      " \"familiar with the investigation. Holmes' psychiatrist contacted several \"\n",
      " 'members of a \"behavioral evaluation and threat assessment\" team to say '\n",
      " 'Holmes could be a danger to others, the station reported. At issue was '\n",
      " 'whether to order Holmes held for 72 hours to be evaluated by mental health '\n",
      " 'professionals, the station reported. \"Fenton made initial phone calls about '\n",
      " 'engaging the BETA team\" in \"the first 10 days\" of June, but it \"never came '\n",
      " 'together\" because in the period Fenton was having conversations with team '\n",
      " 'members, Holmes began the process of dropping out of school, a source told '\n",
      " \"KMGH. Defense attorneys have rejected the prosecution's assertions that \"\n",
      " 'Holmes was barred from campus. Citing statements from the university, '\n",
      " \"Holmes' attorneys have argued that his access was revoked because that's \"\n",
      " 'normal procedure when a student drops enrollment. What caused this turn for '\n",
      " 'the worse for Holmes has yet to be clearly detailed. In the months before '\n",
      " 'the shooting, he bought four weapons and more than 6,000 rounds of '\n",
      " 'ammunition, authorities said. Police said he also booby-trapped his '\n",
      " \"third-floor apartment with explosives, but police weren't fooled. After \"\n",
      " 'Holmes was caught in the cinema parking lot immediately after the shooting, '\n",
      " 'bomb technicians went to the apartment and neutralized the explosives. No '\n",
      " 'one was injured at the apartment building. Nine minutes before Holmes went '\n",
      " 'into the movie theater, he called a University of Colorado switchboard, '\n",
      " 'public defender Brady has said in court. The number he called can be used to '\n",
      " 'get in contact with faculty members during off hours, Brady said. Court '\n",
      " 'documents have also revealed that investigators have obtained text messages '\n",
      " 'that Holmes exchanged with someone before the shooting. That person was not '\n",
      " 'named, and the content of the texts has not been made public. According to '\n",
      " 'The New York Times, Holmes sent a text message to a fellow graduate student, '\n",
      " 'a woman, about two weeks before the shooting. She asked if he had left '\n",
      " \"Aurora yet, reported the newspaper, which didn't identify her. No, he had \"\n",
      " 'two months left on his lease, Holmes wrote back, according to the Times. He '\n",
      " 'asked if she had heard of \"dysphoric mania,\" a form of bipolar disorder '\n",
      " 'marked by the highs of mania and the dark and sometimes paranoid delusions '\n",
      " 'of major depression. The woman asked if the disorder could be managed with '\n",
      " 'treatment. \"It was,\" Holmes wrote her, according to the Times. But he warned '\n",
      " 'she should stay away from him \"because I am bad news,\" the newspaper '\n",
      " \"reported. It was her last contact with Holmes. After the shooting, Holmes' \"\n",
      " 'family issued a brief statement: \"Our hearts go out to those who were '\n",
      " 'involved in this tragedy and to the families and friends of those involved,\" '\n",
      " 'they said, without giving any information about their son. Since then, '\n",
      " 'prosecutors have refused to offer a plea deal to Holmes. For Holmes, '\n",
      " '\"justice is death,\" said Brauchler, the district attorney. In December, '\n",
      " \"Holmes' parents, who will be attending the trial, issued another statement: \"\n",
      " \"They asked that their son's life be spared and that he be sent to an \"\n",
      " \"institution for mentally ill people for the rest of his life, if he's found \"\n",
      " 'not guilty by reason of insanity. \"He is not a monster,\" Robert and Arlene '\n",
      " 'Holmes wrote, saying the death penalty is \"morally wrong, especially when '\n",
      " 'the condemned is mentally ill.\" \"He is a human being gripped by a severe '\n",
      " 'mental illness,\" the parents said. The matter will be settled by the jury. '\n",
      " \"CNN's Ana Cabrera and Sara Weisfeldt contributed to this report from Denver.\")\n"
     ]
    }
   ],
   "source": [
    "long_article = \"\"\"(CNN)James Holmes made his introduction to the world in a Colorado cinema filled with spectators watching a midnight showing of the new Batman movie, \"The Dark Knight Rises,\" in June 2012. The moment became one of the deadliest shootings in U.S. history. Holmes is accused of opening fire on the crowd, killing 12 people and injuring or maiming 70 others in Aurora, a suburb of Denver. Holmes appeared like a comic book character: He resembled the Joker, with red-orange hair, similar to the late actor Heath Ledger\\'s portrayal of the villain in an earlier Batman movie, authorities said. But Holmes was hardly a cartoon. Authorities said he wore body armor and carried several guns, including an AR-15 rifle, with lots of ammo. He also wore a gas mask. Holmes says he was insane at the time of the shootings, and that is his legal defense and court plea: not guilty by reason of insanity. Prosecutors aren\\'t swayed and will seek the death penalty. Opening statements in his trial are scheduled to begin Monday. Holmes admits to the shootings but says he was suffering \"a psychotic episode\" at the time,  according to court papers filed in July 2013 by the state public defenders, Daniel King and Tamara A. Brady. Evidence \"revealed thus far in the case supports the defense\\'s position that Mr. Holmes suffers from a severe mental illness and was in the throes of a psychotic episode when he committed the acts that resulted in the tragic loss of life and injuries sustained by moviegoers on July 20, 2012,\" the public defenders wrote. Holmes no longer looks like a dazed Joker, as he did in his first appearance before a judge in 2012. He appeared dramatically different in January when jury selection began for his trial: 9,000 potential jurors were summoned for duty, described as one of the nation\\'s largest jury calls. Holmes now has a cleaner look, with a mustache, button-down shirt and khaki pants. In January, he had a beard and eyeglasses. If this new image sounds like one of an academician, it may be because Holmes, now 27, once was one. Just before the shooting, Holmes was a doctoral student in neuroscience, and he was studying how the brain works, with his schooling funded by a U.S. government grant. Yet for all his learning, Holmes apparently lacked the capacity to command his own mind, according to the case against him. A jury will ultimately decide Holmes\\' fate. That panel is made up of 12 jurors and 12 alternates. They are 19 women and five men, and almost all are white and middle-aged. The trial could last until autumn. When jury summonses were issued in January, each potential juror stood a 0.2% chance of being selected, District Attorney George Brauchler told the final jury this month. He described the approaching trial as \"four to five months of a horrible roller coaster through the worst haunted house you can imagine.\" The jury will have to render verdicts on each of the 165 counts against Holmes, including murder and attempted murder charges. Meanwhile, victims and their relatives are challenging all media outlets \"to stop the gratuitous use of the name and likeness of mass killers, thereby depriving violent individuals the media celebrity and media spotlight they so crave,\" the No Notoriety group says. They are joined by victims from eight other mass shootings in recent U.S. history. Raised in central coastal California and in San Diego, James Eagan Holmes is the son of a mathematician father noted for his work at the FICO firm that provides credit scores and a registered nurse mother, according to the U-T San Diego newspaper. Holmes also has a sister, Chris, a musician, who\\'s five years younger, the newspaper said. His childhood classmates remember him as a clean-cut, bespectacled boy with an \"exemplary\" character who \"never gave any trouble, and never got in trouble himself,\" The Salinas Californian reported. His family then moved down the California coast, where Holmes grew up in the San Diego-area neighborhood of Rancho Peñasquitos, which a neighbor described as \"kind of like Mayberry,\" the San Diego newspaper said. Holmes attended Westview High School, which says its school district sits in \"a primarily middle- to upper-middle-income residential community.\" There, Holmes ran cross-country, played soccer and later worked at a biotechnology internship at the Salk Institute and Miramar College, which attracts academically talented students. By then, his peers described him as standoffish and a bit of a wiseacre, the San Diego newspaper said. Holmes attended college fairly close to home, in a neighboring area known as Southern California\\'s \"inland empire\" because it\\'s more than an hour\\'s drive from the coast, in a warm, low-desert climate. He entered the University of California, Riverside, in 2006 as a scholarship student. In 2008 he was a summer camp counselor for disadvantaged children, age 7 to 14, at Camp Max Straus, run by Jewish Big Brothers Big Sisters of Los Angeles. He graduated from UC Riverside in 2010 with the highest honors and a bachelor\\'s degree in neuroscience. \"Academically, he was at the top of the top,\" Chancellor Timothy P. White said. He seemed destined for even higher achievement. By 2011, he had enrolled as a doctoral student in the neuroscience program at the University of Colorado Anschutz Medical Campus in Aurora, the largest academic health center in the Rocky Mountain region. The doctoral in neuroscience program attended by Holmes focuses on how the brain works, with an emphasis on processing of information, behavior, learning and memory. Holmes was one of six pre-thesis Ph.D. students in the program who were awarded a neuroscience training grant from the National Institutes of Health. The grant rewards outstanding neuroscientists who will make major contributions to neurobiology. A syllabus that listed Holmes as a student at the medical school shows he was to have delivered a presentation about microRNA biomarkers. But Holmes struggled, and his own mental health took an ominous turn. In March 2012, he told a classmate he wanted to kill people, and that he would do so \"when his life was over,\" court documents said. Holmes was \"denied access to the school after June 12, 2012, after he made threats to a professor,\" according to court documents. About that time, Holmes was a patient of University of Colorado psychiatrist Lynne Fenton. Fenton was so concerned about Holmes\\' behavior that she mentioned it to her colleagues, saying he could be a danger to others, CNN affiliate KMGH-TV reported, citing sources with knowledge of the investigation. Fenton\\'s concerns surfaced in early June, sources told the Denver station. Holmes began to fantasize about killing \"a lot of people\" in early June, nearly six weeks before the shootings, the station reported, citing unidentified sources familiar with the investigation. Holmes\\' psychiatrist contacted several members of a \"behavioral evaluation and threat assessment\" team to say Holmes could be a danger to others, the station reported. At issue was whether to order Holmes held for 72 hours to be evaluated by mental health professionals, the station reported. \"Fenton made initial phone calls about engaging the BETA team\" in \"the first 10 days\" of June, but it \"never came together\" because in the period Fenton was having conversations with team members, Holmes began the process of dropping out of school, a source told KMGH. Defense attorneys have rejected the prosecution\\'s assertions that Holmes was barred from campus. Citing statements from the university, Holmes\\' attorneys have argued that his access was revoked because that\\'s normal procedure when a student drops enrollment. What caused this turn for the worse for Holmes has yet to be clearly detailed. In the months before the shooting, he bought four weapons and more than 6,000 rounds of ammunition, authorities said. Police said he also booby-trapped his third-floor apartment with explosives, but police weren\\'t fooled. After Holmes was caught in the cinema parking lot immediately after the shooting, bomb technicians went to the apartment and neutralized the explosives. No one was injured at the apartment building. Nine minutes before Holmes went into the movie theater, he called a University of Colorado switchboard, public defender Brady has said in court. The number he called can be used to get in contact with faculty members during off hours, Brady said. Court documents have also revealed that investigators have obtained text messages that Holmes exchanged with someone before the shooting. That person was not named, and the content of the texts has not been made public. According to The New York Times, Holmes sent a text message to a fellow graduate student, a woman, about two weeks before the shooting. She asked if he had left Aurora yet, reported the newspaper, which didn\\'t identify her. No, he had two months left on his lease, Holmes wrote back, according to the Times. He asked if she had heard of \"dysphoric mania,\" a form of bipolar disorder marked by the highs of mania and the dark and sometimes paranoid delusions of major depression. The woman asked if the disorder could be managed with treatment. \"It was,\" Holmes wrote her, according to the Times. But he warned she should stay away from him \"because I am bad news,\" the newspaper reported. It was her last contact with Holmes. After the shooting, Holmes\\' family issued a brief statement: \"Our hearts go out to those who were involved in this tragedy and to the families and friends of those involved,\" they said, without giving any information about their son. Since then, prosecutors have refused to offer a plea deal to Holmes. For Holmes, \"justice is death,\" said Brauchler, the district attorney. In December, Holmes\\' parents, who will be attending the trial, issued another statement: They asked that their son\\'s life be spared and that he be sent to an institution for mentally ill people for the rest of his life, if he\\'s found not guilty by reason of insanity. \"He is not a monster,\" Robert and Arlene Holmes wrote, saying the death penalty is \"morally wrong, especially when the condemned is mentally ill.\" \"He is a human being gripped by a severe mental illness,\" the parents said. The matter will be settled by the jury. CNN\\'s Ana Cabrera and Sara Weisfeldt contributed to this report from Denver.\"\"\"\n",
    "pprint(long_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QAJ8e7-XYVlv",
    "outputId": "83a63c8d-da6c-4d96-b70a-f23ed3ad14e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer model: processing document of tensor([2124]) tokens\n",
      "['James Holmes, 27, is accused of opening fire on a Colorado theater.\\n'\n",
      " 'He was a doctoral student at University of Colorado.\\n'\n",
      " 'Holmes says he was suffering \"a psychotic episode\" at the time of the '\n",
      " 'shooting.\\n'\n",
      " \"Prosecutors won't say whether Holmes was barred from campus.\"]\n"
     ]
    }
   ],
   "source": [
    "longformer_summary = longformer.summarize([long_article])\n",
    "pprint(longformer_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TqTNO7N7YVl1",
    "outputId": "f8e07d5d-43f7-4098-e42e-206ae03f0b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer is a abstractive, neural model for summarization. \n",
      " #################### \n",
      " A Longformer2Roberta model finetuned on CNN-DM dataset for summarization.\n",
      "\n",
      "Strengths:\n",
      " - Correctly handles longer (> 2000 tokens) corpus.\n",
      "\n",
      "Weaknesses:\n",
      " - Less accurate on contexts outside training domain.\n",
      "\n",
      "Initialization arguments:\n",
      "  - `corpus`: Unlabelled corpus of documents.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "longformer.show_capability()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9g4Qp0rbYVl2"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXy0c_G0Fpvd"
   },
   "source": [
    "### Supported Evalutaionmetrics\n",
    "\n",
    "SummerTime supports different evaluation metrics (*e.g.,* ROUGE, Bleu, BertScore, Meteor, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4aURKURFpvv",
    "outputId": "53a8430b-e7e7-4534-d21c-ada7623788c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'evaluation.bertscore_metric.BertScore'>,\n",
      " <class 'evaluation.bleu_metric.Bleu'>,\n",
      " <class 'evaluation.rouge_metric.Rouge'>,\n",
      " <class 'evaluation.rougewe_metric.RougeWe'>,\n",
      " <class 'evaluation.meteor_metric.Meteor'>]\n"
     ]
    }
   ],
   "source": [
    "from evaluation import SUPPORTED_EVALUATION_METRICS\n",
    "\n",
    "pprint(SUPPORTED_EVALUATION_METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPld2tGiYVl2",
    "outputId": "8b8204bc-f588-4475-dc58-bc486514f215"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/287113 [00:55<740:45:34,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<dataset.st_dataset.SummInstance object at 0x7f8f3fc39820>,\n",
      " <dataset.st_dataset.SummInstance object at 0x7f90901aec40>,\n",
      " <dataset.st_dataset.SummInstance object at 0x7f8f3fc398b0>,\n",
      " <dataset.st_dataset.SummInstance object at 0x7f8f3fc39880>,\n",
      " <dataset.st_dataset.SummInstance object at 0x7f8f3fc397c0>]\n"
     ]
    }
   ],
   "source": [
    "from evaluation.base_metric import SummMetric\n",
    "from evaluation import Rouge, RougeWe, BertScore\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Initializes a bertscore metric object\n",
    "metric = BertScore()\n",
    "\n",
    "# Evaluates model on subset of cnn_dailymail\n",
    "# Get a slice of the train set - first 5 instances\n",
    "train_set = itertools.islice(cnn_dataset.train_set, 5)\n",
    "\n",
    "corpus = [instance for instance in train_set]\n",
    "pprint(corpus)\n",
    "\n",
    "articles = [instance.source for instance in corpus]\n",
    "\n",
    "summaries = sample_model.summarize(articles)\n",
    "targets = [instance.summary for instance in corpus]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "2_E1kG8zRPHp",
    "outputId": "bbef0b57-15be-4618-9958-323bd7d3379e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge_we_3_f': 0.20183811597317614}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate BertScore\n",
    "metric = RougeWe()\n",
    "metric.evaluate(summaries, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5--0--qinJvp"
   },
   "source": [
    "## More Model and dataset tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment if using Ziva Server\n",
    "## Installs the pytorch version compatible with the CUDA version\n",
    "\n",
    "# !pip install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cu111/torch_nightly.html -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "B 1.10.0.dev20210818+cu111\n",
      "C True\n",
      "D True\n",
      "E _CudaDeviceProperties(name='GeForce RTX 3090', major=8, minor=6, total_memory=24268MB, multi_processor_count=82)\n",
      "F tensor([1., 2.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "print('A', sys.version)\n",
    "print('B', torch.__version__)\n",
    "print('C', torch.cuda.is_available())\n",
    "print('D', torch.backends.cudnn.enabled)\n",
    "device = torch.device('cuda')\n",
    "print('E', torch.cuda.get_device_properties(device))\n",
    "print('F', torch.tensor([1.0, 2.0]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9djoq_btRfrk",
    "outputId": "2c6362cb-39a0-429f-8293-1a07195923b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2021-08-18 18:39:19,420 [MainThread  ] [INFO ]  Set ROUGE home directory to /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\n",
      "Initializing all evaluation metrics...\u001b[0m\n",
      "<class 'evaluation.bertscore_metric.BertScore'>\n",
      "<class 'evaluation.bleu_metric.Bleu'>\n",
      "<class 'evaluation.rouge_metric.Rouge'>\n",
      "<class 'evaluation.rougewe_metric.RougeWe'>\n",
      "<class 'evaluation.meteor_metric.Meteor'>\n",
      "\u001b[35m\n",
      "\n",
      "Beginning integration tests...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/lily/mmm274/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "Reusing dataset cnn_dailymail (/home/lily/mmm274/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "100%|██████████| 287113/287113 [00:18<00:00, 15767.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cnn_dailymail has a training set of 287113 examples\n",
      "\u001b[35mInitializing all matching model pipelines for cnn_dailymail dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset cnn_dailymail (/home/lily/mmm274/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "  0%|          | 0/287113 [00:00<?, ?it/s]/home/lily/mmm274/anaconda3/lib/python3.8/site-packages/transformers/configuration_utils.py:403: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "  logger.warn(\n",
      "You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/lily/mmm274/anaconda3/lib/python3.8/site-packages/spacy/util.py:1176: ResourceWarning: unclosed file <_io.BufferedReader name='/home/lily/mmm274/anaconda3/lib/python3.8/site-packages/en_core_web_sm/en_core_web_sm-3.0.0/tok2vec/model'>\n",
      "  reader(path / key)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/lily/mmm274/anaconda3/lib/python3.8/site-packages/spacy/util.py:1176: ResourceWarning: unclosed file <_io.BufferedReader name='/home/lily/mmm274/anaconda3/lib/python3.8/site-packages/en_core_web_sm/en_core_web_sm-3.0.0/tagger/model'>\n",
      "  reader(path / key)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "/home/lily/mmm274/anaconda3/lib/python3.8/site-packages/spacy/util.py:1176: ResourceWarning: unclosed file <_io.BufferedReader name='/home/lily/mmm274/anaconda3/lib/python3.8/site-packages/en_core_web_sm/en_core_web_sm-3.0.0/senter/model'>\n",
      "  reader(path / key)\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "  0%|          | 99/287113 [00:40<32:23:54,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: cnn_dailymail dataset, BART model ####################\u001b[0m\n",
      "Prediction: ['The 58-year-old man was pinned against a wall after the bin lorry started rolling. It crashed into a Jaguar X-Type before careering through railings. The lorry came to rest hanging over the edge of a pier in South Queensferry. Staff from a nearby pub rushed to help the driver before emergency services reached the scene. But the man, who is yet to be named, later died from his injuries.']\n",
      "Target: ['The 58-year-old man was pinned against a wall when truck started rolling .\\nBiffa lorry mounted a pavement, crashed into a car and through railings .\\nIt came to rest hanging over the edge of Hawes Pier in South Queensferry .\\nStaff from a nearby pub rushed to help driver but he later died in hospital .']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:41:03,499 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:41:03,500 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpl1g226hl/system and model files to /tmp/tmpl1g226hl/model.\n",
      "2021-08-18 18:41:03,501 [MainThread  ] [INFO ]  Processing files in /tmp/tmpuuhhe111.\n",
      "2021-08-18 18:41:03,502 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:41:03,503 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpl1g226hl/system.\n",
      "2021-08-18 18:41:03,504 [MainThread  ] [INFO ]  Processing files in /tmp/tmp7rl6jyiv.\n",
      "2021-08-18 18:41:03,505 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:41:03,506 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpl1g226hl/model.\n",
      "2021-08-18 18:41:03,507 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpzn5ugn_i/rouge_conf.xml\n",
      "2021-08-18 18:41:03,508 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpzn5ugn_i/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.8048666715621948}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 40.62769602451984}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.69291, 'rouge_2_f_score': 0.512, 'rouge_l_f_score': 0.67716}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.6178861788617885}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.4994627816275194}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, BART model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: cnn_dailymail dataset, LexRank model ####################\u001b[0m\n",
      "Prediction: ['While Ami worked, Tesca played a simple interactive game, appearing to deftly use the computer as she sucked on her pacifier. One scene from a plane, as recalled by Ami Fitzgerald: When Tesca was not yet 2, she and her mother took a flight, each with her own laptop, unusual for a toddler in the 1990s.']\n",
      "Target: ['Tesca Fitzgerald began to play with computers at before the age of two .\\nShe skipped middle and high schools and went straight to college .\\nNow a graduate, she is about to start her PHD later this year .\\nHer two sisters appear to be just as clever .']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:41:23,823 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:41:23,824 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmps7vo_qe5/system and model files to /tmp/tmps7vo_qe5/model.\n",
      "2021-08-18 18:41:23,825 [MainThread  ] [INFO ]  Processing files in /tmp/tmpr5p_lquj.\n",
      "2021-08-18 18:41:23,826 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:41:23,827 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmps7vo_qe5/system.\n",
      "2021-08-18 18:41:23,827 [MainThread  ] [INFO ]  Processing files in /tmp/tmppbq_jdot.\n",
      "2021-08-18 18:41:23,828 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:41:23,829 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmps7vo_qe5/model.\n",
      "2021-08-18 18:41:23,830 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmppcmtjg7d/rouge_conf.xml\n",
      "2021-08-18 18:41:23,831 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmppcmtjg7d/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5137070417404175}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.7783078636476368}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.29412, 'rouge_2_f_score': 0.02, 'rouge_l_f_score': 0.2353}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.02040816326530612}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.16068993180906538}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, LexRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: cnn_dailymail dataset, Longformer model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([584]) tokens\n",
      "Prediction: [\"Josh Jenkins, 19, bought a Bargain Bucket after eating leftovers the following day.\\nHe immediately repulsed by the 'grey and wrinkled' organ.\\nKFC has since apologised but he insists he will never eat in one of its branches again.\\nThe chain has since said it will provide him with a goodwill gift.\"]\n",
      "Target: [\"John Jenkins found 'white and wrinkled' organ while eating in Dorset branch .\\nAfter the student found the offal he sent it back to the fast-food chain .\\nKFC studied the piece of chicken and said that it was a kidney .\"]\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:41:47,068 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:41:47,070 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp61lup_j2/system and model files to /tmp/tmp61lup_j2/model.\n",
      "2021-08-18 18:41:47,070 [MainThread  ] [INFO ]  Processing files in /tmp/tmpndp7m44l.\n",
      "2021-08-18 18:41:47,071 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:41:47,072 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp61lup_j2/system.\n",
      "2021-08-18 18:41:47,073 [MainThread  ] [INFO ]  Processing files in /tmp/tmp4v_nnes8.\n",
      "2021-08-18 18:41:47,073 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:41:47,075 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp61lup_j2/model.\n",
      "2021-08-18 18:41:47,075 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpnwgn6mmw/rouge_conf.xml\n",
      "2021-08-18 18:41:47,076 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpnwgn6mmw/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5806867480278015}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 4.035316002020003}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.3913, 'rouge_2_f_score': 0.06666, 'rouge_l_f_score': 0.36956}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.1590909090909091}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.16666666666666666}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, Longformer model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: cnn_dailymail dataset, Pegasus model ####################\u001b[0m\n",
      "Prediction: ['A father who lost a leg in a work accident died after taking an accidental overdose of a drug he bought on the internet, an inquest has found.']\n",
      "Target: [\"Daniel Batchelor, 36, fell off a ladder in 2011 and suffered multiple injuries .\\nHe had to have his right leg amputated and struggled with the pain .\\nHe was unable to take opiate-based painkillers due to an allergy .\\nSo, he bought a painkilling drug called Methoxetamine on the internet .\\nA head injury sustained during the accident also left him with short-term memory loss and it's thought he took too many doses of the drug by mistake .\\nAn inquest heard he died as a result of choking on his own vomit .\"]\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:42:11,642 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:42:11,644 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpn9l1v2ua/system and model files to /tmp/tmpn9l1v2ua/model.\n",
      "2021-08-18 18:42:11,644 [MainThread  ] [INFO ]  Processing files in /tmp/tmp_yepz5rf.\n",
      "2021-08-18 18:42:11,645 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:42:11,647 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpn9l1v2ua/system.\n",
      "2021-08-18 18:42:11,647 [MainThread  ] [INFO ]  Processing files in /tmp/tmpq4ya46rg.\n",
      "2021-08-18 18:42:11,648 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:42:11,649 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpn9l1v2ua/model.\n",
      "2021-08-18 18:42:11,651 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpt4uesv3p/rouge_conf.xml\n",
      "2021-08-18 18:42:11,651 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpt4uesv3p/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.581717312335968}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.8410080006327163}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.31666, 'rouge_2_f_score': 0.0678, 'rouge_l_f_score': 0.18334}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.18965517241379312}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.30023659586579854}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, Pegasus model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: cnn_dailymail dataset, TextRank model ####################\u001b[0m\n",
      "Prediction: ['I didn\\'t get tired until 1.am -- it was very energizing.\" \\'Touching infinity\\' Brooks, who is studying international ocean policy, was one of 30 U.S. scientists monitoring Antarctica\\'s unique eco-system, as part of a National Science Foundation research cruise.']\n",
      "Target: ['Science research ship cruises Antarctica, captures stunning time-lapse video .\\nSouth Pole dubbed \"Land of the Midnight Sun,\" 24-hour sunlight during summer .\\nExtreme conditions include winds of 110kph, temperatures plunge -40C .\\nAntarctica\\'s Ross Sea the last intact marine ecosystem in the world .']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:42:31,574 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:42:31,575 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpl_fzw7ul/system and model files to /tmp/tmpl_fzw7ul/model.\n",
      "2021-08-18 18:42:31,576 [MainThread  ] [INFO ]  Processing files in /tmp/tmpic4jkduc.\n",
      "2021-08-18 18:42:31,577 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:42:31,578 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpl_fzw7ul/system.\n",
      "2021-08-18 18:42:31,579 [MainThread  ] [INFO ]  Processing files in /tmp/tmpzw5kiuv7.\n",
      "2021-08-18 18:42:31,580 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:42:31,582 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpl_fzw7ul/model.\n",
      "2021-08-18 18:42:31,583 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp1z2l1z5q/rouge_conf.xml\n",
      "2021-08-18 18:42:31,584 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp1z2l1z5q/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4563243091106415}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.3302791074921412}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.16092, 'rouge_2_f_score': 0.02353, 'rouge_l_f_score': 0.16092}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.04819277108433735}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.08838383838383838}\n",
      "\u001b[32m#################### Test for cnn_dailymail dataset, TextRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset multi_news (/home/lily/mmm274/.cache/huggingface/datasets/multi_news/default/1.0.0/2e145a8e21361ba4ee46fef70640ab946a3e8d425002f104d2cda99a9efca376)\n",
      "100%|██████████| 44972/44972 [00:03<00:00, 13619.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "multi_news has a training set of 44972 examples\n",
      "\u001b[35mInitializing all matching model pipelines for multi_news dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset multi_news (/home/lily/mmm274/.cache/huggingface/datasets/multi_news/default/1.0.0/2e145a8e21361ba4ee46fef70640ab946a3e8d425002f104d2cda99a9efca376)\n",
      "  0%|          | 0/44972 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 100/44972 [01:02<7:49:06,  1.59it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 200/44972 [02:07<7:52:04,  1.58it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  1%|          | 299/44972 [02:54<7:13:36,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (BART) model ####################\u001b[0m\n",
      "Prediction: ['2004 BL86 will pass about three times the distance of Earth to the moon on January 26. The flyby will be the closest by any known space rock this large until asteroid 1999 AN10 flies past Earth in 2027. Asteroid is expected to be observable to amateur astronomers with small telescopes and strong binoculars.']\n",
      "Target: ['– If you\\'ve ever wanted to get a good look at an asteroid, Monday night will be your best chance for more than a decade. Asteroid 2004 BL86, a space rock about a third of a mile in diameter, will be 745,000 miles away on Monday, around three times as far away as the moon, reports CNN. Barring cosmic surprises, the next close encounter with something that big will be in 2027, and NASA says that while 2004 BL86 doesn\\'t pose any threat, it gives astronomers a \"unique opportunity to observe and learn more.\" Very little is known about this particular asteroid and it won\\'t be this close again for 200 years. Amateur astronomers might be able to see the space rock with strong telescopes or binocuIars. \"I may grab my favorite binoculars and give it a shot myself,\" the chief of NASA\\'s Near-Earth Object Program Office says in a press release. \"Asteroids are something special. Not only did asteroids provide Earth with the building blocks of life and much of its water, but in the future, they will become valuable resources for mineral ores and other vital natural resources. They will also become the fueling stops for humanity as we continue to explore our solar system. There is something about asteroids that makes me want to look up.\" Tech Times has some tips for those who want to try to spot 2004 BL86, which will be at its brightest between 11:07pm and 11:52pm EST.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:46:15,256 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:46:15,257 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmplgqx5a1m/system and model files to /tmp/tmplgqx5a1m/model.\n",
      "2021-08-18 18:46:15,258 [MainThread  ] [INFO ]  Processing files in /tmp/tmpbq0tznac.\n",
      "2021-08-18 18:46:15,259 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:46:15,260 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmplgqx5a1m/system.\n",
      "2021-08-18 18:46:15,261 [MainThread  ] [INFO ]  Processing files in /tmp/tmpq5mfresd.\n",
      "2021-08-18 18:46:15,262 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:46:15,262 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmplgqx5a1m/model.\n",
      "2021-08-18 18:46:15,263 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpjn3iuhf3/rouge_conf.xml\n",
      "2021-08-18 18:46:15,264 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpjn3iuhf3/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.534206211566925}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.08961889027287664}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.2549, 'rouge_2_f_score': 0.04606, 'rouge_l_f_score': 0.13725}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.1390728476821192}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.3126196990424077}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (BART) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (LexRank) model ####################\u001b[0m\n",
      "Prediction: [\"Problem 1: Clinton made herself vulnerable to hackers \\n  \\n Clinton's private server had several potential points of vulnerability, so it was possible for spies to hack into the system — both to view messages or to reroute messages. We don't know why Clinton used a private server.\"]\n",
      "Target: ['– \"There\\'s no equivalency.\" That\\'s Ivanka Trump\\'s official take on her email hubbub versus that of Hillary Clinton, per an interview Tuesday with ABC News. \"All of my emails are stored and preserved. There were no deletions. There is no attempt to hide,\" and nothing classified in them, Trump told Deborah Roberts in a sit-down in Wilder, Idaho, where the first daughter is lobbying for STEM initiatives. She added that \"there is no restriction of using personal email,\" and that she was told if she gets a personal email related to government business, all she has to do is forward it to her government account for archiving purposes. Congressional Dems, however, have said they want to look into her email use and if she \"complied with the law,\" especially as it pertains to the Presidential Records Act and Federal Records Act. Trump spoke on other issues as well, including Robert Mueller\\'s Russia probe—\"I think it absolutely should reach its conclusion\"—the \"heartbreaking\" and \"devastating\" images of asylum seekers being tear-gassed at the border (though she backs up her father\\'s stance, noting \"there are people in the caravan who are not so innocent … [the president] has to protect our country\\'s security\"), and her \"good\" relationship with him. She credits her \"incredibly candid\" nature as a driver of that: \"He knows exactly where I stand on any issue.\" Not that everyone else may be privy to where she stands on everything: \"I\\'ll always tell you what I\\'m for, but it is not my place as somebody working within a White House to tell you what I\\'m against. The only person who knows that is one person, and he knows it.\"']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:46:37,600 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:46:37,602 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp0i22inlz/system and model files to /tmp/tmp0i22inlz/model.\n",
      "2021-08-18 18:46:37,602 [MainThread  ] [INFO ]  Processing files in /tmp/tmpqv0czt_f.\n",
      "2021-08-18 18:46:37,603 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:46:37,605 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp0i22inlz/system.\n",
      "2021-08-18 18:46:37,605 [MainThread  ] [INFO ]  Processing files in /tmp/tmpjruimacm.\n",
      "2021-08-18 18:46:37,606 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:46:37,607 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp0i22inlz/model.\n",
      "2021-08-18 18:46:37,608 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpxzy4h0rm/rouge_conf.xml\n",
      "2021-08-18 18:46:37,608 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpxzy4h0rm/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.44767850637435913}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.00485597570718259}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.09523, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.07738}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.018072289156626505}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.10838150289017343}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (LexRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (Longformer) model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([1510]) tokens\n",
      "Prediction: ['Regal Entertainment Group quietly added a new security warning to its website.\\nRegal added a security warning on its website to show its bag search policy.\\nThe move follows a shooting at a theater in Lafayette, Louisiana last month.\\nA gunman killed two women and injured 70 in a theater shooting in August.']\n",
      "Target: ['– The country\\'s biggest theater chain has announced that all moviegoers can expect to have their bags searched on entry—and it isn\\'t looking for illicit snacks. Instead, Regal Cinemas says on its website that since \"security issues have become a daily part of our lives in America,\" searches will be carried out to ensure the \"safety of our guests and employees,\" Entertainment Weekly reports. The move at the chain, which has around 7,300 screens nationwide, comes after recent theater attacks in Louisiana and Tennessee, which happened three years after James Holmes massacred 12 people in a Colorado theater, EW notes. An analyst for entertainment research firm Rentrak tells USA Today that since people are already used to having their bags searched at places like stadiums, Regal\\'s move probably won\\'t affect movie attendances. \"I don\\'t think anyone is going to stay away from a movie theater because of increased security measures,\" he says. \"If anything, they\\'re going to appreciate it.\" Other analysts, however, say the move seems a little \"undercooked\" and wonder if Regal is training employees on how to react if they do find a gun in a patron\\'s bag. (At a California theater, a \"prankster\" carrying a leaf blower caused a stampede.)']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:47:02,828 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:47:02,829 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpl6kxgxpw/system and model files to /tmp/tmpl6kxgxpw/model.\n",
      "2021-08-18 18:47:02,830 [MainThread  ] [INFO ]  Processing files in /tmp/tmpmnd8c3dg.\n",
      "2021-08-18 18:47:02,831 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:47:02,832 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpl6kxgxpw/system.\n",
      "2021-08-18 18:47:02,833 [MainThread  ] [INFO ]  Processing files in /tmp/tmp94hvetj0.\n",
      "2021-08-18 18:47:02,834 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:47:02,835 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpl6kxgxpw/model.\n",
      "2021-08-18 18:47:02,836 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmptc1xxnqx/rouge_conf.xml\n",
      "2021-08-18 18:47:02,837 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmptc1xxnqx/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5382329821586609}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.2804200562123925}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.21212, 'rouge_2_f_score': 0.0458, 'rouge_l_f_score': 0.1591}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.13846153846153847}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.2767118566176471}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (Longformer) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (Pegasus) model ####################\u001b[0m\n",
      "Prediction: ['The CIA\\'s findings that Russia intervened in the 2016 election to help Donald Trump win the presidency are both \"stunning and not surprising\", the next leader of Senate Democrats said.']\n",
      "Target: ['– Reversing months of vague muttering about Russian influence, the CIA secretly told \"key senators\" that Russian hackers actively tried to put Donald Trump in the Oval Office, reports the Washington Post in one of a pair of damning reports Saturday on Russia\\'s efforts at influencing an American election. In the other, the New York Times reports that Russian hackers accessed both the RNC and the DNC—but released only damning emails from Democrats\\' side, while sitting on \"whatever information they gleaned from the Republican networks.\" Republicans contend that no information was released because they were never hacked, while the Trump transition team moved quickly to dismiss notions of any meddling. \"These are the same people that said Saddam Hussein had weapons of mass destruction,\" it said in a statement released Friday night. \"The election ended a long time ago ... It’s now time to move on.\" \"We now have high confidence that they hacked the DNC and the RNC, and conspicuously released no documents\" from the latter, a source tells the Times. Adds a senior official briefed on the CIA report, per the Post, \"it is the assessment of the intelligence community that Russia’s goal here was to favor one candidate over the other, to help Trump get elected.\" While the CIA is citing what the Post calls \"a growing body of intelligence from multiple sources,\" inter-agency disagreement about the scope of tampering exists and American intelligence has identified Russian actors that are \"one step\" removed from government, not officials from the Kremlin itself. GOP leaders remain skeptical. \"I’ll be the first one to come out and point at Russia if there’s clear evidence, but there is no clear evidence—even now,\" said Rep. Devin Nunes, House Intel committee chair and Trump transition team member. Chuck Schumer called the findings \"stunning but not surprising,\" per the Post; President Obama has ordered a full review of the claims. Read the Post report or the Times report.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:47:30,921 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:47:30,922 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpdjs_f6n2/system and model files to /tmp/tmpdjs_f6n2/model.\n",
      "2021-08-18 18:47:30,923 [MainThread  ] [INFO ]  Processing files in /tmp/tmpyypdgvl6.\n",
      "2021-08-18 18:47:30,924 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:47:30,925 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpdjs_f6n2/system.\n",
      "2021-08-18 18:47:30,925 [MainThread  ] [INFO ]  Processing files in /tmp/tmp8qx1rpnt.\n",
      "2021-08-18 18:47:30,926 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:47:30,927 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpdjs_f6n2/model.\n",
      "2021-08-18 18:47:30,927 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmphxmhiz7p/rouge_conf.xml\n",
      "2021-08-18 18:47:30,928 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmphxmhiz7p/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5230874419212341}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.000266292702621717}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.14959, 'rouge_2_f_score': 0.03343, 'rouge_l_f_score': 0.09419}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.08403361344537814}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.1851851851851852}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (Pegasus) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document joint (TextRank) model ####################\u001b[0m\n",
      "Prediction: ['\\n  \\n “It’s profoundly sad,” said neighbor Harriet Allen.']\n",
      "Target: ['– A 74-year-old Massachusetts woman may have been living with the decomposing body of her sister for up to 18 months, possibly without even realizing her sister was dead, the Brookline TAB reports. According to the Boston Globe, Lynda Waldman lived alone with her 67-year-old sister, Hope Wheaton, in the $1.2 million house in Brookline. Authorities say a cousin came to the house in December to help take out the trash and found Wheaton\\'s body under the kitchen table. Waldman appeared unaware her sister was dead and had to be informed by police, CBS Boston reports. Waldman says her sister would fall and be unable to get up. She said she would nurse Wheaton back to health with Fudgsicles and water, but Wheaton failed to get better after a fall in July 2015. While police are waiting on the results of an autopsy, they don\\'t suspect foul play in Wheaton\\'s death. And while it\\'s unclear why Waldman didn\\'t call authorities at any point, there\\'s no \"evidence of wrongdoing.\" Officials describe a house that was falling apart and filled with clutter to the point of hoarding. The front of the house was boarded up, and some neighbors were unaware anyone even lived there. One neighbor says the sisters were \"recluses\" who never left the house; another says neighbors joked the house was haunted. (A mother\\'s mummified remains were found in the home of an Arizona hoarder.)']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:47:54,852 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:47:54,853 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp1di8llcs/system and model files to /tmp/tmp1di8llcs/model.\n",
      "2021-08-18 18:47:54,853 [MainThread  ] [INFO ]  Processing files in /tmp/tmp0mh1015s.\n",
      "2021-08-18 18:47:54,854 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:47:54,855 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp1di8llcs/system.\n",
      "2021-08-18 18:47:54,855 [MainThread  ] [INFO ]  Processing files in /tmp/tmp83hic5ri.\n",
      "2021-08-18 18:47:54,856 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:47:54,857 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp1di8llcs/model.\n",
      "2021-08-18 18:47:54,858 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpskj3db95/rouge_conf.xml\n",
      "2021-08-18 18:47:54,858 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpskj3db95/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.3624487519264221}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 3.3506980192796586e-11}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.0315, 'rouge_2_f_score': 0.00793, 'rouge_l_f_score': 0.02363}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.016}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.03355704697986578}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document joint (TextRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (BART) model ####################\u001b[0m\n",
      "Prediction: ['Former White Plains Officer Glen Hochman had no known health or psychiatric problems. Interviews with people who knew him found no one had an inkling that \"Mr. Hoffman would have committed this heinous crime\" Alissa, 17, and Deanna, 13, were apparently both sleeping when they were shot in the head. Glen Hochman, a recently retired White Plains police officer, killed his two sleeping daughters, himself and three dogs Saturday. He left a five- to six-page note behind \"indicating the killings were premeditated,\" the local police chief said. The girls – Alissa, 18, and Deanna, 13 – apparently had both already been fatally shot in the head in their rooms at the 1 Adelphi Ave. home.']\n",
      "Target: ['– Glen Hochman apparently shot his 13- and 17-year-old daughters in the head with a .40-caliber Glock as they slept early Saturday, shot the family\\'s three dogs, then wrote a suicide note in which he said \"that the two girls were taken away,\" says the police chief in Harrison, NY, per the Journal News. Hochman indicated why he had done so, and that \"the killings were premeditated,\" says Anthony Marraccini; he would not elaborate. Hochman also included in the note five or six pages of instructions for his wife, Anamarie DiPietro-Hochman, on what she \"needed to do to get things in order for the family.\" The couple had discussed separating last month, but Hochman had no known mental issues and there was no sign of drug or alcohol use. \"The people we have spoken to did not foresee this action coming,\" says Marraccini. Hochman\\'s body was found in the garage Saturday afternoon by the boyfriend of 17-year-old Alissa, reports the AP; DiPietro-Hochman, out of town with her 22-year-old daughter and unable to raise her husband or daughters on the phone, had asked him to check the house. Police later found the two girls\\' bodies inside. \"It\\'s difficult, especially when you see two young girls, their lives have been ripped away, brutally murdered. You can\\'t get any rationale for that,\" said Marraccini. \"The act is so incredibly bad.\"']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:48:27,946 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:48:27,947 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmped4gq_94/system and model files to /tmp/tmped4gq_94/model.\n",
      "2021-08-18 18:48:27,948 [MainThread  ] [INFO ]  Processing files in /tmp/tmp4o46p1kq.\n",
      "2021-08-18 18:48:27,949 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:48:27,950 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmped4gq_94/system.\n",
      "2021-08-18 18:48:27,951 [MainThread  ] [INFO ]  Processing files in /tmp/tmpgf3vxkqc.\n",
      "2021-08-18 18:48:27,952 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:48:27,953 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmped4gq_94/model.\n",
      "2021-08-18 18:48:27,953 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpjhb4fwre/rouge_conf.xml\n",
      "2021-08-18 18:48:27,954 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpjhb4fwre/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5882028341293335}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 3.7324323174646765}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.36828, 'rouge_2_f_score': 0.07407, 'rouge_l_f_score': 0.14164}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.2292263610315186}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.25565161187295843}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (BART) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (LexRank) model ####################\u001b[0m\n",
      "Prediction: ['“As doctors we were assuming that sex gets worse for women.” \\n  \\n More comfortable with our bodies \\n  \\n To get a better sense of the impact of age on sex, Thomas and her colleagues spoke to 39 women whose ages ranged from 46 to 59, either in one on one interviews or in focus groups. The women pointed to several factors leading to better sex: \\n  \\n Increased understanding of how their bodies work when it comes to sex: “They felt more comfortable in their own skins. \"People assume as women get older, they automatically become sexually inactive and sex is not as important to them, which isn\\'t necessarily the case,\" study author Holly Thomas of the University of Pittsburgh told HealthDay. \"But if physicians are aware that a lot of these women are sexually active and interested in maintaining a healthy sex life, they can bring it up.\" Interviews with more than three dozen women ages 45 to 60 revealed that some were more satisfied with sex at midlife even though they had it less often. Some women in the study talked about \"negative\" changes in their sex lives as they aged, such as less frequent sex, vaginal dryness and difficulty reaching orgasm.']\n",
      "Target: ['– Women who have heard for years that they face a declining sex life can take heart in new research that says sex gets better with age. University of Pittsburgh researchers found that while the frequency of sex declines, the quality makes up for it. “We were surprised to find a group of women who said that sex actually got better for them as they got older,” says lead author Holly Thomas. “As doctors we were assuming that sex gets worse for women.” After interviewing 39 women between ages 46 and 59, Thomas and her team cited several factors behind women who experienced a better sex life, including knowing their bodies better and increased self confidence to ask for what they want. A larger survey from Case Western of 505 women between the ages of 40 and 75 found much the same, reports Today. \"They had a better knowledge and understanding of their own bodies as they got older. And they felt more comfortable and empowered to communicate their sexual needs to their partner than when they were younger,\" Thomas said, per WebMD. When women weren\\'t experiencing good sex, they pointed to other side of the bed, citing their partner\\'s low libido or erectile dysfunction. Lower libido was also a complaint of some women in the study, along with vaginal dryness. The new research builds on Thomas\\' previous findings that women over 60 were having a lot of sex, contrary to popular notions. Other research has found that older women who have frequent sex experience benefits such as lower blood pressure, while the opposite is true for older men who risk heart attacks. (How good is sex in Sweden? Researchers will find out.)']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:48:49,832 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:48:49,833 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpg3h6l8nm/system and model files to /tmp/tmpg3h6l8nm/model.\n",
      "2021-08-18 18:48:49,834 [MainThread  ] [INFO ]  Processing files in /tmp/tmpp0alr1w6.\n",
      "2021-08-18 18:48:49,835 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:48:49,836 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpg3h6l8nm/system.\n",
      "2021-08-18 18:48:49,837 [MainThread  ] [INFO ]  Processing files in /tmp/tmpcixmjpb0.\n",
      "2021-08-18 18:48:49,838 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:48:49,838 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpg3h6l8nm/model.\n",
      "2021-08-18 18:48:49,839 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp71yrupev/rouge_conf.xml\n",
      "2021-08-18 18:48:49,840 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp71yrupev/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6463611721992493}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 10.54782677145177}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.50722, 'rouge_2_f_score': 0.16977, 'rouge_l_f_score': 0.2268}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.3575883575883576}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.3566705772985148}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (LexRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (Longformer) model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([441]) tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer model: processing document of tensor([1416]) tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer model: processing document of tensor([2030]) tokens\n",
      "Prediction: [\"Chicago Superintendent Eddie Johnson says he will recommend firing seven officers.\\nHe will recommend the firing of seven officers who filed false reports in the fatal shooting of black teen Laquan McDonald.\\nThe officer shot McDonald 16 times in October 2014.\\nTwo of the officers cited in the report have since retired. The move is a long-delayed official response to a six-month investigation.\\nThe department's critics say the department is covering up for one another.\\nA video shows the officer opening fire within seconds of the shooting.\\nIt's unclear whether the officers will be fired or fired. Chicago Police Supt. Eddie Johnson is seeking to fire seven officers for lying in their accounts of what happened in the shooting of Laquan McDonald.\\nThe officer who was shot 16 times by Van Dyke was one of the 7 cops who were fired.\\nJohnson has decided not to seek termination because he disagrees with the city's recommendation to fire eight of the officers.\"]\n",
      "Target: ['– Chicago police superintendent Eddie Johnson recommended Thursday that seven officers be fired for their roles in the aftermath of the fatal shooting of Laquan McDonald, the Chicago Tribune reports. According to the AP, the officers are accused of violating Rule 14 against making false reports. Video released of the October 2014 shooting of McDonald shows McDonald holding a knife and walking away from officers prior to the shooting. Regardless, multiple officers at the scene reported that McDonald was walking threateningly toward them, and one officer even claimed McDonald swung the knife at them. The officers are accused of attempting to cover up what actually happened. Jason Van Dyke, the officer who shot McDonald 16 times, has been since charged with murder. In addition to recommending the seven officers be fired, Johnson also took away their police powers. \"These decisions were not made lightly,\" Johnson wrote in an email to police Thursday. \"Each officer will have their right to due process.\" The ultimate fate of the seven officers will be decided by the Chicago Police Board, the Chicago Sun-Times reports. Earlier this week, a report from the inspector general recommended firing 10 officers, but Johnson decided there wasn\\'t enough evidence against one. Two others had already retired. The inspector general will now investigate police brass and why the officers caught making false reports weren\\'t put on desk duty pending investigation.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:49:24,762 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:49:24,763 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp_ycxlavt/system and model files to /tmp/tmp_ycxlavt/model.\n",
      "2021-08-18 18:49:24,763 [MainThread  ] [INFO ]  Processing files in /tmp/tmp5qmxqon3.\n",
      "2021-08-18 18:49:24,764 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:49:24,764 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp_ycxlavt/system.\n",
      "2021-08-18 18:49:24,765 [MainThread  ] [INFO ]  Processing files in /tmp/tmp51lls709.\n",
      "2021-08-18 18:49:24,765 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:49:24,766 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp_ycxlavt/model.\n",
      "2021-08-18 18:49:24,767 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp9zowatj7/rouge_conf.xml\n",
      "2021-08-18 18:49:24,767 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp9zowatj7/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6449233889579773}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 6.361614074750951}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.52262, 'rouge_2_f_score': 0.18687, 'rouge_l_f_score': 0.29146}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.350253807106599}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.3261371887185183}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (Longformer) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (Pegasus) model ####################\u001b[0m\n",
      "Prediction: ['The periodic table will soon have four new names added to its lower right-hand corner. Four new names have been recommended for the chemical elements ununtrium, ununpentium, ununseptium and ununoctium. The latest additions to the periodic table will now be known as nihonium, moscovium, tennessine and oganesson.']\n",
      "Target: ['– Sorry, chemistry students, you\\'ve got four new names on the periodic table to memorize. The International Union of Pure and Applied Chemistry announced names for the four newest elements on Wednesday, Nature reports. Those names: nihonium (Nh), moscovium (Mc), tennessine (Ts), and oganesson (Og). According to the Guardian, elements 113, 115, 117, and 118 were added to the table after their discoveries were verified in December. Until now they\\'d been known by the Latin words for their atomic numbers: ununtrium, ununpentium, ununseptium, and ununoctium. So their new names are a little more interesting, at least. The new additions are all artificial elements, meaning they were created by—in Nature\\'s words—\"smashing lighter atomic nuclei together.\" The new elements were named by the laboratories in the US, Japan, and Russia that discovered them. Elements can be named after scientists, mythology, places, or their traits. The new elements are named for Moscow, Tennessee, Nihon (one way of saying \"Japan\" in Japanese), and 83-year-old Russian scientist Yuri Oganessian. Oganesson is only the second element to be named after a living scientist. While the names aren\\'t final until five months of public comment, the Royal Society of Chemistry—which predicted three out of the four names—\"can\\'t see too much objection to any of them.\" The last additions to the periodic table were in 2011, New Scientist reports.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:50:03,853 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:50:03,854 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmppjt86z54/system and model files to /tmp/tmppjt86z54/model.\n",
      "2021-08-18 18:50:03,854 [MainThread  ] [INFO ]  Processing files in /tmp/tmpvdga5x5c.\n",
      "2021-08-18 18:50:03,855 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:50:03,856 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmppjt86z54/system.\n",
      "2021-08-18 18:50:03,856 [MainThread  ] [INFO ]  Processing files in /tmp/tmp9h40vkkz.\n",
      "2021-08-18 18:50:03,857 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:50:03,857 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmppjt86z54/model.\n",
      "2021-08-18 18:50:03,858 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpr_urmv97/rouge_conf.xml\n",
      "2021-08-18 18:50:03,858 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpr_urmv97/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.6016560196876526}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.3600425939675759}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.24373, 'rouge_2_f_score': 0.11553, 'rouge_l_f_score': 0.14337}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.16727272727272727}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.3393689285875867}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (Pegasus) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: multi_news dataset, Multi-document separate (TextRank) model ####################\u001b[0m\n",
      "Prediction: [\"Mercury's hot surface also posed problems during low orbits, so additional radiators and heat pipes were used to get rid of this excess heat. Starting in 1996, Alexa Internet has been donating their crawl data to the Internet Archive. The probe, which has been mapping Mercury since 2011, is due to run out of fuel on Thursday and is expected to crash into the far side of the planet \\n  \\n Mercury, the innermost planet of the solar system, will acquire a fresh crater on Thursday when a half-tonne US spacecraft slams into the planet’s surface to end its spectacular four-year mission.\"]\n",
      "Target: ['– The first spacecraft ever to orbit Mercury is about to become the first spacecraft to smash into the planet. NASA says the Messenger probe will conclude its hugely successful mission when it crashes at 8,750mph into the side of the planet facing the sun today at 3:26pm EDT. The probe has been in orbit around Mercury for four years—or more than 16 Mercury years—and NASA says a final maneuver exhausted the last of its helium gas, leaving it incapable of \"fighting the downward push of the sun\\'s gravity.\" It will serve NASA until the end: The spacecraft has been taking low-altitude photos in its final days, sending back images of craters much like the one its crash will create today, Ars Technica reports. \"Messenger has been an amazing mission. The only previous Mercury mission, Mariner 10, flew past the planet three times in 1974 and 1975, giving us only an incomplete view,\" a professor of planetary sciences tells the Guardian. \"Messenger revealed the whole globe in detail.\" The trove of information Messenger has sent back, which includes signs of recent volcanic eruptions and of possible ice at the poles, shows that Mercury is a \"misfit planet that seems not to belong where we now find it,\" the professor says. \"Biggest mystery to be solved next time,\" the spacecraft\\'s Twitter feed said last week. \"Questions would probably be best answered by a lander. What is that dark material at the poles?\"']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:50:29,751 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:50:29,752 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp6rqe1ery/system and model files to /tmp/tmp6rqe1ery/model.\n",
      "2021-08-18 18:50:29,753 [MainThread  ] [INFO ]  Processing files in /tmp/tmpmq2ks8nx.\n",
      "2021-08-18 18:50:29,753 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:50:29,754 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp6rqe1ery/system.\n",
      "2021-08-18 18:50:29,755 [MainThread  ] [INFO ]  Processing files in /tmp/tmpm993uda_.\n",
      "2021-08-18 18:50:29,755 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:50:29,756 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp6rqe1ery/model.\n",
      "2021-08-18 18:50:29,757 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpuxkby6ee/rouge_conf.xml\n",
      "2021-08-18 18:50:29,757 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpuxkby6ee/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5458119511604309}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.298182715298779}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.30199, 'rouge_2_f_score': 0.06304, 'rouge_l_f_score': 0.16524}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.14409221902017288}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.21472392638036808}\n",
      "\u001b[32m#################### Test for multi_news dataset, Multi-document separate (TextRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/lily/mmm274/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      "100%|██████████| 204045/204045 [00:24<00:00, 8461.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xsum has a training set of 204045 examples\n",
      "\u001b[35mInitializing all matching model pipelines for xsum dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset xsum (/home/lily/mmm274/.cache/huggingface/datasets/xsum/default/1.2.0/4957825a982999fbf80bca0b342793b01b2611e021ef589fb7c6250b3577b499)\n",
      "  0%|          | 0/204045 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 99/204045 [00:37<21:35:02,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: xsum dataset, BART model ####################\u001b[0m\n",
      "Prediction: ['Clouds of apple and cherry mist and peach snow will be released into the air. People will also get scratch \\'n\\' sniff programmes and fruit sweets. The mayor said it was among the world\\'s \"most dazzling firework displays\" BBC London weather forecaster Sara Thornton said there would be scattered showers.']\n",
      "Target: ['Revellers celebrating the New Year in central London will be able to \"taste\" the atmosphere with flavoured mist, \"snow\" and confetti released.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:52:18,778 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:52:18,779 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp57sdcxr6/system and model files to /tmp/tmp57sdcxr6/model.\n",
      "2021-08-18 18:52:18,779 [MainThread  ] [INFO ]  Processing files in /tmp/tmp56vc6ddf.\n",
      "2021-08-18 18:52:18,780 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:52:18,781 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp57sdcxr6/system.\n",
      "2021-08-18 18:52:18,782 [MainThread  ] [INFO ]  Processing files in /tmp/tmp1x2g3f0x.\n",
      "2021-08-18 18:52:18,783 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:52:18,784 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp57sdcxr6/model.\n",
      "2021-08-18 18:52:18,785 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpprwm04f2/rouge_conf.xml\n",
      "2021-08-18 18:52:18,785 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpprwm04f2/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5275789499282837}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.0690162381325976}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.24657, 'rouge_2_f_score': 0.02817, 'rouge_l_f_score': 0.10959}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.14492753623188406}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.0635593220338983}\n",
      "\u001b[32m#################### Test for xsum dataset, BART model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: xsum dataset, LexRank model ####################\u001b[0m\n",
      "Prediction: ['Mr Schultz said the sales increase meant it had served 23 million more customers in the quarter compared to the same period last year. Both firms give their customers a chance to earn Starbucks \"starts\" which can be used in the coffee chain\\'s shops.']\n",
      "Target: ['Starbucks said global sales increased 18% to $4.9bn in the quarter to 28 June - its highest ever quarterly revenue.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:52:40,365 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:52:40,366 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpp03t_i4w/system and model files to /tmp/tmpp03t_i4w/model.\n",
      "2021-08-18 18:52:40,367 [MainThread  ] [INFO ]  Processing files in /tmp/tmp11ajaonr.\n",
      "2021-08-18 18:52:40,368 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:52:40,369 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpp03t_i4w/system.\n",
      "2021-08-18 18:52:40,369 [MainThread  ] [INFO ]  Processing files in /tmp/tmpj9ua_nno.\n",
      "2021-08-18 18:52:40,370 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:52:40,371 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpp03t_i4w/model.\n",
      "2021-08-18 18:52:40,372 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpuigl96g0/rouge_conf.xml\n",
      "2021-08-18 18:52:40,373 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpuigl96g0/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.529384434223175}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 3.725917780842771}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.27692, 'rouge_2_f_score': 0.09524, 'rouge_l_f_score': 0.21539}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.13114754098360654}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.19200969485060393}\n",
      "\u001b[32m#################### Test for xsum dataset, LexRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: xsum dataset, Longformer model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([384]) tokens\n",
      "Prediction: ['Public Health Wales recommends restrictions on advertising e-cigarettes in media.\\nPublic Health Service says e-cigs deliver nicotine within an inhalable aerosol.\\nComes as health risks are significantly lower than cigarettes.\\nHealth officials say e-cigarette sales are not without risk.']\n",
      "Target: ['Health officials are calling for a ban on the sale of confectionary-like flavours in e-cigarettes over concerns they appeal to children.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:53:03,296 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:53:03,297 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp0h72qqc6/system and model files to /tmp/tmp0h72qqc6/model.\n",
      "2021-08-18 18:53:03,298 [MainThread  ] [INFO ]  Processing files in /tmp/tmpx3u0gpab.\n",
      "2021-08-18 18:53:03,299 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:53:03,300 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp0h72qqc6/system.\n",
      "2021-08-18 18:53:03,300 [MainThread  ] [INFO ]  Processing files in /tmp/tmp98zsdy29.\n",
      "2021-08-18 18:53:03,301 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:53:03,302 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp0h72qqc6/model.\n",
      "2021-08-18 18:53:03,303 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp0h5gibr_/rouge_conf.xml\n",
      "2021-08-18 18:53:03,303 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp0h5gibr_/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5759812593460083}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.331372206682652}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.24616, 'rouge_2_f_score': 0.06349, 'rouge_l_f_score': 0.18462}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.0983606557377049}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.12892253675663815}\n",
      "\u001b[32m#################### Test for xsum dataset, Longformer model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: xsum dataset, Pegasus model ####################\u001b[0m\n",
      "Prediction: ['Leicester have made three changes to the side that lost to Saracens at the weekend.']\n",
      "Target: ['Adam Thompstone returns on the wing for Leicester for the visit of London Irish, while Jono Kitto makes a first start for the club at scrum-half.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:53:30,674 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:53:30,675 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpzg_kclyy/system and model files to /tmp/tmpzg_kclyy/model.\n",
      "2021-08-18 18:53:30,676 [MainThread  ] [INFO ]  Processing files in /tmp/tmpitmvlg25.\n",
      "2021-08-18 18:53:30,677 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:53:30,678 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpzg_kclyy/system.\n",
      "2021-08-18 18:53:30,678 [MainThread  ] [INFO ]  Processing files in /tmp/tmpa5l6chzh.\n",
      "2021-08-18 18:53:30,679 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:53:30,680 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpzg_kclyy/model.\n",
      "2021-08-18 18:53:30,681 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp60j_p7fj/rouge_conf.xml\n",
      "2021-08-18 18:53:30,682 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp60j_p7fj/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.46819964051246643}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.7274520003385847}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.19048, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.14286}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.052631578947368425}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.15527950310559005}\n",
      "\u001b[32m#################### Test for xsum dataset, Pegasus model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: xsum dataset, TextRank model ####################\u001b[0m\n",
      "Prediction: ['Three of the courses earmarked for the Olympics are in the bay and three are in the Atlantic, with up to 1,400 athletes set to compete in water sports at the Games.']\n",
      "Target: [\"Sailing's governing body has warned that events at the Rio Olympics in 2016 could be moved out of the polluted Guanabara Bay.\"]\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:53:51,696 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:53:51,697 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpfc6fazc0/system and model files to /tmp/tmpfc6fazc0/model.\n",
      "2021-08-18 18:53:51,698 [MainThread  ] [INFO ]  Processing files in /tmp/tmph91p2ray.\n",
      "2021-08-18 18:53:51,698 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:53:51,699 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpfc6fazc0/system.\n",
      "2021-08-18 18:53:51,700 [MainThread  ] [INFO ]  Processing files in /tmp/tmpv31ktv6j.\n",
      "2021-08-18 18:53:51,701 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:53:51,702 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpfc6fazc0/model.\n",
      "2021-08-18 18:53:51,703 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp4jvxt4im/rouge_conf.xml\n",
      "2021-08-18 18:53:51,703 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp4jvxt4im/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.49894580245018005}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 3.5410607693940146}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.25, 'rouge_2_f_score': 0.07407, 'rouge_l_f_score': 0.17857}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.23076923076923075}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.09677419354838708}\n",
      "\u001b[32m#################### Test for xsum dataset, TextRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset pubmed_qa (/home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d)\n",
      "Loading cached split indices for dataset at /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-ea46b0ec6b6151e7.arrow and /home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d/cache-34d92cfafb0bbd63.arrow\n",
      "100%|██████████| 169226/169226 [01:26<00:00, 1956.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pubmed_qa has a training set of 169226 examples\n",
      "\u001b[35mInitializing all matching model pipelines for pubmed_qa dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset pubmed_qa (/home/lily/mmm274/.cache/huggingface/datasets/pubmed_qa/pqa_artificial/1.0.0/2e65addecca4197502cd10ab8ef1919a47c28672f62d7abac7cc9afdcf24fb2d)\n",
      "  0%|          | 0/169226 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 100/169226 [00:55<26:15:12,  1.79it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 200/169226 [01:50<26:04:47,  1.80it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 299/169226 [02:28<23:22:15,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (BART) model ####################\u001b[0m\n",
      "Prediction: ['chronic metabolic acidosis ( cma ) normal adults results complex endocrine metabolic alterations including growth hormone ( gh ) insensitivity, hypothyroidism, hyperglucocorticoidism, hypoalbuminaemia loss protein stores. treated 14 chronic haemodialysis patients daily oral na-citrate 4 weeks, yielding steady-state pre-dialytic plasma bicarbonate concentration 26.7 mmol/l.']\n",
      "Target: ['CMA contributes to the derangements of the growth and thyroid hormone axes and to hypoalbuminaemia, but is not a modulator of systemic inflammation in dialysis patients. Correcting CMA may improve nutritional and metabolic parameters and thus lower morbidity and mortality.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:58:37,664 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:58:37,665 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp2cn_oar8/system and model files to /tmp/tmp2cn_oar8/model.\n",
      "2021-08-18 18:58:37,666 [MainThread  ] [INFO ]  Processing files in /tmp/tmpfi8xwe34.\n",
      "2021-08-18 18:58:37,667 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:58:37,668 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp2cn_oar8/system.\n",
      "2021-08-18 18:58:37,668 [MainThread  ] [INFO ]  Processing files in /tmp/tmpi71hwkbh.\n",
      "2021-08-18 18:58:37,669 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:58:37,670 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp2cn_oar8/model.\n",
      "2021-08-18 18:58:37,671 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpms00qx9_/rouge_conf.xml\n",
      "2021-08-18 18:58:37,671 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpms00qx9_/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5473907589912415}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.177721496744438}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.14117, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.11765}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.07407407407407408}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.045871559633027525}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (BART) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (LexRank) model ####################\u001b[0m\n",
      "Prediction: ['treatment epcs gw501516 , ppar-δ agonist , induced specifically matrix metallo-proteinase ( mmp ) -9 direct transcriptional activation . roles peroxisome proliferator-activated receptor ( ppar ) -δ vascular biology mainly unknown .']\n",
      "Target: ['Our results suggest that PPAR-δ is a crucial modulator of angio-myogenesis via the paracrine effects of EPCs, and its agonist is a good candidate as a therapeutic drug for patients with peripheral vascular diseases.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:59:00,887 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:59:00,888 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp15ipf7jq/system and model files to /tmp/tmp15ipf7jq/model.\n",
      "2021-08-18 18:59:00,889 [MainThread  ] [INFO ]  Processing files in /tmp/tmpa9omdq6c.\n",
      "2021-08-18 18:59:00,890 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:59:00,891 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp15ipf7jq/system.\n",
      "2021-08-18 18:59:00,891 [MainThread  ] [INFO ]  Processing files in /tmp/tmpdfxcqc0b.\n",
      "2021-08-18 18:59:00,892 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:59:00,893 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp15ipf7jq/model.\n",
      "2021-08-18 18:59:00,894 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpej9vfzpv/rouge_conf.xml\n",
      "2021-08-18 18:59:00,895 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpej9vfzpv/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5089986324310303}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.4476896280149854}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.13334, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.1}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.0}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.046583850931677016}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (LexRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (Longformer) model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([185]) tokens\n",
      "Prediction: ['V-couples were able to extubate higher v-cpf and involuntary cough peak flow.\\nV-cp fintillation was a controlled cough peak.\\nThe study was compared predictive accuracy voluntary cough peak (v-cpF)\\nThe researchers were able extubated higher vibrations 106 times.']\n",
      "Target: ['V-CPF is noninvasive. It is much more accurate than IV-CPF as a predictor of re-intubation in cooperative patients because the IV-CPF may underestimate cough strength in patients with high V-CPF. However, it is unclear which is optimal for use in uncooperative patients.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:59:27,254 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:59:27,255 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp3madcj83/system and model files to /tmp/tmp3madcj83/model.\n",
      "2021-08-18 18:59:27,256 [MainThread  ] [INFO ]  Processing files in /tmp/tmpf0s4razc.\n",
      "2021-08-18 18:59:27,257 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:59:27,258 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp3madcj83/system.\n",
      "2021-08-18 18:59:27,258 [MainThread  ] [INFO ]  Processing files in /tmp/tmpnmsu2vga.\n",
      "2021-08-18 18:59:27,259 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:59:27,260 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp3madcj83/model.\n",
      "2021-08-18 18:59:27,261 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpee3g4is_/rouge_conf.xml\n",
      "2021-08-18 18:59:27,261 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpee3g4is_/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5620355010032654}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.1885227360790502}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.15731, 'rouge_2_f_score': 0.04598, 'rouge_l_f_score': 0.15731}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.1411764705882353}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.052083333333333336}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (Longformer) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (Pegasus) model ####################\u001b[0m\n",
      "Prediction: ['Expression of a novel human pancreatic acinar cell receptor has been reported for the first time.']\n",
      "Target: ['These results indicate that SPINK1 plays a role as a growth factor, signaling through the EGFR pathway in pancreatic ductal adenocarcinoma and neoplasms, and that the EGFR is involved in the malignant transformation of IPMN.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 18:59:53,412 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 18:59:53,413 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpr9h6i0dy/system and model files to /tmp/tmpr9h6i0dy/model.\n",
      "2021-08-18 18:59:53,414 [MainThread  ] [INFO ]  Processing files in /tmp/tmpcihtahsj.\n",
      "2021-08-18 18:59:53,414 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 18:59:53,416 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpr9h6i0dy/system.\n",
      "2021-08-18 18:59:53,416 [MainThread  ] [INFO ]  Processing files in /tmp/tmpmpoyj9a3.\n",
      "2021-08-18 18:59:53,417 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 18:59:53,418 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpr9h6i0dy/model.\n",
      "2021-08-18 18:59:53,419 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpcsuu8lc6/rouge_conf.xml\n",
      "2021-08-18 18:59:53,420 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpcsuu8lc6/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5063368082046509}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.9943036623640187}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.15687, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.11764}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.0851063829787234}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.11173184357541902}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (Pegasus) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, TF-IDF (TextRank) model ####################\u001b[0m\n",
      "Prediction: ['therefore , hypothesized , δpwv strongly associated left ventricular mass index ( lvmi ) apwv cpwvd . δpwv 2.4 ± 1.2 m/s ( mean ± sd ) , ranging 0.8 m/s , indicating almost constant arterial stiffness cardiac cycle , 4.4 m/s , reflecting substantial pressure dependency .']\n",
      "Target: ['The change in arterial stiffness over the cardiac cycle, rather than diastolic stiffness, is independently associated with LVMI in healthy middle-aged individuals. Therefore, the pressure dependency of arterial stiffness should be considered in cardiovascular risk assessment.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:00:16,911 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:00:16,912 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpp5grgucd/system and model files to /tmp/tmpp5grgucd/model.\n",
      "2021-08-18 19:00:16,912 [MainThread  ] [INFO ]  Processing files in /tmp/tmpxt1b_9y4.\n",
      "2021-08-18 19:00:16,913 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:00:16,914 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpp5grgucd/system.\n",
      "2021-08-18 19:00:16,914 [MainThread  ] [INFO ]  Processing files in /tmp/tmpbnwred7t.\n",
      "2021-08-18 19:00:16,915 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:00:16,916 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpp5grgucd/model.\n",
      "2021-08-18 19:00:16,916 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpsxq_qnxy/rouge_conf.xml\n",
      "2021-08-18 19:00:16,917 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpsxq_qnxy/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5187576413154602}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 4.2168875803062384}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.23077, 'rouge_2_f_score': 0.07895, 'rouge_l_f_score': 0.15384}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.13513513513513511}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.12231815803244374}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, TF-IDF (TextRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (BART) model ####################\u001b[0m\n",
      "Prediction: [\"parkinson's disease ( pd ) chronic progressive neurologic disorder, affects approximately one million men women us alone. pd represents heterogeneous disorder common clinical manifestations, part, common neuropathological findings. pD represents heterogenous disorder common Clinical manifestations, Part, common Neuropathological Findings.\"]\n",
      "Target: ['Strategies aimed at maintaining parkin in a catalytically active state or interfering with the toxicity of AIMP2 and PARIS (ZNF746) offer new therapeutic opportunities.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:00:46,985 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:00:46,986 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpns46jgom/system and model files to /tmp/tmpns46jgom/model.\n",
      "2021-08-18 19:00:46,986 [MainThread  ] [INFO ]  Processing files in /tmp/tmp4hlg9lyr.\n",
      "2021-08-18 19:00:46,987 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:00:46,988 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpns46jgom/system.\n",
      "2021-08-18 19:00:46,989 [MainThread  ] [INFO ]  Processing files in /tmp/tmp419ba0_2.\n",
      "2021-08-18 19:00:46,989 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:00:46,990 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpns46jgom/model.\n",
      "2021-08-18 19:00:46,991 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmptt4ik8ox/rouge_conf.xml\n",
      "2021-08-18 19:00:46,991 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmptt4ik8ox/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.3538912534713745}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.022951633574269}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.0, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.0}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.0}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.0}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (BART) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (LexRank) model ####################\u001b[0m\n",
      "Prediction: ['examined whether accounting conscious status administrative data improved mortality prediction among patients moderate severe tbi . patients dichotomized no/brief loss consciousness ( loc ) vs extended loc greater 1 hour using international classification diseases , ninth revision ( icd-9 ) fifth digit modifiers .']\n",
      "Target: ['Accounting for LOC along with anatomical measures of injury severity improves mortality prediction among patients with moderate/severe TBI in administrative datasets. Further work is warranted to determine whether other physiological measures may also improve prediction across a variety of injury types.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:01:10,049 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:01:10,051 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpkfcy1v4x/system and model files to /tmp/tmpkfcy1v4x/model.\n",
      "2021-08-18 19:01:10,052 [MainThread  ] [INFO ]  Processing files in /tmp/tmp_3km17ae.\n",
      "2021-08-18 19:01:10,052 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:01:10,053 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpkfcy1v4x/system.\n",
      "2021-08-18 19:01:10,054 [MainThread  ] [INFO ]  Processing files in /tmp/tmp9p099xf7.\n",
      "2021-08-18 19:01:10,054 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:01:10,055 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpkfcy1v4x/model.\n",
      "2021-08-18 19:01:10,056 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpn8eu5q7p/rouge_conf.xml\n",
      "2021-08-18 19:01:10,056 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpn8eu5q7p/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5667684078216553}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 6.407123783602852}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.29629, 'rouge_2_f_score': 0.1519, 'rouge_l_f_score': 0.22222}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.2077922077922078}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.12585812356979406}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (LexRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (Longformer) model ####################\u001b[0m\n",
      "Longformer model: processing document of tensor([98]) tokens\n",
      "Prediction: ['58 patients studied obese patients.\\nThe obese patients were assessed for low calorie diet.\\nIn the obese patients, 58 patients were treated obese.\\nDiabetes resistance evaluated.\\nLow calorie diet was assessed.\\nStress-free diet was also assessed.22 patients.']\n",
      "Target: ['NK cells are significantly increased in IR severely obese people in respect to IS, suggesting a slightly different immune status in these patients with a probable dietary relationship. Weight loss could reverse this increase either after VLCD or after bariatric surgery.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:01:37,955 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:01:37,957 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmp5x_uiotu/system and model files to /tmp/tmp5x_uiotu/model.\n",
      "2021-08-18 19:01:37,958 [MainThread  ] [INFO ]  Processing files in /tmp/tmpaggurjea.\n",
      "2021-08-18 19:01:37,958 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:01:37,959 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp5x_uiotu/system.\n",
      "2021-08-18 19:01:37,960 [MainThread  ] [INFO ]  Processing files in /tmp/tmpd_odzko_.\n",
      "2021-08-18 19:01:37,960 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:01:37,961 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmp5x_uiotu/model.\n",
      "2021-08-18 19:01:37,962 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpjknkp3br/rouge_conf.xml\n",
      "2021-08-18 19:01:37,963 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpjknkp3br/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5035908222198486}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 1.188432823684058}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.075, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.075}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.02631578947368421}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.04010695187165775}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (Longformer) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (Pegasus) model ####################\u001b[0m\n",
      "Prediction: ['The influence of electromyographic signals on muscle contraction and pain is investigated.']\n",
      "Target: ['Short-term dynamic reorganization of the spatial distribution of muscle activity occurred in response to nociceptive afferent input.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:02:10,095 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:02:10,096 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpkt8o2h3h/system and model files to /tmp/tmpkt8o2h3h/model.\n",
      "2021-08-18 19:02:10,097 [MainThread  ] [INFO ]  Processing files in /tmp/tmpnrxhb32d.\n",
      "2021-08-18 19:02:10,098 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:02:10,099 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpkt8o2h3h/system.\n",
      "2021-08-18 19:02:10,099 [MainThread  ] [INFO ]  Processing files in /tmp/tmphu3bvv3k.\n",
      "2021-08-18 19:02:10,100 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:02:10,101 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpkt8o2h3h/model.\n",
      "2021-08-18 19:02:10,102 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp2r0cot1c/rouge_conf.xml\n",
      "2021-08-18 19:02:10,103 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp2r0cot1c/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5448035597801208}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 2.7673854938424567}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.2, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.2}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.15384615384615385}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.12}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (Pegasus) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: pubmed_qa dataset, BM25 (TextRank) model ####################\u001b[0m\n",
      "Prediction: ['patients evaluated upon admission , day leg crossing , upon discharge , 1 year discharge .']\n",
      "Target: ['Leg crossing is an easily obtained clinical sign and is independent of additional technical examinations. Leg crossing within the first 15 days after severe stroke indicates a favorable outcome which includes less neurologic deficits, better independence in daily life, and lower rates of death.']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:02:34,657 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:02:34,658 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpbbo7z1bt/system and model files to /tmp/tmpbbo7z1bt/model.\n",
      "2021-08-18 19:02:34,658 [MainThread  ] [INFO ]  Processing files in /tmp/tmpcuco0l13.\n",
      "2021-08-18 19:02:34,658 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:02:34,659 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpbbo7z1bt/system.\n",
      "2021-08-18 19:02:34,660 [MainThread  ] [INFO ]  Processing files in /tmp/tmp1c9ibnqq.\n",
      "2021-08-18 19:02:34,661 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:02:34,661 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpbbo7z1bt/model.\n",
      "2021-08-18 19:02:34,662 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpoj6kcm8o/rouge_conf.xml\n",
      "2021-08-18 19:02:34,663 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpoj6kcm8o/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4858647882938385}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.46806954336200896}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.07142, 'rouge_2_f_score': 0.03704, 'rouge_l_f_score': 0.07142}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset summertime_scisummnet (/home/lily/mmm274/.cache/huggingface/datasets/summertime_scisummnet/default/0.0.0/2de3b585a09db9aaf7f42cebe7c334a94ebae2d8104a752ce286c8a0d3fadaec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge_we_3_f': 0.07692307692307693}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.16788563829787237}\n",
      "\u001b[32m#################### Test for pubmed_qa dataset, BM25 (TextRank) model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 808/808 [00:00<00:00, 5996.24it/s]\n",
      "Reusing dataset summertime_scisummnet (/home/lily/mmm274/.cache/huggingface/datasets/summertime_scisummnet/default/0.0.0/2de3b585a09db9aaf7f42cebe7c334a94ebae2d8104a752ce286c8a0d3fadaec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ScisummNet has a training set of 808 examples\n",
      "\u001b[35mInitializing all matching model pipelines for ScisummNet dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/808 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 12%|█▏        | 99/808 [01:03<07:37,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m#################### Testing: ScisummNet dataset, BART model ####################\u001b[0m\n",
      "Prediction: ['For a training corpus with 10,000 sentence pairs we increase the coverage of unique test set unigrams from 48% to 90%. More than half of the newly covered items accurately translated, as opposed to none in current approaches. We show that upon encountering an unknown source phrase, we can substitute a paraphrase for it and then proceed using the translation of that paraphrase.']\n",
      "Target: ['Improved Statistical Machine Translation Using Paraphrases\\nParallel corpora are crucial for training SMT systems.\\nHowever, for many language pairs they are available only in very limited quantities.\\nFor these language pairs a huge portion of phrases encountered at run-time will be unknown.\\nWe show how techniques from paraphrasing can be used to deal with these otherwise unknown source language phrases.\\nOur results show that augmenting a state-of-the-art SMT system with paraphrases leads to significantly improved coverage and translation quality.\\nFor a training corpus with 10,000 sentence pairs we increase the coverage of unique test set unigrams from 48% to 90%, with more than half of the newly covered items accurately translated, as opposed to none in current approaches.\\nWe propose a novel method which substitutes a paraphrase for an unknown source word or phrase in the input sentence and then proceeds to use the translation of that paraphrase in the production of the target-language result.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:04:32,961 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:04:32,962 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpdommb5zv/system and model files to /tmp/tmpdommb5zv/model.\n",
      "2021-08-18 19:04:32,963 [MainThread  ] [INFO ]  Processing files in /tmp/tmpyr3v78io.\n",
      "2021-08-18 19:04:32,963 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:04:32,964 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpdommb5zv/system.\n",
      "2021-08-18 19:04:32,965 [MainThread  ] [INFO ]  Processing files in /tmp/tmpf94is5so.\n",
      "2021-08-18 19:04:32,966 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:04:32,967 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpdommb5zv/model.\n",
      "2021-08-18 19:04:32,967 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmp6mx5z84v/rouge_conf.xml\n",
      "2021-08-18 19:04:32,968 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmp6mx5z84v/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.7273702025413513}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 17.512927724582575}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.55111, 'rouge_2_f_score': 0.4574, 'rouge_l_f_score': 0.53333}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.47963800904977366}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.7080104819116995}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, BART model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: ScisummNet dataset, LexRank model ####################\u001b[0m\n",
      "Prediction: ['entropy-based measures, as in (Redlich, 1993).</S>\\n    <S sid=\"44\" ssid=\"38\">Word induction from natural language text without word boundaries is also studied in (Deligne and Bimbot, 1997; Hua, 2000), where MDL-based model optimization measures are used.</S>\\n    <S sid=\"45\" ssid=\"39\">Viterbi or the forward-backward algorithm (an EM algorithm) is used for improving the segmentation of the corpus2.</S>\\n    <S sid=\"46\" ssid=\"40\">Also de Marcken (1995; 1996) studies the problem of learning a lexicon, but instead of optimizing the cost of the whole corpus, as in (Redlich, 1993; Hua, 2000), de Marcken starts with sentences.</S>\\n    <S sid=\"47\" ssid=\"41\">Spaces are included as any other characters.</S>\\n    <S sid=\"48\" ssid=\"42\">Utterances are also analyzed in (Kit and Wilks, 1999) where optimal segmentation for an utterance is sought so that the compression effect over the segments is maximal.</S>\\n    <S sid=\"49\" ssid=\"43\">The compression effect is measured in what the authors call Description Length Gain, defined as the relative reduction in entropy.</S>\\n    <S sid=\"50\" ssid=\"44\">The Viterbi algorithm is used for searching for the optimal segmentation given a model.</S>\\n    <S sid=\"51\" ssid=\"45\">The input utterances include spaces and punctuation as ordinary characters.</S>\\n    <S sid=\"52\" ssid=\"46\">The method is evaluated in terms of precision and recall on word boundary prediction.</S>\\n    <S sid=\"53\" ssid=\"47\">Brent presents a general, modular probabilistic model structure for word discovery (Brent, 1999).</S>\\n    <S sid=\"54\" ssid=\"48\">He uses a minimum representation length criterion for model optimization and applies an incremental, greedy search algorithm which is suitable for on-line learning such that children might employ.</S>\\n    <S sid=\"55\" ssid=\"49\">In this work, we use a model where words may consist of lengthy sequences of segments.</S>\\n    <S sid=\"56\" ssid=\"50\">This model is especially suitable for languages with agglutinative morphological structure.</S>\\n    <S sid=\"57\" ssid=\"51\">We call the segments morphs and at this point no distinction is made between stems and affixes.</S>\\n    <S sid=\"58\" ssid=\"52\">The practical purpose of the segmentation is to provide a vocabulary of language units that is smaller and generalizes better than a vocabulary consisting of words as they appear in text.</S>\\n    <S sid=\"59\" ssid=\"53\">Such a vocabulary could be utilized in statistical language modeling, e.g., for speech recognition.</S>\\n    <S sid=\"60\" ssid=\"54\">Moreover, one could assume that such a discovered morph vocabulary would correspond rather closely to linguistic morphemes of the language.</S>\\n    <S sid=\"61\" ssid=\"55\">We examine two methods for unsupervised learning of the model, presented in Sections 2 and 3.</S>\\n    <S sid=\"62\" ssid=\"56\">The cost function for the first method is derived from the Minimum Description Length principle from classic information theory (Rissanen, 1989), which simultaneously measures the goodness of the representation and the model complexity.</S>\\n    <S sid=\"63\" ssid=\"57\">Including a model complexity term generally improves generalization by inhibiting overlearning, a problem especially severe for sparse data.</S>\\n    <S sid=\"64\" ssid=\"58\">An incremental (online) search algorithm is utilized that applies a hierarchical splitting strategy for words.</S>\\n    <S sid=\"65\" ssid=\"59\">In the second method the cost function is defined as the maximum likelihood of the data given the model.</S>\\n    <S sid=\"66\" ssid=\"60\">Sequential splitting is applied and a batch learning algorithm is utilized.</S>\\n    <S sid=\"67\" ssid=\"61\">In Section 4, we develop a method for evaluating the quality of the morph segmentations produced by the unsupervised segmentation methods.</S>\\n    <S sid=\"68\" ssid=\"62\">Even though the morph segmentations obtained are not intended to correspond exactly to the morphemes of linguistic theory, a basis for comparison is provided by existing, linguistically motivated morphological analyses of the words.</S>\\n    <S sid=\"69\" ssid=\"63\">Both segmentation methods are applied to the segmentation of both Finnish and English words.</S>\\n    <S sid=\"70\" ssid=\"64\">In Section 5, we compare the results obtained from our methods to results produced by Goldsmith&#8217;s Linguistica on the same data.</S>\\n  </SECTION>\\n  <SECTION title=\"2 Method 1: Recursive Segmentation and MDL Cost\" number=\"2\">\\n    <S sid=\"71\" ssid=\"1\">The task is to find the optimal segmentation of the source text into morphs.</S>\\n    <S sid=\"72\" ssid=\"2\">One can think of this as constructing a model of the data in which the model consists of a vocabulary of morphs, i.e. endings and markers) and clitics.</S>\\n    <S sid=\"198\" ssid=\"7\">Unfortunately the parser does not distinguish derivational affixes.</S>\\n    <S sid=\"199\" ssid=\"8\">The first 100 000 word tokens were used as training data, and the following 100 000 word tokens were used as test data.</S>\\n    <S sid=\"200\" ssid=\"9\">The test data contained 34 821 word types.</S>\\n    <S sid=\"201\" ssid=\"10\">The English corpus consisted of mainly newspaper text from the Brown corpus8.</S>\\n    <S sid=\"202\" ssid=\"11\">A morphological analysis of the words was performed using the Lingsoft ENGTWOL analyzer9.</S>\\n    <S sid=\"203\" ssid=\"12\">In case of multiple alternative morphological analyses, the shortest analysis was selected.</S>\\n    <S sid=\"204\" ssid=\"13\">All characters were converted to lower case, and words containing other characters than a through z, an apostrophe or a hyphen were removed.</S>\\n    <S sid=\"205\" ssid=\"14\">Other than morphemic tags were removed from the morphological analyses of the words.</S>\\n    <S sid=\"206\" ssid=\"15\">The remaining tags correspond to inflectional or derivational affixes.</S>\\n    <S sid=\"207\" ssid=\"16\">A set of 100 000 word tokens from the corpus sections Press Reportage and Press Editorial were used as training data.</S>\\n    <S sid=\"208\" ssid=\"17\">A separate set of 100 000 word tokens from the sections Press Editorial, Press Reviews, Religion, and Skills Hobbies were used as test data.</S>\\n    <S sid=\"209\" ssid=\"18\">The test data contained 12 053 word types.</S>\\n    <S sid=\"210\" ssid=\"19\">Test results for the three methods and the two languages are shown in Table 2.</S>\\n    <S sid=\"211\" ssid=\"20\">We observe different tendencies for Finnish and English.</S>\\n    <S sid=\"212\" ssid=\"21\">For Finnish, there is a correlation between the compression of the corpus and the linguistic generalization capacity to new word forms.</S>\\n    <S sid=\"213\" ssid=\"22\">The Recursive splitting with the MDL cost function is clearly superior to the Sequential splitting with ML cost, which in turn is superior to Linguistica.</S>\\n    <S sid=\"214\" ssid=\"23\">The Recursive MDL method is best in terms of data compression: it produces the smallest morph lexicon (codebook), and the codebook naturally occupies a small part of the total cost.</S>\\n    <S sid=\"215\" ssid=\"24\">It is best also in terms of the linguistic measure, the total alignment distance on test data.</S>\\n    <S sid=\"216\" ssid=\"25\">Linguistica, on the other hand, employs a more restricted segmentation, which leads to a larger codebook and to the fact that the codebook occupies a large part of the total MDL cost.</S>\\n    <S sid=\"217\" ssid=\"26\">This also appears to lead to a poor generalization ability to new word forms.</S>\\n    <S sid=\"218\" ssid=\"27\">The linguistic alignment distance is the highest, and so is the percentage of aligned morph/morphemic label pairs that were never observed in the training set.</S>\\n    <S sid=\"219\" ssid=\"28\">On the other hand, Linguistica is the fastest program10.</S>\\n    <S sid=\"220\" ssid=\"29\">Also for English, the Recursive MDL method achieves the best alignment, but here Linguistica achieves nearly the same result.</S>\\n    <S sid=\"221\" ssid=\"30\">The rate of compression follows the same pattern as for Finnish, in that Linguistica produces a much larger morph lexicon than the methods presented in this paper.</S>\\n    <S sid=\"222\" ssid=\"31\">In spite of this fact, the percentage of unseen morph/morphemic label pairs is about the same for all three methods.</S>\\n    <S sid=\"223\" ssid=\"32\">This suggests that in a morphologically poor language such as English a restrictive segmentation method, such as Linguistica, can compensate for new word forms &#8211; that it does not recognize at all &#8211; with old, familiar words, that it &#8220;gets just right&#8221;.</S>\\n    <S sid=\"224\" ssid=\"33\">In contrast, the methods presented in this paper produce a morph lexicon that is smaller and able to generalize better to new word forms but has somewhat lower accuracy for already observed word forms.</S>\\n    <S sid=\"225\" ssid=\"34\">Visual inspection of a sample of words.</S>\\n    <S sid=\"226\" ssid=\"35\">In an attempt to analyze the segmentations more thoroughly, we randomly picked 1000 different words from the Finnish test set.</S>\\n    <S sid=\"227\" ssid=\"36\">The total number of occurrences of these words constitute about 2.5% of the whole set.</S>\\n    <S sid=\"228\" ssid=\"37\">We inspected the segmentation of each word visually and classified it into one of three categories: (1) correct and complete segmentation (i.e., all relevant morpheme boundaries were identified), (2) correct but incomplete segmentation (i.e., not all relevant morpheme boundaries were identified, but no proposed boundary was incorrect), (3) incorrect segmentation (i.e., some proposed boundary did not correspond to an actual morpheme boundary).</S>\\n    <S sid=\"229\" ssid=\"38\">The results of the inspection for each of the three segmentation methods are shown in Table 3.</S>\\n    <S sid=\"230\" ssid=\"39\">The Recursive MDL method performs best and segments about half of the words correctly.</S>\\n    <S sid=\"231\" ssid=\"40\">The Sequential ML method comes second and Linguistica third with a share of 43% correctly segmented words.</S>\\n    <S sid=\"232\" ssid=\"41\">When considering the incomplete and incorrect segmentations the methods behave differently.</S>\\n    <S sid=\"233\" ssid=\"42\">The Recursive MDL method leaves very common word forms unsplit, and often produces excessive splitting for rare mentation and MDL cost (Rec.</S>\\n    <S sid=\"234\" ssid=\"43\">MDL), Sequential segmentation and ML cost (Seq.</S>\\n    <S sid=\"235\" ssid=\"44\">ML), and Linguistica (Ling.']\n",
      "Target: ['Unsupervised Discovery Of Morphemes\\nWe present two methods for unsupervised segmentation of words into morpheme-like units.\\nThe model utilized is especially suited for languages with a rich morphology, such as Finnish.\\nThe first method is based on the Minimum Description Length (MDL) principle and works online.\\nIn the second method, Maximum Likelihood (ML) optimization is used.\\nThe quality of the segmentations is measured using an evaluation method that compares the segmentations produced to an existing morphological analysis.\\nExperiments on both Finnish and English corpora show that the presented methods perform well compared to a current state-of-the-art system.\\nOur method is based on jointly minimizing the size of the morph codebook and the encoded size of all the word forms using the minimum description length MDL cost function.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:04:56,295 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:04:56,296 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpmanwigr9/system and model files to /tmp/tmpmanwigr9/model.\n",
      "2021-08-18 19:04:56,297 [MainThread  ] [INFO ]  Processing files in /tmp/tmpuaji__a0.\n",
      "2021-08-18 19:04:56,298 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:04:56,299 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpmanwigr9/system.\n",
      "2021-08-18 19:04:56,300 [MainThread  ] [INFO ]  Processing files in /tmp/tmp2pnyusik.\n",
      "2021-08-18 19:04:56,301 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:04:56,302 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpmanwigr9/model.\n",
      "2021-08-18 19:04:56,303 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpilv6_41y/rouge_conf.xml\n",
      "2021-08-18 19:04:56,303 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpilv6_41y/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5092178583145142}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.8733969433383787}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.05796, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.05796}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.10474631751227495}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.04660400472057366}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, LexRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: ScisummNet dataset, Longformer model ####################\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longformer model: processing document of tensor([4096]) tokens\n",
      "Prediction: ['Theorem 2 states that disagreement upper bounds error.\\nTheorem predicts that disagreement between rules and the core of the language.\\nIt is not difficult to prove that a classifier has low generalization error.2222;.\\nA simple example is the number of examples of the number 1 and 0;.']\n",
      "Target: [\"Bootstrapping\\nThis paper refines the analysis of co-training, defines and evaluates a new co-training algorithm that has theoretical justification, gives a theoretical justification for the Yarowsky algorithm, and shows that co-training and the Yarowsky algorithm are based on different independence assumptions.\\nWe show that the independence assumption can be relaxed, and co-training is still effective under a weaker independence assumption.\\nWe refine Dasgupta et al's result by relaxing the view independence assumption with a new constraint.\\nWe propose the Greedy Agreement Algorithm, which, based on two independent views of the data, learns two binary classifiers from a set of hand-typed seed rules.\\nWe show that if certain independence conditions between the classifier rules are satisfied and the precision of each rule is larger than a threshold T, then the precision of the final classifier is larger than T.\\nWe argue that the conditional independence assumption is remarkably strong and is rarely satisfied in real data sets, showing that a weaker independence assumption suffices.\\n\"]\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:05:28,826 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:05:28,827 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpgb4iin0s/system and model files to /tmp/tmpgb4iin0s/model.\n",
      "2021-08-18 19:05:28,828 [MainThread  ] [INFO ]  Processing files in /tmp/tmp_8go2dm_.\n",
      "2021-08-18 19:05:28,829 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:05:28,830 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpgb4iin0s/system.\n",
      "2021-08-18 19:05:28,830 [MainThread  ] [INFO ]  Processing files in /tmp/tmpfsj5h24w.\n",
      "2021-08-18 19:05:28,831 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:05:28,832 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpgb4iin0s/model.\n",
      "2021-08-18 19:05:28,833 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpsz0gevon/rouge_conf.xml\n",
      "2021-08-18 19:05:28,833 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpsz0gevon/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.5065644383430481}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.3717885486559232}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.18433, 'rouge_2_f_score': 0.03721, 'rouge_l_f_score': 0.17512}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.12206572769953052}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.23439483259526697}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, Longformer model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: ScisummNet dataset, Pegasus model ####################\u001b[0m\n",
      "Prediction: ['Thesaurus extraction has traditionally been used in retrieval tasks to expand words in queries with synonymous terms.']\n",
      "Target: ['Improvements In Automatic Thesaurus Extraction\\nThe use of semantic resources is common in modern NLP systems, but methods to extract lexical semantics have only recently begun to perform well enough for practical use.\\nWe evaluate existing and new similarity metrics for thesaurus extraction, and experiment with the trade-off between extraction performance and efficiency.\\nWe propose an approximation algorithm, based on canonical attributes and coarse and fine-grained matching, that reduces the time complexity and execution time of thesaurus extraction with only a marginal performance penalty.\\nWe show that synonymy extraction for lexical semantic resources using distributional similarity produces continuing gains in accuracy as the volume of input data increases.\\nWe demonstrate that dramatically increasing the quantity of text used to extract contexts significantly improves synonym quality.\\nWe find the JACCARD measure and the TTEST weight to have the best performance in our comparison of distance measures.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:05:59,511 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:05:59,513 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmpqrccxfe7/system and model files to /tmp/tmpqrccxfe7/model.\n",
      "2021-08-18 19:05:59,513 [MainThread  ] [INFO ]  Processing files in /tmp/tmpsy5j7v6w.\n",
      "2021-08-18 19:05:59,514 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:05:59,515 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpqrccxfe7/system.\n",
      "2021-08-18 19:05:59,516 [MainThread  ] [INFO ]  Processing files in /tmp/tmp3eo2i986.\n",
      "2021-08-18 19:05:59,516 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:05:59,517 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmpqrccxfe7/model.\n",
      "2021-08-18 19:05:59,518 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmphlpts20i/rouge_conf.xml\n",
      "2021-08-18 19:05:59,519 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmphlpts20i/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.4973493218421936}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 0.0017876429458869197}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.09756, 'rouge_2_f_score': 0.01235, 'rouge_l_f_score': 0.09756}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.012499999999999999}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.13422818791946312}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, Pegasus model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[35m#################### Testing: ScisummNet dataset, TextRank model ####################\u001b[0m\n",
      "Prediction: ['<PAPER>\\n  <S sid=\"0\">Accurate Information Extraction From Research Papers Using Conditional Random Fields</S>\\n  <ABSTRACT>\\n    <S sid=\"1\" ssid=\"1\">With the increasing use of research paper search engines, such as CiteSeer, for both literature search and hiring decisions, the accuracy of such systems is of paramount importance.</S>\\n    <S sid=\"2\" ssid=\"2\">This paper employs Conditional Random Fields (CRFs) for the task of extracting various common fields from the headers and citation of research papers.</S>\\n    <S sid=\"3\" ssid=\"3\">The basic theory of CRFs is becoming well-understood, but best-practices for applying them to real-world data requires additional exploration.</S>\\n    <S sid=\"4\" ssid=\"4\">This paper makes an empirical exploration of several factors, including variations on Gaussian, expoand priors for improved regularization, and several classes of features and Markov order.</S>\\n    <S sid=\"5\" ssid=\"5\">On a standard benchmark data set, we achieve new state-of-the-art performance, reducing error in average F1 by 36%, and word error rate by 78% in comparison with the previous best SVM results.</S>\\n    <S sid=\"6\" ssid=\"6\">Accuracy compares even more favorably against HMMs.</S>\\n  </ABSTRACT>\\n  <SECTION title=\"1 Introduction\" number=\"1\">\\n    <S sid=\"7\" ssid=\"1\">Research paper search engines, such as CiteSeer (Lawrence et al., 1999) and Cora (McCallum et al., 2000), give researchers tremendous power and convenience in their research.</S>\\n    ']\n",
      "Target: ['Accurate Information Extraction From Research Papers Using Conditional Random Fields\\nWith the increasing use of research paper search engines, such as CiteSeer, for both literature search and hiring decisions, the accuracy of such systems is of paramount importance.\\nThis paper employs Conditional Random Fields (CRFs) for the task of extracting various common fields from the headers and citation of research papers.\\nThe basic theory of CRFs is becoming well-understood, but best-practices for applying them to real-world data requires additional exploration.\\nThis paper makes an empirical exploration of several factors, including variations on Gaussian, exponential and hyperbolic-L1 priors for improved regularization, and several classes of features and Markov order.\\nOn a standard benchmark data set, we achieve new state-of-the-art performance, reducing error in average F1 by 36%, and word error rate by 78% in comparison with the previous best SVM results.\\nAccuracy compares even more favorably against HMMs.\\nCORA consists of two collections: a set of research paper headers annotated for entities such as title, author, and institution; and a collection of references annotated with BibTeX fields such as journal, year, and publisher.\\n']\n",
      "\n",
      "\u001b[35mbert score metric\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-18 19:06:24,137 [MainThread  ] [INFO ]  Writing summaries.\n",
      "2021-08-18 19:06:24,138 [MainThread  ] [INFO ]  Processing summaries. Saving system files to /tmp/tmptz0nywut/system and model files to /tmp/tmptz0nywut/model.\n",
      "2021-08-18 19:06:24,139 [MainThread  ] [INFO ]  Processing files in /tmp/tmp36dqkwju.\n",
      "2021-08-18 19:06:24,140 [MainThread  ] [INFO ]  Processing system.0.txt.\n",
      "2021-08-18 19:06:24,141 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmptz0nywut/system.\n",
      "2021-08-18 19:06:24,142 [MainThread  ] [INFO ]  Processing files in /tmp/tmpw8ef_y27.\n",
      "2021-08-18 19:06:24,142 [MainThread  ] [INFO ]  Processing model.A.0.txt.\n",
      "2021-08-18 19:06:24,143 [MainThread  ] [INFO ]  Saved processed files to /tmp/tmptz0nywut/model.\n",
      "2021-08-18 19:06:24,144 [MainThread  ] [INFO ]  Written ROUGE configuration to /tmp/tmpabv30ias/rouge_conf.xml\n",
      "2021-08-18 19:06:24,144 [MainThread  ] [INFO ]  Running ROUGE with command /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/ROUGE-1.5.5.pl -e /home/lily/mmm274/anaconda3/lib/python3.8/site-packages/summ_eval/ROUGE-1.5.5/data -c 95 -2 -1 -U -r 1000 -n 4 -w 1.2 -a -m /tmp/tmpabv30ias/rouge_conf.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-uncased_L8_no-idf_version=0.3.9(hug_trans=4.5.1)\n",
      "{'bert_score_f1': 0.68541020154953}\n",
      "\u001b[35mbleu metric\u001b[0m\n",
      "{'bleu': 43.512402237542766}\n",
      "\u001b[35mrouge metric\u001b[0m\n",
      "{'rouge_1_f_score': 0.0, 'rouge_2_f_score': 0.0, 'rouge_l_f_score': 0.0}\n",
      "\u001b[35mrougeWE metric\u001b[0m\n",
      "{'rouge_we_3_f': 0.7002398081534772}\n",
      "\u001b[35mmeteor metric\u001b[0m\n",
      "{'meteor': 0.6541982424289587}\n",
      "\u001b[32m#################### Test for ScisummNet dataset, TextRank model COMPLETE ####################\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset summertime_summscreen (/home/lily/mmm274/.cache/huggingface/datasets/summertime_summscreen/default/0.0.0/3b7dab2d730657a8545307f56c2e997a817186018ef6141b5699deebdc103573)\n",
      "100%|██████████| 22588/22588 [00:15<00:00, 1446.36it/s]\n",
      "Reusing dataset summertime_summscreen (/home/lily/mmm274/.cache/huggingface/datasets/summertime_summscreen/default/0.0.0/3b7dab2d730657a8545307f56c2e997a817186018ef6141b5699deebdc103573)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SummScreen_fd+tms_tokenized has a training set of 22588 examples\n",
      "\u001b[35mInitializing all matching model pipelines for SummScreen_fd+tms_tokenized dataset...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22588 [00:00<?, ?it/s]You are using a model of type encoder_decoder to instantiate a model of type encoder-decoder. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of the model checkpoint at patrickvonplaten/longformer2roberta-cnn_dailymail-fp16 were not used when initializing EncoderDecoderModel: ['decoder.roberta.pooler.dense.weight', 'decoder.roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing EncoderDecoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing EncoderDecoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "usage: ipykernel_launcher.py [-h] [--command COMMAND] [--conf_file CONF_FILE] [--PYLEARN_MODEL PYLEARN_MODEL] [--master_port MASTER_PORT] [--cluster CLUSTER]\n",
      "                             [--dist_init_path DIST_INIT_PATH] [--fp16] [--fp16_opt_level FP16_OPT_LEVEL] [--no_cuda] [--config_overrides CONFIG_OVERRIDES]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /data/lily/mmm274/.local/share/jupyter/runtime/kernel-369aba35-f017-4079-b962-647940f28e66.json\n",
      "  0%|          | 99/22588 [01:12<4:34:49,  1.36it/s]\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_all (__main__.IntegrationTests)\n",
      "Runs integration test on all compatible dataset + model + evaluation metric pipelines supported by SummerTime.\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-10-2ac3e8c0d838>\", line 81, in test_all\n",
      "    matching_model_instances = assemble_model_pipeline(dataset_cls, SUPPORTED_SUMM_MODELS)\n",
      "  File \"/data/lily/mmm274/SummerTime/SummerTime/pipeline/__init__.py\", line 51, in assemble_model_pipeline\n",
      "    dialogue_based_model_instances = [model_cls() for model_cls in dialogue_based_model_list] if dataset.is_dialogue_based else []\n",
      "  File \"/data/lily/mmm274/SummerTime/SummerTime/pipeline/__init__.py\", line 51, in <listcomp>\n",
      "    dialogue_based_model_instances = [model_cls() for model_cls in dialogue_based_model_list] if dataset.is_dialogue_based else []\n",
      "  File \"/data/lily/mmm274/SummerTime/SummerTime/model/dialogue/hmnet_model.py\", line 31, in __init__\n",
      "    self.opt = self._parse_args()\n",
      "  File \"/data/lily/mmm274/SummerTime/SummerTime/model/dialogue/hmnet_model.py\", line 59, in _parse_args\n",
      "    cmdline_args = parser.parse_args()\n",
      "  File \"/home/lily/mmm274/anaconda3/lib/python3.8/argparse.py\", line 1771, in parse_args\n",
      "    self.error(msg % ' '.join(argv))\n",
      "  File \"/home/lily/mmm274/anaconda3/lib/python3.8/argparse.py\", line 2521, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"/home/lily/mmm274/anaconda3/lib/python3.8/argparse.py\", line 2508, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1750.835s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7f68892a2610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "from model.base_model import SummModel\n",
    "from model import SUPPORTED_SUMM_MODELS, LexRankModel, PegasusModel\n",
    "\n",
    "from pipeline import assemble_model_pipeline\n",
    "\n",
    "from evaluation.base_metric import SummMetric\n",
    "from evaluation import SUPPORTED_EVALUATION_METRICS, Rouge, RougeWe\n",
    "\n",
    "from dataset.st_dataset import SummInstance, SummDataset\n",
    "from dataset import SUPPORTED_SUMM_DATASETS\n",
    "from dataset.non_huggingface_datasets import ScisummnetDataset, SummscreenDataset, ArxivDataset\n",
    "from dataset.huggingface_datasets import CnndmDataset, MlsumDataset, SamsumDataset\n",
    "\n",
    "from tests.helpers import print_with_color, retrieve_random_test_instances\n",
    "\n",
    "import random\n",
    "import time\n",
    "from typing import Dict, List, Union, Tuple\n",
    "import sys\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "class IntegrationTests(unittest.TestCase):\n",
    "    \n",
    "    def get_prediction(self, model: SummModel, dataset: SummDataset, test_instances: List[SummInstance]) -> Tuple[Union[List[str], List[List[str]]], Union[List[str], List[List[str]]]]:\n",
    "        \"\"\"\n",
    "        Get summary prediction given model and dataset instances.\n",
    "\n",
    "        :param SummModel `model`: Model for summarization task.\n",
    "        :param SummDataset `dataset`: Dataset for summarization task.\n",
    "        :param List[SummInstance] `test_instances`: Instances from `dataset` to summarize.\n",
    "        :returns Tuple containing summary list of summary predictions and targets corresponding to each instance in `test_instances`.\n",
    "        \"\"\"\n",
    "\n",
    "        src = [ins.source[0] for ins in test_instances] if isinstance(dataset, ScisummnetDataset) else [ins.source for ins in test_instances]\n",
    "        tgt = [ins.summary for ins in test_instances]\n",
    "        query = [ins.query for ins in test_instances] if dataset.is_query_based else None\n",
    "        prediction = model.summarize(src, query)\n",
    "        return prediction, tgt\n",
    "    \n",
    "    def get_eval_dict(self, metric: SummMetric, prediction: List[str], tgt: List[str]):\n",
    "        \"\"\"\n",
    "        Run evaluation metric on summary prediction.\n",
    "\n",
    "        :param SummMetric `metric`: Evaluation metric.\n",
    "        :param List[str] `prediction`: Summary prediction instances.\n",
    "        :param List[str] `tgt`: Target prediction instances from dataset.\n",
    "        \"\"\"\n",
    "        score_dict = metric.evaluate(prediction, tgt)\n",
    "        return score_dict\n",
    "\n",
    "    def test_all(self):\n",
    "        \"\"\"\n",
    "        Runs integration test on all compatible dataset + model + evaluation metric pipelines supported by SummerTime.\n",
    "        \"\"\"\n",
    "\n",
    "        print_with_color(\"\\nInitializing all evaluation metrics...\", \"35\")\n",
    "        evaluation_metrics = []\n",
    "        for eval_cls in SUPPORTED_EVALUATION_METRICS:\n",
    "            # # TODO: Temporarily skipping Rouge/RougeWE metrics to avoid local bug.\n",
    "            # if eval_cls in [Rouge, RougeWe]:\n",
    "            #     continue\n",
    "            print(eval_cls)\n",
    "            evaluation_metrics.append(eval_cls())\n",
    "\n",
    "        print_with_color(\"\\n\\nBeginning integration tests...\", \"35\")\n",
    "        for dataset_cls in SUPPORTED_SUMM_DATASETS:\n",
    "            # TODO: Temporarily skipping MLSumm (Gitlab: server-side login gating) and Arxiv (size/time)\n",
    "            if dataset_cls in [MlsumDataset, ArxivDataset, SamsumDataset]:\n",
    "                continue\n",
    "            dataset = dataset_cls()\n",
    "            if dataset.train_set is not None:\n",
    "                dataset_instances = list(dataset.train_set)\n",
    "                print(f\"\\n{dataset.dataset_name} has a training set of {len(dataset_instances)} examples\")\n",
    "                print_with_color(f\"Initializing all matching model pipelines for {dataset.dataset_name} dataset...\", \"35\")\n",
    "                # matching_model_instances = assemble_model_pipeline(dataset_cls, list(filter(lambda m: m != PegasusModel, SUPPORTED_SUMM_MODELS)))\n",
    "                matching_model_instances = assemble_model_pipeline(dataset_cls, SUPPORTED_SUMM_MODELS)\n",
    "                for model, model_name in matching_model_instances:\n",
    "                    test_instances = retrieve_random_test_instances(dataset_instances=dataset_instances, num_instances=1)\n",
    "                    print_with_color(f\"{'#' * 20} Testing: {dataset.dataset_name} dataset, {model_name} model {'#' * 20}\", \"35\")\n",
    "                    prediction, tgt = self.get_prediction(model, dataset, test_instances)\n",
    "                    print(f\"Prediction: {prediction}\\nTarget: {tgt}\\n\")\n",
    "                    for metric in evaluation_metrics:\n",
    "                        print_with_color(f\"{metric.metric_name} metric\", \"35\")\n",
    "                        score_dict = self.get_eval_dict(metric, prediction, tgt)\n",
    "                        print(score_dict)\n",
    "\n",
    "                    print_with_color(f\"{'#' * 20} Test for {dataset.dataset_name} dataset, {model_name} model COMPLETE {'#' * 20}\\n\\n\", \"32\")\n",
    "\n",
    "unittest.main(argv=['first-arg-is-ignored'], exit=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SummerTime midway showcase",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
